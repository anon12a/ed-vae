{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main Experiment  - Fashion-MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anon12a/ed-vae/blob/main/Main_Experiment_Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuGBmuIP2-3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3588db16-df05-445f-b8c9-84f40886c89d"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "from keras.layers import *\n",
        "from keras.layers import Layer, Dense, Activation, Flatten, Lambda, Conv2D, Conv2DTranspose, BatchNormalization, Reshape\n",
        "from keras.models import Model, Input, Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.losses import mse\n",
        "from keras import backend as K\n",
        "from keras import optimizers, initializers, regularizers, constraints\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from keras.datasets import mnist, fashion_mnist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDM00KrzsQDN"
      },
      "source": [
        "%matplotlib inline "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_37I8fOyzoqM"
      },
      "source": [
        "#Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NMF0_qm95ju"
      },
      "source": [
        "def flatten_data(data):\n",
        "\n",
        "  data = np.reshape(data,(-1, original_dim))\n",
        "  \n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7J_-RM_zu9N"
      },
      "source": [
        "#Losses and Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLHN4RV-ijiK"
      },
      "source": [
        "def reconstruction_error(model):\n",
        "\n",
        "    recon_error = mse(K.reshape(model.input, [-1]), K.reshape(model.output, [-1]))  \n",
        "    recon_error *= original_dim\n",
        "    recon_error = K.mean(recon_error)\n",
        "\n",
        "    return recon_error     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9gRiLBzOQhL"
      },
      "source": [
        "def kl_divergence(encoder):\n",
        "\n",
        "    kl = K.mean(- 0.5 * K.sum(1 + encoder.get_output_at(1)[1] - K.square(encoder.get_output_at(1)[0]) - K.exp(encoder.get_output_at(1)[1]), axis=-1))\n",
        "\n",
        "    return kl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRx30fLElcLn"
      },
      "source": [
        "def per_example_reconstruction_error(model, data):\n",
        "\n",
        "    decoded = model.predict(data, batch_size=batch_size)\n",
        "    recon_error = mse(np.reshape(data,(-1,original_dim)), np.reshape(decoded,(-1,original_dim)))\n",
        "    recon_error *= original_dim\n",
        "\n",
        "    return tf.Session().run(recon_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYQ567VGbAS6"
      },
      "source": [
        "# reconstruction error of the expected latent representation \n",
        "def per_example_elr_reconstruction_error(encoder, decoder, data):\n",
        "\n",
        "    z_mean, z_log_var, z = encoder.predict(data, batch_size=batch_size)\n",
        "    decoded = decoder.predict(z_mean, batch_size=batch_size)\n",
        "    recon_error = mse(np.reshape(data,(-1,original_dim)), np.reshape(decoded,(-1,original_dim)))\n",
        "    recon_error *= original_dim\n",
        "\n",
        "    return tf.Session().run(recon_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z9EoorcRUc3"
      },
      "source": [
        "def per_example_kl_divergence(encoder, data):\n",
        "\n",
        "    z_mean, z_log_var, z = encoder.predict(data, batch_size=batch_size)\n",
        "\n",
        "    kl = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "    kl = K.sum(kl, axis=-1)\n",
        "    kl *= -0.5\n",
        "\n",
        "    return tf.Session().run(kl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qkn5Zlr1JFkH"
      },
      "source": [
        "def pr_auc(x, y):\n",
        "    precision, recall, _ = precision_recall_curve(x, y, pos_label=1)\n",
        "    pr_auc = auc(recall, precision)\n",
        "    \n",
        "    return pr_auc    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dADdxoGUJO6F"
      },
      "source": [
        "def roc_auc(x, y):\n",
        "    fpr, tpr, thresholds = roc_curve(x, y, pos_label=1)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    return roc_auc "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkK2NAigwrHP"
      },
      "source": [
        "# Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8MJGnfLcKx3"
      },
      "source": [
        "## Convolutional Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BOMeH0iwrHS"
      },
      "source": [
        "def conv_encoder(input_side=32, n_channels=3, representation_dim=512, filter_size = 64, representation_activation='sigmoid', intermediate_activation='relu', batch_norm = False):\n",
        "  \n",
        "    input_shape = (input_side, input_side, n_channels)\n",
        "\n",
        "    input = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(filter_size, kernel_size=(3, 3), strides=(2, 2), padding='same')(input)\n",
        "    if batch_norm == True:\n",
        "      x = BatchNormalization()(x)\n",
        "    x = Activation(intermediate_activation)(x)\n",
        "\n",
        "    x = Conv2D(filter_size, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "    if batch_norm == True:\n",
        "      x = BatchNormalization()(x) \n",
        "    x = Activation(intermediate_activation)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(filter_size * input_side//4 * input_side//4)(x)\n",
        "    if batch_norm == True:\n",
        "      x = BatchNormalization()(x) \n",
        "    x = Activation(intermediate_activation)(x)\n",
        "\n",
        "    x = Dense(representation_dim)(x)\n",
        "    if batch_norm == True:\n",
        "      x = BatchNormalization()(x)\n",
        "    encoded = Activation(representation_activation)(x)   \n",
        "\n",
        "    return Model(input, encoded, name=\"encoder\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKf5kMSMwrHS"
      },
      "source": [
        "def conv_decoder(output_side=32, n_channels=3, representation_dim=512, filter_size = 64, activation='relu', batch_norm = False):\n",
        "\n",
        "    encoded_input = Input(shape=(representation_dim,))\n",
        "\n",
        "    x = Dense(filter_size * output_side//4 * output_side//4)(encoded_input)\n",
        "    if batch_norm == True:\n",
        "      x = BatchNormalization()(x) \n",
        "    x = Activation(activation)(x)\n",
        "\n",
        "    conv_shape = (output_side//4, output_side//4, filter_size)\n",
        "    x = Reshape(conv_shape)(x)\n",
        "    \n",
        "    x = Conv2DTranspose(filter_size, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "    if batch_norm == True:\n",
        "      x = BatchNormalization()(x)    \n",
        "    x = Activation(activation)(x)\n",
        "\n",
        "    x = Conv2DTranspose(filter_size, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "    if batch_norm == True:\n",
        "      x = BatchNormalization()(x)     \n",
        "    x = Activation(activation)(x)\n",
        "\n",
        "    x = Conv2DTranspose(n_channels, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
        "    if batch_norm == True:\n",
        "      x = BatchNormalization()(x)    \n",
        "    decoded = Activation('sigmoid')(x)\n",
        "\n",
        "    return Model(encoded_input, decoded, name=\"decoder\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXuaAZ8gieCp"
      },
      "source": [
        "def convolutional_autoencoder(encoder, decoder):\n",
        "\n",
        "    input = Input(batch_shape=encoder.input_shape)\n",
        "    output = decoder(encoder(input))\n",
        "\n",
        "    cae = Model(input, output, name='cae')\n",
        "\n",
        "    return cae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1JqywGXcURQ"
      },
      "source": [
        "## Convolutional Variational Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWkLuk7zwrHT"
      },
      "source": [
        "def cvae_encoder(input_side=32, n_channels=3, representation_dim=512, filter_size = 64, intermediate_activation='relu', batch_norm=False):  \n",
        "    input_shape = (input_side, input_side, n_channels)\n",
        "\n",
        "    input = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(filter_size, kernel_size=(3, 3), strides=(2, 2), padding='same')(input)\n",
        "    x = Activation(intermediate_activation)(x)\n",
        "\n",
        "    x = Conv2D(filter_size, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = Activation(intermediate_activation)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(filter_size * input_side//4 * input_side//4)(x)\n",
        "    x = Activation(intermediate_activation)(x)\n",
        "\n",
        "    z_mean = Dense(representation_dim, name='z_mean')(x)\n",
        "    z_log_var = Dense(representation_dim, name='z_log_var')(x)\n",
        "    z = Lambda(sampling, output_shape=(representation_dim,), name='z')([z_mean, z_log_var])\n",
        "\n",
        "    return Model(input, [z_mean, z_log_var, z], name=\"encoder\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPvLRAowwrHT"
      },
      "source": [
        "def cvae_decoder(output_side=32, n_channels=3, representation_dim=512, filter_size = 64, activation='relu', batch_norm=False):\n",
        "    \n",
        "    encoded_input = Input(shape=(representation_dim,))\n",
        "\n",
        "    x = Dense(filter_size * output_side//4 * output_side//4)(encoded_input)\n",
        "    x = Activation(activation)(x)\n",
        "\n",
        "    conv_shape = (output_side//4, output_side//4, filter_size)\n",
        "    x = Reshape(conv_shape)(x)\n",
        "\n",
        "    x = Conv2DTranspose(filter_size, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = Activation(activation)(x)\n",
        "\n",
        "    x = Conv2DTranspose(filter_size, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = Activation(activation)(x)\n",
        "\n",
        "    x = Conv2DTranspose(n_channels, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
        "    decoded = Activation('sigmoid')(x)\n",
        "\n",
        "    return Model(encoded_input, decoded, name=\"decoder\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw4n1DELN7Yx"
      },
      "source": [
        "def convolutional_variational_autoencoder(encoder, decoder):\n",
        "\n",
        "    input = Input(batch_shape=encoder.input_shape)\n",
        "    output = decoder(encoder(input)[2])\n",
        "\n",
        "    cvae = Model(input, output, name='cvae')\n",
        "\n",
        "    return cvae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9c4wxcgv8ck"
      },
      "source": [
        "# Reparamaterization Trick\n",
        "# z = z_mean + sqrt(var)*eps\n",
        "def sampling(args):\n",
        "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
        "    # Arguments:\n",
        "        args (tensor): mean and log of variance of Q(z|X)\n",
        "    # Returns:\n",
        "        z (tensor): sampled latent vector\n",
        "    \"\"\"\n",
        "    z_mean, z_log_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    # by default, random_normal has mean=0 and std=1.0\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k58jQ7bov8ci"
      },
      "source": [
        "#Comparable Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4phvCkiGv8cl"
      },
      "source": [
        "## Convolutional Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T8CjuUmv8cl"
      },
      "source": [
        "def cae_1(x_train, y_train, x_val, x_test, y_test, epochs, batch_size, learning_rate, input_side, n_channels, latent_dim, filter_size, batch_norm = False):\n",
        "\n",
        "  encoder = conv_encoder(input_side=image_shape[0], n_channels=image_shape[2], representation_dim=latent_dim, filter_size = filter_size, batch_norm = batch_norm)\n",
        "  decoder = conv_decoder(output_side=image_shape[0], n_channels=image_shape[2], representation_dim=latent_dim, filter_size = filter_size, batch_norm = batch_norm)\n",
        "  cae = convolutional_autoencoder(encoder, decoder) \n",
        "\n",
        "  #encoder.summary()\n",
        "  #decoder.summary() \n",
        "\n",
        "  recon_error = reconstruction_error(cae)\n",
        "\n",
        "  cae.add_loss(recon_error)\n",
        "  adam = optimizers.Adam(lr=learning_rate)\n",
        "  cae.compile(optimizer=adam)\n",
        "\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', patience = 20, verbose=1)\n",
        "\n",
        "  history = cae.fit(x_train,\n",
        "                  epochs=epochs,\n",
        "                  batch_size=batch_size,\n",
        "                  validation_data=(x_val, None),\n",
        "                  callbacks=[es],\n",
        "                  verbose=0)\n",
        "  \n",
        "  rec_results = per_example_reconstruction_error(cae, x_test)\n",
        "\n",
        "  pr_auc_rec_result = pr_auc(y_test, rec_results)\n",
        "  roc_auc_rec_result = roc_auc(y_test, rec_results)\n",
        "\n",
        "  return pr_auc_rec_result, roc_auc_rec_result, pr_auc_rec_result, roc_auc_rec_result, pr_auc_rec_result, roc_auc_rec_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LxR44S4v8cn"
      },
      "source": [
        "## PCA (via SVD)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFQudufmv8cn"
      },
      "source": [
        "def pca_1(x_train, y_train, x_val, x_test, y_test, input_side, n_channels, latent_dim):\n",
        "\n",
        "    pca = PCA(n_components=latent_dim, svd_solver='full')\n",
        "\n",
        "    pca.fit(flatten_data(x_train))\n",
        "    encoded = pca.transform(flatten_data(x_test))\n",
        "    recon = pca.inverse_transform(encoded)\n",
        "\n",
        "    recon_error = mse(flatten_data(x_test), recon)\n",
        "    recon_error *= original_dim\n",
        "    recon_error = tf.Session().run(recon_error)\n",
        "\n",
        "    pr_auc_result = pr_auc(y_test, recon_error)\n",
        "    roc_auc_result = roc_auc(y_test, recon_error)\n",
        "\n",
        "    return pr_auc_result, roc_auc_result, pr_auc_result, roc_auc_result, pr_auc_result, roc_auc_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnTUn4Y0v8cn"
      },
      "source": [
        "## KernalPCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5sOtCQzv8co"
      },
      "source": [
        "def kpca_1(x_train, y_train, x_val, x_test, y_test, input_side, n_channels, latent_dim):\n",
        "\n",
        "    kpca = KernelPCA(n_components=latent_dim, kernel='rbf', fit_inverse_transform=\"True\")\n",
        "\n",
        "    kpca.fit(flatten_data(x_train))\n",
        "    encoded = kpca.transform(flatten_data(x_test))\n",
        "    recon = kpca.inverse_transform(encoded)\n",
        "\n",
        "    recon_error = mse(flatten_data(x_test), recon)\n",
        "    recon_error *= original_dim\n",
        "    recon_error = tf.Session().run(recon_error)\n",
        "\n",
        "    pr_auc_result = pr_auc(y_test, recon_error)\n",
        "    roc_auc_result = roc_auc(y_test, recon_error)\n",
        "\n",
        "    return pr_auc_result, roc_auc_result, pr_auc_result, roc_auc_result, pr_auc_result, roc_auc_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzN5hz2zv8co"
      },
      "source": [
        "## Deep Structured Energy Based Anomaly Detection (DSEBM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuevRaI2v8co"
      },
      "source": [
        "# From the following implementation: https://github.com/izikgo/AnomalyDetectionTransformations/blob/master/models/dsebm.py\n",
        "# Licensed under the MIT License\n",
        "class Prior(Layer):\n",
        "    def __init__(self,\n",
        "                 bias_initializer='zeros',\n",
        "                 bias_regularizer=None,\n",
        "                 bias_constraint=None,\n",
        "                 **kwargs):\n",
        "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
        "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
        "        super(Prior, self).__init__(**kwargs)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "        self.input_spec = InputSpec(min_ndim=2)\n",
        "        self.bias = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.bias = self.add_weight(shape=input_shape[1:],\n",
        "                                    initializer=self.bias_initializer,\n",
        "                                    name='bias',\n",
        "                                    regularizer=self.bias_regularizer,\n",
        "                                    constraint=self.bias_constraint)\n",
        "        super(Prior, self).build(input_shape)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], 1\n",
        "\n",
        "    def call(self, x, **kwargs):\n",
        "        return K.sum(K.batch_flatten(K.square(K.bias_add(x, -self.bias))), axis=-1, keepdims=True)\n",
        "\n",
        "\n",
        "def create_energy_model(encoder_mdl):\n",
        "    x_in = Input(batch_shape=encoder_mdl.input_shape)\n",
        "\n",
        "    encoded = encoder_mdl(x_in)\n",
        "    prior = Prior()(x_in)\n",
        "    energy = Lambda(lambda args: 0.5*args[0] - K.sum(K.batch_flatten(args[1]), axis=-1, keepdims=True),\n",
        "                    output_shape=(1,))([prior, encoded])\n",
        "    return Model(x_in, energy)\n",
        "\n",
        "\n",
        "def create_reconstruction_model(energy_mdl):\n",
        "    x_in = Input(batch_shape=energy_mdl.input_shape)\n",
        "    x = GaussianNoise(stddev=.5)(x_in)  # only active in training\n",
        "    energy = energy_mdl(x)\n",
        "    rec = Lambda(lambda args: args[1] - K.gradients(args[0], args[1]),\n",
        "                 output_shape=energy_mdl.input_shape[1:])([energy, x])\n",
        "\n",
        "    return Model(x_in, rec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q5-xD8RlNdy"
      },
      "source": [
        "def dsebm_1(x_train, y_train, x_val, x_test, y_test, epochs, batch_size, learning_rate, input_side, n_channels, latent_dim, filter_size):\n",
        "  \n",
        "  encoder_mdl = conv_encoder(input_side=image_shape[0], n_channels=image_shape[2], representation_dim=latent_dim, filter_size=filter_size)\n",
        "  energy_mdl = create_energy_model(encoder_mdl)\n",
        "  reconstruction_mdl = create_reconstruction_model(energy_mdl)\n",
        "\n",
        "  adam = optimizers.Adam(lr=learning_rate)\n",
        "  reconstruction_mdl.compile(optimizer=adam, loss=\"mse\")\n",
        "\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', patience = 20, verbose=1)\n",
        "\n",
        "  history = reconstruction_mdl.fit(x=x_train, y=x_train, \n",
        "                  epochs=epochs,\n",
        "                  batch_size=batch_size,\n",
        "                  validation_data=(x_val, x_val),\n",
        "                  callbacks=[es],\n",
        "                  verbose=0)\n",
        "  \n",
        "  scores = -energy_mdl.predict(x_test, batch_size)\n",
        "\n",
        "  pr_auc_result = pr_auc(y_test, -scores)\n",
        "  roc_auc_result = roc_auc(y_test, -scores)\n",
        "\n",
        "  return pr_auc_result, roc_auc_result, pr_auc_result, roc_auc_result, pr_auc_result, roc_auc_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmRR7TMZmzRE"
      },
      "source": [
        "# ED-VAE and VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CgCYNSDmzRF"
      },
      "source": [
        "def edvae_vae_comparison(x_train, y_train, x_val, x_test, y_test, epochs, batch_size, learning_rate, input_side, n_channels, latent_dim, filter_size, batch_norm=False, beta = 1.0):\n",
        "\n",
        "  encoder = cvae_encoder(input_side=image_shape[0], n_channels=image_shape[2], representation_dim=latent_dim, filter_size = filter_size, batch_norm = batch_norm)\n",
        "  decoder = cvae_decoder(output_side=image_shape[0], n_channels=image_shape[2], representation_dim=latent_dim, filter_size = filter_size, batch_norm = batch_norm)\n",
        "  cae = convolutional_variational_autoencoder(encoder, decoder) \n",
        "\n",
        "  #encoder.summary()\n",
        "  #decoder.summary() \n",
        "\n",
        "  recon_error = reconstruction_error(cae)\n",
        "  kl = kl_divergence(encoder)\n",
        "  loss = beta * kl + recon_error\n",
        "\n",
        "  cae.add_loss(loss)\n",
        "  \n",
        "  adam = optimizers.Adam(lr=learning_rate)\n",
        "  cae.compile(optimizer=adam)\n",
        "\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', patience = 20, verbose=1)\n",
        "\n",
        "  history = cae.fit(x_train,\n",
        "                  epochs=epochs,\n",
        "                  batch_size=batch_size,\n",
        "                  validation_data=(x_val, None),\n",
        "                  callbacks=[es],\n",
        "                  verbose=0)\n",
        "  \n",
        "  # vae results \n",
        "  kl_results = per_example_kl_divergence(encoder, x_test)\n",
        "  rec_results = per_example_reconstruction_error(cae, x_test)\n",
        "  elbo_results = beta * kl_results + rec_results\n",
        "\n",
        "  pr_auc_rec_result = pr_auc(y_test, rec_results)\n",
        "  roc_auc_rec_result = roc_auc(y_test, rec_results)\n",
        "\n",
        "  pr_auc_elbo_result = pr_auc(y_test, elbo_results)\n",
        "  roc_auc_elbo_result = roc_auc(y_test, elbo_results)\n",
        "\n",
        "  pr_auc_kl_result = pr_auc(y_test, kl_results)\n",
        "  roc_auc_kl_result = roc_auc(y_test, kl_results) \n",
        "    \n",
        "  # ed-vae results\n",
        "  kl_results = per_example_kl_divergence(encoder, x_test)\n",
        "  rec_results = per_example_elr_reconstruction_error(encoder, decoder, x_test)\n",
        "  elbo_results = beta * kl_results + rec_results\n",
        "\n",
        "  elr_pr_auc_rec_result = pr_auc(y_test, rec_results)\n",
        "  elr_roc_auc_rec_result = roc_auc(y_test, rec_results)\n",
        "\n",
        "  elr_pr_auc_elbo_result = pr_auc(y_test, elbo_results)\n",
        "  elr_roc_auc_elbo_result = roc_auc(y_test, elbo_results)\n",
        "\n",
        "  elr_pr_auc_kl_result = pr_auc(y_test, kl_results )\n",
        "  elr_roc_auc_kl_result = roc_auc(y_test, kl_results )\n",
        "\n",
        "  return np.array([[pr_auc_rec_result, roc_auc_rec_result, pr_auc_elbo_result, roc_auc_elbo_result, pr_auc_kl_result, roc_auc_kl_result],\n",
        "                   [elr_pr_auc_rec_result, elr_roc_auc_rec_result, elr_pr_auc_elbo_result, elr_roc_auc_elbo_result, elr_pr_auc_kl_result, elr_roc_auc_kl_result]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVzUrWfJn0b-"
      },
      "source": [
        "# Data Preperation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtIp8y44wXXB"
      },
      "source": [
        "def load_mnist():\n",
        "\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "  x_train = x_train.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
        "  x_test = x_test.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
        "\n",
        "  #print('x_train shape:', x_train.shape)\n",
        "  #print(x_train.shape[0], 'train samples')\n",
        "  #print(x_test.shape[0], 'test samples')\n",
        "\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHNv17T-0KUO"
      },
      "source": [
        "def load_fashion_mnist():\n",
        "\n",
        "  (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "  x_train =  x_train.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
        "  x_test = x_test.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
        "\n",
        "  #print('x_train shape:', x_train.shape)\n",
        "  #print(x_train.shape[0], 'train samples')\n",
        "  #print(x_test.shape[0], 'test samples')\n",
        "\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cJ8bRAIGFjx"
      },
      "source": [
        "# create training set without anomalies and test set with a ratio p of anomalies. E.g. p = 0.2 \n",
        "# creates a test set where 20% of the test set are anomalies\n",
        "def create_data(X_train, Y_train, X_test, Y_test, normal_class, p = .1):\n",
        "\n",
        "    X_norm_train_filter = np.where(np.isin(Y_train, normal_class))\n",
        "    X_norm_test_filter = np.where(np.isin(Y_test, normal_class))\n",
        "    X_anom_test_filter = np.where(np.isin(Y_test, normal_class, invert = True))\n",
        "\n",
        "    # a = (# of normal instances)/(1 - ratio of outliers)) * ratio of outliers\n",
        "    # e.g. if p = .2 20% of the test set is anomalies\n",
        "    a = math.floor(((len(X_norm_test_filter[0]))/(1-p))*p)\n",
        "\n",
        "    X_anom_test_filter = (np.random.choice(X_anom_test_filter[0], a, replace=False),)\n",
        "    X_test_filter = (np.concatenate((X_norm_test_filter[0], X_anom_test_filter[0]), axis=None),)\n",
        "\n",
        "    X_train, Y_train = X_train[X_norm_train_filter[0]], Y_train[X_norm_train_filter]\n",
        "    X_test_norm, Y_test_norm = X_test[X_norm_test_filter[0]], Y_test[X_norm_test_filter]\n",
        "    Y_test_class_labels = Y_test[X_test_filter]\n",
        "    X_test, Y_test, = X_test[X_test_filter[0]], Y_test[X_test_filter]\n",
        "\n",
        "    Y_test[np.isin(Y_test_class_labels, normal_class)] = 0\n",
        "    Y_test[np.isin(Y_test_class_labels, normal_class, invert = True)] = 1\n",
        "    \n",
        "    return X_train, Y_train, X_test, Y_test, Y_test_class_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08AoBB68n-Sq"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNZQXGB0HTwt"
      },
      "source": [
        "image_shape = (28, 28, 1)\n",
        "original_dim = image_shape[0] * image_shape[1] * image_shape[2]\n",
        "input_shape = image_shape\n",
        "batch_size = 128\n",
        "latent_dim = 32\n",
        "beta = 1.0\n",
        "epochs = 1000\n",
        "learning_rate = 0.0001\n",
        "activation = 'relu'\n",
        "filter_size = 32\n",
        "p = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_tUDUIpn4aZ"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lmO4TbIFZia"
      },
      "source": [
        "normal_classes = np.arange(0,10)\n",
        "num_models = 6\n",
        "num_measures = 6\n",
        "reps = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5BptUPsqeqP"
      },
      "source": [
        "def models(x_train, y_train, x_val, x_test, y_test):\n",
        "\n",
        "  pca_1_results = pca_1(x_train, y_train, x_val, x_test, y_test, image_shape[0], image_shape[2], latent_dim)\n",
        "  kpca_1_results = kpca_1(x_train, y_train, x_val, x_test, y_test, image_shape[0], image_shape[2], latent_dim)\n",
        "  dsebm_1_results = dsebm_1(x_train, y_train, x_val, x_test, y_test, epochs, batch_size, learning_rate, image_shape[0], image_shape[2], latent_dim, filter_size)\n",
        "  cae_1_results = cae_1(x_train, y_train, x_val, x_test, y_test, epochs, batch_size, learning_rate, image_shape[0], image_shape[2], latent_dim, filter_size, batch_norm=False)\n",
        "  edvae_vae_comparison_results = edvae_vae_comparison(x_train, y_train, x_val, x_test, y_test, epochs, batch_size, learning_rate, image_shape[0], image_shape[2], latent_dim, filter_size, beta = beta)\n",
        "  \n",
        "  return pca_1_results, kpca_1_results, dsebm_1_results, cae_1_results, edvae_vae_comparison_results[0], edvae_vae_comparison_results[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep-pTu2z7GMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd7cf67-41cc-4f4f-dc79-82b132d93697"
      },
      "source": [
        "results = np.zeros((reps, len(normal_classes), num_models, num_measures))\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for rep in tqdm(range(reps), desc=\"reps\"):\n",
        "  for normal in tqdm(range(len(normal_classes)), desc=\"anomaly\"):\n",
        "    x_train, y_train, x_test, y_test = load_fashion_mnist()\n",
        "    x_train, y_train, x_test, y_test, y_test_class_labels = create_data(x_train, y_train, x_test, y_test, normal_classes[normal], p = p)\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
        "    results[rep, normal] = models(x_train, y_train, x_val, x_test, y_test)\n",
        "    tf.keras.backend.clear_session() #release gpu memory"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reps:   0%|          | 0/10 [00:00<?, ?it/s]\n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 00205: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00232: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00384: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [03:29<31:27, 209.77s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00046: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00816: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00383: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [08:10<30:49, 231.16s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00222: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00194: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00313: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [11:08<25:06, 215.22s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00231: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00289: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [16:47<25:13, 252.26s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00246: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00274: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [22:26<23:11, 278.35s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00225: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00197: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00369: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [25:39<16:51, 252.76s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00229: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00279: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00319: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [28:59<11:50, 236.73s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00217: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00235: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00343: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [32:11<07:26, 223.48s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00204: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00102: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00453: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [35:20<03:33, 213.03s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00235: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00268: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [40:53<00:00, 245.37s/it]\n",
            "reps:  10%|█         | 1/10 [40:53<6:08:03, 2453.70s/it]\n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00222: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00292: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [05:38<50:43, 338.20s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00037: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00318: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00304: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [08:16<37:53, 284.22s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00227: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00296: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00306: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [11:35<30:09, 258.55s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00222: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00257: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00335: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [14:51<23:59, 239.95s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00282: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00303: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [20:43<22:47, 273.45s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00144: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00199: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00361: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [23:38<16:15, 243.88s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00227: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00268: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00314: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [26:53<11:27, 229.29s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00155: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00216: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00255: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [29:28<06:54, 207.01s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00261: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00416: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [35:50<04:19, 259.60s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00243: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00430: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [42:14<00:00, 253.50s/it]\n",
            "reps:  20%|██        | 2/10 [1:23:08<5:30:24, 2478.09s/it]\n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00224: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00338: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [05:57<53:38, 357.63s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00058: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00243: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00329: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [08:36<39:42, 297.86s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00246: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00375: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [14:48<37:20, 320.12s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00228: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00379: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [20:56<33:27, 334.51s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00257: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00280: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00377: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [24:39<25:05, 301.11s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00130: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00168: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00262: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [27:04<16:56, 254.21s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00196: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00221: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00348: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [30:16<11:46, 235.51s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00203: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00199: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00251: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [33:02<07:09, 214.79s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00227: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00177: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00298: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [35:59<03:23, 203.61s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00231: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00271: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [41:48<00:00, 250.80s/it]\n",
            "reps:  30%|███       | 3/10 [2:04:56<4:50:09, 2487.08s/it]\n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00212: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00315: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [05:50<52:30, 350.04s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00190: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00271: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00284: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [08:54<40:02, 300.27s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00220: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00186: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00273: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [11:47<30:35, 262.23s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00252: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00309: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00292: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [15:16<24:38, 246.34s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00224: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00442: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [21:37<23:52, 286.58s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00115: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00218: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00339: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [24:28<16:48, 252.09s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00239: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00185: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00348: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [27:43<11:44, 234.91s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00050: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00235: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00296: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [30:12<06:57, 208.94s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00158: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00208: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00390: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [33:22<03:23, 203.40s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00236: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00165: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00307: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [36:27<00:00, 218.72s/it]\n",
            "reps:  40%|████      | 4/10 [2:41:23<3:59:42, 2397.11s/it]\n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00211: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00280: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00362: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [03:34<32:08, 214.26s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00041: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00199: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00445: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [06:28<26:57, 202.16s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00212: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00276: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [12:11<28:31, 244.56s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00230: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00358: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00377: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [16:04<24:06, 241.05s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00251: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00286: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [21:51<22:44, 272.85s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00108: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00201: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00369: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [24:43<16:09, 242.44s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00238: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00168: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00295: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [27:39<11:08, 222.72s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00307: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00204: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00364: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [31:19<07:23, 221.84s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00164: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00145: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00240: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [33:43<03:18, 198.48s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00244: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00146: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00270: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [36:33<00:00, 219.33s/it]\n",
            "reps:  50%|█████     | 5/10 [3:17:57<3:14:39, 2335.96s/it]\n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00168: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00294: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00227: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [02:51<25:44, 171.66s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00065: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00267: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00344: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [05:41<22:50, 171.25s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00239: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00198: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00282: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [08:43<20:19, 174.28s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00249: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00233: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00410: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [12:22<18:47, 187.88s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00227: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00323: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [18:22<19:57, 239.49s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00170: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00179: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00268: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [21:02<14:22, 215.57s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00230: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00168: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00248: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [23:50<10:03, 201.14s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00185: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00233: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00314: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [26:56<06:33, 196.73s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00238: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00363: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [33:06<04:08, 248.80s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00248: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00256: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00382: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [36:47<00:00, 220.76s/it]\n",
            "reps:  60%|██████    | 6/10 [3:54:44<2:33:09, 2297.46s/it]\n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00235: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00210: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00330: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [03:14<29:11, 194.60s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00199: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00257: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [08:48<31:30, 236.25s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00216: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00299: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00236: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [11:55<25:50, 221.55s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00231: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00292: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [17:43<25:58, 259.69s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00241: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00416: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [24:05<24:41, 296.26s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00141: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00210: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00390: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [27:11<17:32, 263.10s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00222: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00176: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00416: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [30:37<12:18, 246.09s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00177: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00268: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00235: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [33:28<07:27, 223.51s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00183: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00170: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00493: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [37:02<03:40, 220.70s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00246: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00367: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [43:10<00:00, 259.06s/it]\n",
            "reps:  70%|███████   | 7/10 [4:37:55<1:59:16, 2385.41s/it]\n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00208: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00191: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00298: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [02:55<26:19, 175.55s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00074: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00284: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [08:04<28:45, 215.69s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00202: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00206: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00305: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [11:05<23:55, 205.03s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00242: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00175: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00304: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [14:06<19:47, 197.93s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00266: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00328: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [20:09<20:37, 247.56s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00182: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00164: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00309: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [22:57<14:54, 223.63s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00199: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00204: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00380: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [26:12<10:45, 215.07s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00173: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00280: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00289: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [29:16<06:51, 205.65s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00214: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00260: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00287: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [32:25<03:20, 200.63s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00189: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00162: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00287: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [35:07<00:00, 210.80s/it]\n",
            "reps:  80%|████████  | 8/10 [5:13:03<1:16:44, 2302.18s/it]\n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00196: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00317: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [05:47<52:05, 347.28s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00040: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00370: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00412: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [09:08<40:27, 303.39s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00219: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00328: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [15:04<37:14, 319.17s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00207: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00310: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00282: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [18:20<28:14, 282.36s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00233: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00264: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [24:03<25:03, 300.61s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00104: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00236: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00274: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [26:40<17:09, 257.43s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00173: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00213: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00234: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [29:18<11:23, 227.67s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00038: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00190: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00333: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [31:42<06:44, 202.50s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00180: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00177: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00328: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [34:37<03:14, 194.10s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00229: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00315: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [40:30<00:00, 243.09s/it]\n",
            "reps:  90%|█████████ | 9/10 [5:53:34<39:00, 2340.79s/it]  \n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00208: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00183: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00364: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [03:09<28:28, 189.85s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00239: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00217: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [08:40<30:55, 231.97s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00225: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00277: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [14:23<30:56, 265.27s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00252: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00366: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00336: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [18:13<25:29, 254.92s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00242: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00305: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [24:06<23:41, 284.23s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00080: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00213: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00331: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [26:46<16:27, 246.85s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00202: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00339: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [32:41<13:58, 279.44s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00186: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00259: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00423: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [36:17<08:40, 260.50s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00218: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00905: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00338: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [41:54<04:43, 283.32s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00227: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00321: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [47:45<00:00, 286.59s/it]\n",
            "reps: 100%|██████████| 10/10 [6:41:20<00:00, 2408.02s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNIiuLGQvLSb"
      },
      "source": [
        "# Results - ED-VAE vs. Comparable Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9U7oiHrfKCe"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRz6rJQvbYfE"
      },
      "source": [
        "index_labels = normal_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6C3oarV5luz"
      },
      "source": [
        "avg_results = np.mean(results, axis=0)\n",
        "std_results = np.std(results, axis=0)\n",
        "avg_class_results = np.mean(results, axis=(0, 1))\n",
        "std_class_results = np.std(results, axis=(0, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYqOKCHdRiBl"
      },
      "source": [
        "pr_header = [np.array(['pca','pca',\n",
        "                    'kpca','kpca',\n",
        "                    'dsebm','dsebm',\n",
        "                    'ae','ae',\n",
        "                    'vae', 'vae',             \n",
        "                    'ed-vae', 'ed-vae',\n",
        "                    ]), \n",
        "np.array(['pr_auc_mean','pr_auc_std',\n",
        "          'pr_auc_mean','pr_auc_std',\n",
        "          'pr_auc_mean','pr_auc_std',\n",
        "          'pr_auc_mean','pr_auc_std',\n",
        "          'pr_auc_mean','pr_auc_std',\n",
        "          'pr_auc_mean','pr_auc_std',\n",
        "          ])] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2kKWVNYTPHo"
      },
      "source": [
        "auc_header = [np.array(['pca','pca',\n",
        "                    'kpca','kpca',\n",
        "                    'dsebm','dsebm',\n",
        "                    'ae','ae',\n",
        "                    'vae', 'vae',             \n",
        "                    'ed-vae', 'ed-vae',\n",
        "                    ]), \n",
        "np.array(['auc_mean','auc_std',\n",
        "          'auc_mean','auc_std',\n",
        "          'auc_mean','auc_std',\n",
        "          'auc_mean','auc_std',\n",
        "          'auc_mean','auc_std',\n",
        "          'auc_mean','auc_std',\n",
        "          ])] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtMsETaBRYPH"
      },
      "source": [
        "## $ELBO$ \n",
        "Compare ELBO of VAE and ED-VAE to results of competitive models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkpQ6aLEUIP9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "cf5d86e0-e480-4d9a-d377-811a565e4eb4"
      },
      "source": [
        "# AUC\n",
        "avg_auc_elbo_class_results = pd.DataFrame((avg_class_results[0,3], std_class_results[0,3], \n",
        "                                  avg_class_results[1,3], std_class_results[1,3],\n",
        "                                  avg_class_results[2,3], std_class_results[2,3],  \n",
        "                                  avg_class_results[3,3], std_class_results[3,3], \n",
        "                                  avg_class_results[4,3], std_class_results[4,3], \n",
        "                                  avg_class_results[5,3], std_class_results[5,3], \n",
        "                                  ), \n",
        "                                  index = auc_header).T\n",
        "avg_auc_elbo_class_results = avg_auc_elbo_class_results.rename(index={0: \"mean\"})\n",
        "avg_auc_elbo_final_results = pd.DataFrame((avg_results[:,0,3], std_results[:,0,3],\n",
        "                                  avg_results[:,1,3], std_results[:,1,3], \n",
        "                                  avg_results[:,2,3], std_results[:,2,3], \n",
        "                                  avg_results[:,3,3], std_results[:,3,3], \n",
        "                                  avg_results[:,4,3], std_results[:,4,3],  \n",
        "                                  avg_results[:,5,3], std_results[:,5,3], \n",
        "                                  ), \n",
        "                                  index = auc_header, columns = index_labels).T\n",
        "avg_auc_elbo_final_results.append(avg_auc_elbo_class_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">pca</th>\n",
              "      <th colspan=\"2\" halign=\"left\">kpca</th>\n",
              "      <th colspan=\"2\" halign=\"left\">dsebm</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">vae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ed-vae</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.898339</td>\n",
              "      <td>0.005398</td>\n",
              "      <td>0.906345</td>\n",
              "      <td>0.006592</td>\n",
              "      <td>0.872652</td>\n",
              "      <td>0.019989</td>\n",
              "      <td>0.896966</td>\n",
              "      <td>0.012320</td>\n",
              "      <td>0.906740</td>\n",
              "      <td>0.007390</td>\n",
              "      <td>0.911173</td>\n",
              "      <td>0.007674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.985436</td>\n",
              "      <td>0.001879</td>\n",
              "      <td>0.982097</td>\n",
              "      <td>0.002359</td>\n",
              "      <td>0.784110</td>\n",
              "      <td>0.134305</td>\n",
              "      <td>0.979720</td>\n",
              "      <td>0.006758</td>\n",
              "      <td>0.985576</td>\n",
              "      <td>0.002004</td>\n",
              "      <td>0.987114</td>\n",
              "      <td>0.001906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.887165</td>\n",
              "      <td>0.008119</td>\n",
              "      <td>0.890545</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.833402</td>\n",
              "      <td>0.013873</td>\n",
              "      <td>0.866617</td>\n",
              "      <td>0.013023</td>\n",
              "      <td>0.884042</td>\n",
              "      <td>0.007990</td>\n",
              "      <td>0.891146</td>\n",
              "      <td>0.007604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.919152</td>\n",
              "      <td>0.007362</td>\n",
              "      <td>0.925635</td>\n",
              "      <td>0.011317</td>\n",
              "      <td>0.913408</td>\n",
              "      <td>0.015568</td>\n",
              "      <td>0.905385</td>\n",
              "      <td>0.015106</td>\n",
              "      <td>0.924055</td>\n",
              "      <td>0.009302</td>\n",
              "      <td>0.927871</td>\n",
              "      <td>0.008745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.885009</td>\n",
              "      <td>0.013492</td>\n",
              "      <td>0.884886</td>\n",
              "      <td>0.014163</td>\n",
              "      <td>0.875427</td>\n",
              "      <td>0.019237</td>\n",
              "      <td>0.887289</td>\n",
              "      <td>0.009809</td>\n",
              "      <td>0.899538</td>\n",
              "      <td>0.013268</td>\n",
              "      <td>0.908718</td>\n",
              "      <td>0.013040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.886346</td>\n",
              "      <td>0.009993</td>\n",
              "      <td>0.888076</td>\n",
              "      <td>0.008158</td>\n",
              "      <td>0.872494</td>\n",
              "      <td>0.008884</td>\n",
              "      <td>0.876394</td>\n",
              "      <td>0.006077</td>\n",
              "      <td>0.893064</td>\n",
              "      <td>0.008791</td>\n",
              "      <td>0.895072</td>\n",
              "      <td>0.007228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.813194</td>\n",
              "      <td>0.012386</td>\n",
              "      <td>0.821431</td>\n",
              "      <td>0.009973</td>\n",
              "      <td>0.756203</td>\n",
              "      <td>0.019512</td>\n",
              "      <td>0.776370</td>\n",
              "      <td>0.017384</td>\n",
              "      <td>0.823253</td>\n",
              "      <td>0.012089</td>\n",
              "      <td>0.830588</td>\n",
              "      <td>0.011563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.984449</td>\n",
              "      <td>0.002424</td>\n",
              "      <td>0.983995</td>\n",
              "      <td>0.002469</td>\n",
              "      <td>0.953105</td>\n",
              "      <td>0.057234</td>\n",
              "      <td>0.980500</td>\n",
              "      <td>0.002904</td>\n",
              "      <td>0.982244</td>\n",
              "      <td>0.003357</td>\n",
              "      <td>0.985006</td>\n",
              "      <td>0.002306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.836911</td>\n",
              "      <td>0.006764</td>\n",
              "      <td>0.839565</td>\n",
              "      <td>0.008515</td>\n",
              "      <td>0.795964</td>\n",
              "      <td>0.035885</td>\n",
              "      <td>0.821306</td>\n",
              "      <td>0.023230</td>\n",
              "      <td>0.835084</td>\n",
              "      <td>0.011485</td>\n",
              "      <td>0.848064</td>\n",
              "      <td>0.012047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.970721</td>\n",
              "      <td>0.007420</td>\n",
              "      <td>0.966373</td>\n",
              "      <td>0.006154</td>\n",
              "      <td>0.972514</td>\n",
              "      <td>0.006888</td>\n",
              "      <td>0.971163</td>\n",
              "      <td>0.007767</td>\n",
              "      <td>0.963205</td>\n",
              "      <td>0.007989</td>\n",
              "      <td>0.970858</td>\n",
              "      <td>0.006165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.906672</td>\n",
              "      <td>0.056695</td>\n",
              "      <td>0.908895</td>\n",
              "      <td>0.053946</td>\n",
              "      <td>0.862928</td>\n",
              "      <td>0.083847</td>\n",
              "      <td>0.896171</td>\n",
              "      <td>0.065376</td>\n",
              "      <td>0.909680</td>\n",
              "      <td>0.053844</td>\n",
              "      <td>0.915561</td>\n",
              "      <td>0.051721</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           pca                kpca               dsebm                  ae  \\\n",
              "      auc_mean   auc_std  auc_mean   auc_std  auc_mean   auc_std  auc_mean   \n",
              "0     0.898339  0.005398  0.906345  0.006592  0.872652  0.019989  0.896966   \n",
              "1     0.985436  0.001879  0.982097  0.002359  0.784110  0.134305  0.979720   \n",
              "2     0.887165  0.008119  0.890545  0.007060  0.833402  0.013873  0.866617   \n",
              "3     0.919152  0.007362  0.925635  0.011317  0.913408  0.015568  0.905385   \n",
              "4     0.885009  0.013492  0.884886  0.014163  0.875427  0.019237  0.887289   \n",
              "5     0.886346  0.009993  0.888076  0.008158  0.872494  0.008884  0.876394   \n",
              "6     0.813194  0.012386  0.821431  0.009973  0.756203  0.019512  0.776370   \n",
              "7     0.984449  0.002424  0.983995  0.002469  0.953105  0.057234  0.980500   \n",
              "8     0.836911  0.006764  0.839565  0.008515  0.795964  0.035885  0.821306   \n",
              "9     0.970721  0.007420  0.966373  0.006154  0.972514  0.006888  0.971163   \n",
              "mean  0.906672  0.056695  0.908895  0.053946  0.862928  0.083847  0.896171   \n",
              "\n",
              "                     vae              ed-vae            \n",
              "       auc_std  auc_mean   auc_std  auc_mean   auc_std  \n",
              "0     0.012320  0.906740  0.007390  0.911173  0.007674  \n",
              "1     0.006758  0.985576  0.002004  0.987114  0.001906  \n",
              "2     0.013023  0.884042  0.007990  0.891146  0.007604  \n",
              "3     0.015106  0.924055  0.009302  0.927871  0.008745  \n",
              "4     0.009809  0.899538  0.013268  0.908718  0.013040  \n",
              "5     0.006077  0.893064  0.008791  0.895072  0.007228  \n",
              "6     0.017384  0.823253  0.012089  0.830588  0.011563  \n",
              "7     0.002904  0.982244  0.003357  0.985006  0.002306  \n",
              "8     0.023230  0.835084  0.011485  0.848064  0.012047  \n",
              "9     0.007767  0.963205  0.007989  0.970858  0.006165  \n",
              "mean  0.065376  0.909680  0.053844  0.915561  0.051721  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLcLg1j-Rots",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "5815daa2-d78f-42ef-ee0e-f0373cbfcf0c"
      },
      "source": [
        "# PR-AUC\n",
        "avg_pr_elbo_class_results = pd.DataFrame((avg_class_results[0,2], std_class_results[0,2], \n",
        "                                  avg_class_results[1,2], std_class_results[1,2],\n",
        "                                  avg_class_results[2,2], std_class_results[2,2],  \n",
        "                                  avg_class_results[3,2], std_class_results[3,2], \n",
        "                                  avg_class_results[4,2], std_class_results[4,2], \n",
        "                                  avg_class_results[5,2], std_class_results[5,2], \n",
        "                                  ), \n",
        "                                  index = pr_header).T\n",
        "avg_pr_elbo_class_results = avg_pr_elbo_class_results.rename(index={0: \"mean\"})\n",
        "avg_pr_elbo_final_results = pd.DataFrame((avg_results[:,0,2], std_results[:,0,2],\n",
        "                                  avg_results[:,1,2], std_results[:,1,2], \n",
        "                                  avg_results[:,2,2], std_results[:,2,2], \n",
        "                                  avg_results[:,3,2], std_results[:,3,2], \n",
        "                                  avg_results[:,4,2], std_results[:,4,2],  \n",
        "                                  avg_results[:,5,2], std_results[:,5,2], \n",
        "                                  ), \n",
        "                                  index = pr_header, columns = index_labels).T\n",
        "avg_pr_elbo_final_results.append(avg_pr_elbo_class_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">pca</th>\n",
              "      <th colspan=\"2\" halign=\"left\">kpca</th>\n",
              "      <th colspan=\"2\" halign=\"left\">dsebm</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">vae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ed-vae</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.698673</td>\n",
              "      <td>0.013300</td>\n",
              "      <td>0.730707</td>\n",
              "      <td>0.014845</td>\n",
              "      <td>0.674400</td>\n",
              "      <td>0.038337</td>\n",
              "      <td>0.711722</td>\n",
              "      <td>0.015720</td>\n",
              "      <td>0.722367</td>\n",
              "      <td>0.016622</td>\n",
              "      <td>0.721989</td>\n",
              "      <td>0.018962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.940467</td>\n",
              "      <td>0.006721</td>\n",
              "      <td>0.933861</td>\n",
              "      <td>0.007438</td>\n",
              "      <td>0.638965</td>\n",
              "      <td>0.167223</td>\n",
              "      <td>0.919310</td>\n",
              "      <td>0.021887</td>\n",
              "      <td>0.944248</td>\n",
              "      <td>0.007205</td>\n",
              "      <td>0.947529</td>\n",
              "      <td>0.007014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.708055</td>\n",
              "      <td>0.012931</td>\n",
              "      <td>0.751151</td>\n",
              "      <td>0.009973</td>\n",
              "      <td>0.624861</td>\n",
              "      <td>0.022804</td>\n",
              "      <td>0.694003</td>\n",
              "      <td>0.030495</td>\n",
              "      <td>0.741947</td>\n",
              "      <td>0.010923</td>\n",
              "      <td>0.749466</td>\n",
              "      <td>0.012310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.792979</td>\n",
              "      <td>0.018098</td>\n",
              "      <td>0.828515</td>\n",
              "      <td>0.020055</td>\n",
              "      <td>0.816480</td>\n",
              "      <td>0.021882</td>\n",
              "      <td>0.802410</td>\n",
              "      <td>0.025692</td>\n",
              "      <td>0.824475</td>\n",
              "      <td>0.018503</td>\n",
              "      <td>0.828265</td>\n",
              "      <td>0.018536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.762130</td>\n",
              "      <td>0.016841</td>\n",
              "      <td>0.763155</td>\n",
              "      <td>0.017801</td>\n",
              "      <td>0.711659</td>\n",
              "      <td>0.050418</td>\n",
              "      <td>0.740442</td>\n",
              "      <td>0.015772</td>\n",
              "      <td>0.786449</td>\n",
              "      <td>0.018267</td>\n",
              "      <td>0.799682</td>\n",
              "      <td>0.017247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.825434</td>\n",
              "      <td>0.009205</td>\n",
              "      <td>0.811392</td>\n",
              "      <td>0.007588</td>\n",
              "      <td>0.766110</td>\n",
              "      <td>0.016099</td>\n",
              "      <td>0.763120</td>\n",
              "      <td>0.008826</td>\n",
              "      <td>0.816291</td>\n",
              "      <td>0.007996</td>\n",
              "      <td>0.811389</td>\n",
              "      <td>0.007388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.599379</td>\n",
              "      <td>0.020939</td>\n",
              "      <td>0.624451</td>\n",
              "      <td>0.021465</td>\n",
              "      <td>0.470427</td>\n",
              "      <td>0.046672</td>\n",
              "      <td>0.508540</td>\n",
              "      <td>0.022887</td>\n",
              "      <td>0.639569</td>\n",
              "      <td>0.023570</td>\n",
              "      <td>0.645248</td>\n",
              "      <td>0.022122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.963140</td>\n",
              "      <td>0.004338</td>\n",
              "      <td>0.960817</td>\n",
              "      <td>0.004519</td>\n",
              "      <td>0.911702</td>\n",
              "      <td>0.084214</td>\n",
              "      <td>0.947319</td>\n",
              "      <td>0.003903</td>\n",
              "      <td>0.958223</td>\n",
              "      <td>0.006442</td>\n",
              "      <td>0.962574</td>\n",
              "      <td>0.004556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.614004</td>\n",
              "      <td>0.013122</td>\n",
              "      <td>0.658172</td>\n",
              "      <td>0.013313</td>\n",
              "      <td>0.464933</td>\n",
              "      <td>0.056769</td>\n",
              "      <td>0.526791</td>\n",
              "      <td>0.041653</td>\n",
              "      <td>0.592811</td>\n",
              "      <td>0.020648</td>\n",
              "      <td>0.608472</td>\n",
              "      <td>0.021543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.931633</td>\n",
              "      <td>0.011673</td>\n",
              "      <td>0.913366</td>\n",
              "      <td>0.012572</td>\n",
              "      <td>0.910897</td>\n",
              "      <td>0.019187</td>\n",
              "      <td>0.917540</td>\n",
              "      <td>0.028600</td>\n",
              "      <td>0.910692</td>\n",
              "      <td>0.014042</td>\n",
              "      <td>0.919511</td>\n",
              "      <td>0.011703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.783589</td>\n",
              "      <td>0.125907</td>\n",
              "      <td>0.797559</td>\n",
              "      <td>0.109070</td>\n",
              "      <td>0.699043</td>\n",
              "      <td>0.164755</td>\n",
              "      <td>0.753120</td>\n",
              "      <td>0.147324</td>\n",
              "      <td>0.793707</td>\n",
              "      <td>0.117990</td>\n",
              "      <td>0.799412</td>\n",
              "      <td>0.116207</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             pca                   kpca                  dsebm             \\\n",
              "     pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std   \n",
              "0       0.698673   0.013300    0.730707   0.014845    0.674400   0.038337   \n",
              "1       0.940467   0.006721    0.933861   0.007438    0.638965   0.167223   \n",
              "2       0.708055   0.012931    0.751151   0.009973    0.624861   0.022804   \n",
              "3       0.792979   0.018098    0.828515   0.020055    0.816480   0.021882   \n",
              "4       0.762130   0.016841    0.763155   0.017801    0.711659   0.050418   \n",
              "5       0.825434   0.009205    0.811392   0.007588    0.766110   0.016099   \n",
              "6       0.599379   0.020939    0.624451   0.021465    0.470427   0.046672   \n",
              "7       0.963140   0.004338    0.960817   0.004519    0.911702   0.084214   \n",
              "8       0.614004   0.013122    0.658172   0.013313    0.464933   0.056769   \n",
              "9       0.931633   0.011673    0.913366   0.012572    0.910897   0.019187   \n",
              "mean    0.783589   0.125907    0.797559   0.109070    0.699043   0.164755   \n",
              "\n",
              "              ae                    vae                 ed-vae             \n",
              "     pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std  \n",
              "0       0.711722   0.015720    0.722367   0.016622    0.721989   0.018962  \n",
              "1       0.919310   0.021887    0.944248   0.007205    0.947529   0.007014  \n",
              "2       0.694003   0.030495    0.741947   0.010923    0.749466   0.012310  \n",
              "3       0.802410   0.025692    0.824475   0.018503    0.828265   0.018536  \n",
              "4       0.740442   0.015772    0.786449   0.018267    0.799682   0.017247  \n",
              "5       0.763120   0.008826    0.816291   0.007996    0.811389   0.007388  \n",
              "6       0.508540   0.022887    0.639569   0.023570    0.645248   0.022122  \n",
              "7       0.947319   0.003903    0.958223   0.006442    0.962574   0.004556  \n",
              "8       0.526791   0.041653    0.592811   0.020648    0.608472   0.021543  \n",
              "9       0.917540   0.028600    0.910692   0.014042    0.919511   0.011703  \n",
              "mean    0.753120   0.147324    0.793707   0.117990    0.799412   0.116207  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrzSPJk9RE93"
      },
      "source": [
        "## $R_{error}$ \n",
        "Compare Reconstruction Error of VAE and ED-VAE to results of competitive models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nx6NOTySnLL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "8c272530-b2ac-4a9d-f56b-d0253355861a"
      },
      "source": [
        "# AUC\n",
        "avg_auc_rec_class_results = pd.DataFrame((avg_class_results[0,1], std_class_results[0,1], \n",
        "                                  avg_class_results[1,1], std_class_results[1,1],\n",
        "                                  avg_class_results[2,1], std_class_results[2,1],  \n",
        "                                  avg_class_results[3,1], std_class_results[3,1], \n",
        "                                  avg_class_results[4,1], std_class_results[4,1], \n",
        "                                  avg_class_results[5,1], std_class_results[5,1], \n",
        "                                  ), \n",
        "                                  index = auc_header).T\n",
        "avg_auc_rec_class_results = avg_auc_rec_class_results.rename(index={0: \"mean\"})\n",
        "avg_auc_rec_final_results = pd.DataFrame((avg_results[:,0,1], std_results[:,0,1], \n",
        "                                  avg_results[:,1,1], std_results[:,1,1],\n",
        "                                  avg_results[:,2,1], std_results[:,2,1],  \n",
        "                                  avg_results[:,3,1], std_results[:,3,1], \n",
        "                                  avg_results[:,4,1], std_results[:,4,1], \n",
        "                                  avg_results[:,5,1], std_results[:,5,1], \n",
        "                                  ), \n",
        "                                  index = auc_header, columns = index_labels).T\n",
        "avg_auc_rec_final_results.append(avg_auc_rec_class_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">pca</th>\n",
              "      <th colspan=\"2\" halign=\"left\">kpca</th>\n",
              "      <th colspan=\"2\" halign=\"left\">dsebm</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">vae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ed-vae</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.898339</td>\n",
              "      <td>0.005398</td>\n",
              "      <td>0.906345</td>\n",
              "      <td>0.006592</td>\n",
              "      <td>0.872652</td>\n",
              "      <td>0.019989</td>\n",
              "      <td>0.896966</td>\n",
              "      <td>0.012320</td>\n",
              "      <td>0.896063</td>\n",
              "      <td>0.007094</td>\n",
              "      <td>0.901122</td>\n",
              "      <td>0.007483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.985436</td>\n",
              "      <td>0.001879</td>\n",
              "      <td>0.982097</td>\n",
              "      <td>0.002359</td>\n",
              "      <td>0.784110</td>\n",
              "      <td>0.134305</td>\n",
              "      <td>0.979720</td>\n",
              "      <td>0.006758</td>\n",
              "      <td>0.982152</td>\n",
              "      <td>0.002555</td>\n",
              "      <td>0.985460</td>\n",
              "      <td>0.002292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.887165</td>\n",
              "      <td>0.008119</td>\n",
              "      <td>0.890545</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.833402</td>\n",
              "      <td>0.013873</td>\n",
              "      <td>0.866617</td>\n",
              "      <td>0.013023</td>\n",
              "      <td>0.878164</td>\n",
              "      <td>0.008535</td>\n",
              "      <td>0.886226</td>\n",
              "      <td>0.007555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.919152</td>\n",
              "      <td>0.007362</td>\n",
              "      <td>0.925635</td>\n",
              "      <td>0.011317</td>\n",
              "      <td>0.913408</td>\n",
              "      <td>0.015568</td>\n",
              "      <td>0.905385</td>\n",
              "      <td>0.015106</td>\n",
              "      <td>0.915553</td>\n",
              "      <td>0.007754</td>\n",
              "      <td>0.920695</td>\n",
              "      <td>0.007345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.885009</td>\n",
              "      <td>0.013492</td>\n",
              "      <td>0.884886</td>\n",
              "      <td>0.014163</td>\n",
              "      <td>0.875427</td>\n",
              "      <td>0.019237</td>\n",
              "      <td>0.887289</td>\n",
              "      <td>0.009809</td>\n",
              "      <td>0.901077</td>\n",
              "      <td>0.013091</td>\n",
              "      <td>0.911860</td>\n",
              "      <td>0.012613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.886346</td>\n",
              "      <td>0.009993</td>\n",
              "      <td>0.888076</td>\n",
              "      <td>0.008158</td>\n",
              "      <td>0.872494</td>\n",
              "      <td>0.008884</td>\n",
              "      <td>0.876394</td>\n",
              "      <td>0.006077</td>\n",
              "      <td>0.884665</td>\n",
              "      <td>0.008748</td>\n",
              "      <td>0.885300</td>\n",
              "      <td>0.007125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.813194</td>\n",
              "      <td>0.012386</td>\n",
              "      <td>0.821431</td>\n",
              "      <td>0.009973</td>\n",
              "      <td>0.756203</td>\n",
              "      <td>0.019512</td>\n",
              "      <td>0.776370</td>\n",
              "      <td>0.017384</td>\n",
              "      <td>0.819804</td>\n",
              "      <td>0.014603</td>\n",
              "      <td>0.826755</td>\n",
              "      <td>0.013618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.984449</td>\n",
              "      <td>0.002424</td>\n",
              "      <td>0.983995</td>\n",
              "      <td>0.002469</td>\n",
              "      <td>0.953105</td>\n",
              "      <td>0.057234</td>\n",
              "      <td>0.980500</td>\n",
              "      <td>0.002904</td>\n",
              "      <td>0.977047</td>\n",
              "      <td>0.004266</td>\n",
              "      <td>0.981493</td>\n",
              "      <td>0.002973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.836911</td>\n",
              "      <td>0.006764</td>\n",
              "      <td>0.839565</td>\n",
              "      <td>0.008515</td>\n",
              "      <td>0.795964</td>\n",
              "      <td>0.035885</td>\n",
              "      <td>0.821306</td>\n",
              "      <td>0.023230</td>\n",
              "      <td>0.812620</td>\n",
              "      <td>0.010624</td>\n",
              "      <td>0.827066</td>\n",
              "      <td>0.011497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.970721</td>\n",
              "      <td>0.007420</td>\n",
              "      <td>0.966373</td>\n",
              "      <td>0.006154</td>\n",
              "      <td>0.972514</td>\n",
              "      <td>0.006888</td>\n",
              "      <td>0.971163</td>\n",
              "      <td>0.007767</td>\n",
              "      <td>0.959224</td>\n",
              "      <td>0.010769</td>\n",
              "      <td>0.969056</td>\n",
              "      <td>0.007599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.906672</td>\n",
              "      <td>0.056695</td>\n",
              "      <td>0.908895</td>\n",
              "      <td>0.053946</td>\n",
              "      <td>0.862928</td>\n",
              "      <td>0.083847</td>\n",
              "      <td>0.896171</td>\n",
              "      <td>0.065376</td>\n",
              "      <td>0.902637</td>\n",
              "      <td>0.056620</td>\n",
              "      <td>0.909503</td>\n",
              "      <td>0.054988</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           pca                kpca               dsebm                  ae  \\\n",
              "      auc_mean   auc_std  auc_mean   auc_std  auc_mean   auc_std  auc_mean   \n",
              "0     0.898339  0.005398  0.906345  0.006592  0.872652  0.019989  0.896966   \n",
              "1     0.985436  0.001879  0.982097  0.002359  0.784110  0.134305  0.979720   \n",
              "2     0.887165  0.008119  0.890545  0.007060  0.833402  0.013873  0.866617   \n",
              "3     0.919152  0.007362  0.925635  0.011317  0.913408  0.015568  0.905385   \n",
              "4     0.885009  0.013492  0.884886  0.014163  0.875427  0.019237  0.887289   \n",
              "5     0.886346  0.009993  0.888076  0.008158  0.872494  0.008884  0.876394   \n",
              "6     0.813194  0.012386  0.821431  0.009973  0.756203  0.019512  0.776370   \n",
              "7     0.984449  0.002424  0.983995  0.002469  0.953105  0.057234  0.980500   \n",
              "8     0.836911  0.006764  0.839565  0.008515  0.795964  0.035885  0.821306   \n",
              "9     0.970721  0.007420  0.966373  0.006154  0.972514  0.006888  0.971163   \n",
              "mean  0.906672  0.056695  0.908895  0.053946  0.862928  0.083847  0.896171   \n",
              "\n",
              "                     vae              ed-vae            \n",
              "       auc_std  auc_mean   auc_std  auc_mean   auc_std  \n",
              "0     0.012320  0.896063  0.007094  0.901122  0.007483  \n",
              "1     0.006758  0.982152  0.002555  0.985460  0.002292  \n",
              "2     0.013023  0.878164  0.008535  0.886226  0.007555  \n",
              "3     0.015106  0.915553  0.007754  0.920695  0.007345  \n",
              "4     0.009809  0.901077  0.013091  0.911860  0.012613  \n",
              "5     0.006077  0.884665  0.008748  0.885300  0.007125  \n",
              "6     0.017384  0.819804  0.014603  0.826755  0.013618  \n",
              "7     0.002904  0.977047  0.004266  0.981493  0.002973  \n",
              "8     0.023230  0.812620  0.010624  0.827066  0.011497  \n",
              "9     0.007767  0.959224  0.010769  0.969056  0.007599  \n",
              "mean  0.065376  0.902637  0.056620  0.909503  0.054988  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOb8UOKU6jOM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "29d1002c-2b7e-40f2-a27c-55b2b855c7bf"
      },
      "source": [
        "# PR-AUC\n",
        "avg_pr_rec_class_results = pd.DataFrame((avg_class_results[0,0], std_class_results[0,0], \n",
        "                                  avg_class_results[1,0], std_class_results[1,0],\n",
        "                                  avg_class_results[2,0], std_class_results[2,0],  \n",
        "                                  avg_class_results[3,0], std_class_results[3,0], \n",
        "                                  avg_class_results[4,0], std_class_results[4,0], \n",
        "                                  avg_class_results[5,0], std_class_results[5,0], \n",
        "                                  ), \n",
        "                                  index = pr_header).T\n",
        "avg_pr_rec_class_results = avg_pr_rec_class_results.rename(index={0: \"mean\"})\n",
        "avg_pr_rec_final_results = pd.DataFrame((avg_results[:,0,0], std_results[:,0,0], \n",
        "                                  avg_results[:,1,0], std_results[:,1,0],\n",
        "                                  avg_results[:,2,0], std_results[:,2,0],  \n",
        "                                  avg_results[:,3,0], std_results[:,3,0], \n",
        "                                  avg_results[:,4,0], std_results[:,4,0], \n",
        "                                  avg_results[:,5,0], std_results[:,5,0], \n",
        "                                  ), \n",
        "                                  index = pr_header, columns = index_labels).T\n",
        "avg_pr_rec_final_results.append(avg_pr_rec_class_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">pca</th>\n",
              "      <th colspan=\"2\" halign=\"left\">kpca</th>\n",
              "      <th colspan=\"2\" halign=\"left\">dsebm</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">vae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ed-vae</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.698673</td>\n",
              "      <td>0.013300</td>\n",
              "      <td>0.730707</td>\n",
              "      <td>0.014845</td>\n",
              "      <td>0.674400</td>\n",
              "      <td>0.038337</td>\n",
              "      <td>0.711722</td>\n",
              "      <td>0.015720</td>\n",
              "      <td>0.686710</td>\n",
              "      <td>0.017583</td>\n",
              "      <td>0.683710</td>\n",
              "      <td>0.019027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.940467</td>\n",
              "      <td>0.006721</td>\n",
              "      <td>0.933861</td>\n",
              "      <td>0.007438</td>\n",
              "      <td>0.638965</td>\n",
              "      <td>0.167223</td>\n",
              "      <td>0.919310</td>\n",
              "      <td>0.021887</td>\n",
              "      <td>0.936850</td>\n",
              "      <td>0.007662</td>\n",
              "      <td>0.943020</td>\n",
              "      <td>0.007366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.708055</td>\n",
              "      <td>0.012931</td>\n",
              "      <td>0.751151</td>\n",
              "      <td>0.009973</td>\n",
              "      <td>0.624861</td>\n",
              "      <td>0.022804</td>\n",
              "      <td>0.694003</td>\n",
              "      <td>0.030495</td>\n",
              "      <td>0.721591</td>\n",
              "      <td>0.013055</td>\n",
              "      <td>0.727865</td>\n",
              "      <td>0.014579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.792979</td>\n",
              "      <td>0.018098</td>\n",
              "      <td>0.828515</td>\n",
              "      <td>0.020055</td>\n",
              "      <td>0.816480</td>\n",
              "      <td>0.021882</td>\n",
              "      <td>0.802410</td>\n",
              "      <td>0.025692</td>\n",
              "      <td>0.801492</td>\n",
              "      <td>0.017408</td>\n",
              "      <td>0.805554</td>\n",
              "      <td>0.017027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.762130</td>\n",
              "      <td>0.016841</td>\n",
              "      <td>0.763155</td>\n",
              "      <td>0.017801</td>\n",
              "      <td>0.711659</td>\n",
              "      <td>0.050418</td>\n",
              "      <td>0.740442</td>\n",
              "      <td>0.015772</td>\n",
              "      <td>0.780542</td>\n",
              "      <td>0.019491</td>\n",
              "      <td>0.793460</td>\n",
              "      <td>0.018910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.825434</td>\n",
              "      <td>0.009205</td>\n",
              "      <td>0.811392</td>\n",
              "      <td>0.007588</td>\n",
              "      <td>0.766110</td>\n",
              "      <td>0.016099</td>\n",
              "      <td>0.763120</td>\n",
              "      <td>0.008826</td>\n",
              "      <td>0.809740</td>\n",
              "      <td>0.008844</td>\n",
              "      <td>0.802923</td>\n",
              "      <td>0.007537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.599379</td>\n",
              "      <td>0.020939</td>\n",
              "      <td>0.624451</td>\n",
              "      <td>0.021465</td>\n",
              "      <td>0.470427</td>\n",
              "      <td>0.046672</td>\n",
              "      <td>0.508540</td>\n",
              "      <td>0.022887</td>\n",
              "      <td>0.631358</td>\n",
              "      <td>0.022082</td>\n",
              "      <td>0.635030</td>\n",
              "      <td>0.021455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.963140</td>\n",
              "      <td>0.004338</td>\n",
              "      <td>0.960817</td>\n",
              "      <td>0.004519</td>\n",
              "      <td>0.911702</td>\n",
              "      <td>0.084214</td>\n",
              "      <td>0.947319</td>\n",
              "      <td>0.003903</td>\n",
              "      <td>0.950122</td>\n",
              "      <td>0.008087</td>\n",
              "      <td>0.956836</td>\n",
              "      <td>0.005809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.614004</td>\n",
              "      <td>0.013122</td>\n",
              "      <td>0.658172</td>\n",
              "      <td>0.013313</td>\n",
              "      <td>0.464933</td>\n",
              "      <td>0.056769</td>\n",
              "      <td>0.526791</td>\n",
              "      <td>0.041653</td>\n",
              "      <td>0.549982</td>\n",
              "      <td>0.020126</td>\n",
              "      <td>0.564549</td>\n",
              "      <td>0.021504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.931633</td>\n",
              "      <td>0.011673</td>\n",
              "      <td>0.913366</td>\n",
              "      <td>0.012572</td>\n",
              "      <td>0.910897</td>\n",
              "      <td>0.019187</td>\n",
              "      <td>0.917540</td>\n",
              "      <td>0.028600</td>\n",
              "      <td>0.904508</td>\n",
              "      <td>0.016123</td>\n",
              "      <td>0.914632</td>\n",
              "      <td>0.013445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.783589</td>\n",
              "      <td>0.125907</td>\n",
              "      <td>0.797559</td>\n",
              "      <td>0.109070</td>\n",
              "      <td>0.699043</td>\n",
              "      <td>0.164755</td>\n",
              "      <td>0.753120</td>\n",
              "      <td>0.147324</td>\n",
              "      <td>0.777290</td>\n",
              "      <td>0.126473</td>\n",
              "      <td>0.782758</td>\n",
              "      <td>0.126155</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             pca                   kpca                  dsebm             \\\n",
              "     pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std   \n",
              "0       0.698673   0.013300    0.730707   0.014845    0.674400   0.038337   \n",
              "1       0.940467   0.006721    0.933861   0.007438    0.638965   0.167223   \n",
              "2       0.708055   0.012931    0.751151   0.009973    0.624861   0.022804   \n",
              "3       0.792979   0.018098    0.828515   0.020055    0.816480   0.021882   \n",
              "4       0.762130   0.016841    0.763155   0.017801    0.711659   0.050418   \n",
              "5       0.825434   0.009205    0.811392   0.007588    0.766110   0.016099   \n",
              "6       0.599379   0.020939    0.624451   0.021465    0.470427   0.046672   \n",
              "7       0.963140   0.004338    0.960817   0.004519    0.911702   0.084214   \n",
              "8       0.614004   0.013122    0.658172   0.013313    0.464933   0.056769   \n",
              "9       0.931633   0.011673    0.913366   0.012572    0.910897   0.019187   \n",
              "mean    0.783589   0.125907    0.797559   0.109070    0.699043   0.164755   \n",
              "\n",
              "              ae                    vae                 ed-vae             \n",
              "     pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std  \n",
              "0       0.711722   0.015720    0.686710   0.017583    0.683710   0.019027  \n",
              "1       0.919310   0.021887    0.936850   0.007662    0.943020   0.007366  \n",
              "2       0.694003   0.030495    0.721591   0.013055    0.727865   0.014579  \n",
              "3       0.802410   0.025692    0.801492   0.017408    0.805554   0.017027  \n",
              "4       0.740442   0.015772    0.780542   0.019491    0.793460   0.018910  \n",
              "5       0.763120   0.008826    0.809740   0.008844    0.802923   0.007537  \n",
              "6       0.508540   0.022887    0.631358   0.022082    0.635030   0.021455  \n",
              "7       0.947319   0.003903    0.950122   0.008087    0.956836   0.005809  \n",
              "8       0.526791   0.041653    0.549982   0.020126    0.564549   0.021504  \n",
              "9       0.917540   0.028600    0.904508   0.016123    0.914632   0.013445  \n",
              "mean    0.753120   0.147324    0.777290   0.126473    0.782758   0.126155  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPi0xeGAnpVi"
      },
      "source": [
        "## Formated for Publication\n",
        "Mean and SEM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5RBEX7PyD3y"
      },
      "source": [
        "# returns the list for df.style.apply() method\n",
        "def highlight_max(s):\n",
        "    s = s.str.split(pat='±',expand=True)[0]\n",
        "    is_max = s == s.max()\n",
        "    return ['font-weight: bold' if cell else '' for cell in is_max]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1KDkJyD5-0K"
      },
      "source": [
        "### $ELBO$ \n",
        " Compare ELBO of VAE and ED-VAE to results of competitive models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poEcAPrgPiwp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "dddb077c-5e10-4556-a428-018bafc99515"
      },
      "source": [
        "# AUC\n",
        "df = pd.DataFrame((\n",
        "    round(avg_auc_elbo_final_results[column,'auc_mean']*100,1).astype(str) + '±' + round(avg_auc_elbo_final_results[column,'auc_std']*100/np.sqrt(reps),1).astype(str) for column in avg_auc_elbo_final_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_auc_elbo_final_results.keys().get_level_values(0)[::2]).T\n",
        "df = df.append(pd.DataFrame((\n",
        "    #round(avg_auc_elbo_class_results[column,'auc_mean']*100,1).astype(str) + '±' + round(avg_auc_elbo_class_results[column,'pr_auc_std']*100/np.sqrt(reps * len(df.index)),1).astype(str) for column in avg_auc_elbo_class_results.keys().get_level_values(0)[::2]\n",
        "    round(avg_auc_elbo_class_results[column,'auc_mean']*100,1).astype(str) for column in avg_auc_elbo_class_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_auc_elbo_class_results.keys().get_level_values(0)[::2]).T)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pca</th>\n",
              "      <th>kpca</th>\n",
              "      <th>dsebm</th>\n",
              "      <th>ae</th>\n",
              "      <th>vae</th>\n",
              "      <th>ed-vae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>89.8±0.2</td>\n",
              "      <td>90.6±0.2</td>\n",
              "      <td>87.3±0.6</td>\n",
              "      <td>89.7±0.4</td>\n",
              "      <td>90.7±0.2</td>\n",
              "      <td>91.1±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98.5±0.1</td>\n",
              "      <td>98.2±0.1</td>\n",
              "      <td>78.4±4.2</td>\n",
              "      <td>98.0±0.2</td>\n",
              "      <td>98.6±0.1</td>\n",
              "      <td>98.7±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>88.7±0.3</td>\n",
              "      <td>89.1±0.2</td>\n",
              "      <td>83.3±0.4</td>\n",
              "      <td>86.7±0.4</td>\n",
              "      <td>88.4±0.3</td>\n",
              "      <td>89.1±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91.9±0.2</td>\n",
              "      <td>92.6±0.4</td>\n",
              "      <td>91.3±0.5</td>\n",
              "      <td>90.5±0.5</td>\n",
              "      <td>92.4±0.3</td>\n",
              "      <td>92.8±0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>88.5±0.4</td>\n",
              "      <td>88.5±0.4</td>\n",
              "      <td>87.5±0.6</td>\n",
              "      <td>88.7±0.3</td>\n",
              "      <td>90.0±0.4</td>\n",
              "      <td>90.9±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>88.6±0.3</td>\n",
              "      <td>88.8±0.3</td>\n",
              "      <td>87.2±0.3</td>\n",
              "      <td>87.6±0.2</td>\n",
              "      <td>89.3±0.3</td>\n",
              "      <td>89.5±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>81.3±0.4</td>\n",
              "      <td>82.1±0.3</td>\n",
              "      <td>75.6±0.6</td>\n",
              "      <td>77.6±0.5</td>\n",
              "      <td>82.3±0.4</td>\n",
              "      <td>83.1±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>98.4±0.1</td>\n",
              "      <td>98.4±0.1</td>\n",
              "      <td>95.3±1.8</td>\n",
              "      <td>98.1±0.1</td>\n",
              "      <td>98.2±0.1</td>\n",
              "      <td>98.5±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>83.7±0.2</td>\n",
              "      <td>84.0±0.3</td>\n",
              "      <td>79.6±1.1</td>\n",
              "      <td>82.1±0.7</td>\n",
              "      <td>83.5±0.4</td>\n",
              "      <td>84.8±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>97.1±0.2</td>\n",
              "      <td>96.6±0.2</td>\n",
              "      <td>97.3±0.2</td>\n",
              "      <td>97.1±0.2</td>\n",
              "      <td>96.3±0.3</td>\n",
              "      <td>97.1±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>90.7</td>\n",
              "      <td>90.9</td>\n",
              "      <td>86.3</td>\n",
              "      <td>89.6</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           pca      kpca     dsebm        ae       vae    ed-vae\n",
              "0     89.8±0.2  90.6±0.2  87.3±0.6  89.7±0.4  90.7±0.2  91.1±0.2\n",
              "1     98.5±0.1  98.2±0.1  78.4±4.2  98.0±0.2  98.6±0.1  98.7±0.1\n",
              "2     88.7±0.3  89.1±0.2  83.3±0.4  86.7±0.4  88.4±0.3  89.1±0.2\n",
              "3     91.9±0.2  92.6±0.4  91.3±0.5  90.5±0.5  92.4±0.3  92.8±0.3\n",
              "4     88.5±0.4  88.5±0.4  87.5±0.6  88.7±0.3  90.0±0.4  90.9±0.4\n",
              "5     88.6±0.3  88.8±0.3  87.2±0.3  87.6±0.2  89.3±0.3  89.5±0.2\n",
              "6     81.3±0.4  82.1±0.3  75.6±0.6  77.6±0.5  82.3±0.4  83.1±0.4\n",
              "7     98.4±0.1  98.4±0.1  95.3±1.8  98.1±0.1  98.2±0.1  98.5±0.1\n",
              "8     83.7±0.2  84.0±0.3  79.6±1.1  82.1±0.7  83.5±0.4  84.8±0.4\n",
              "9     97.1±0.2  96.6±0.2  97.3±0.2  97.1±0.2  96.3±0.3  97.1±0.2\n",
              "mean      90.7      90.9      86.3      89.6      91.0      91.6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_AOdoyy_SJ9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "0cf3e6d5-7739-4aee-adbc-4f851651397e"
      },
      "source": [
        "df.style.apply(highlight_max, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row0_col5,#T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row1_col5,#T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row2_col1,#T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row2_col5,#T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row3_col5,#T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row4_col5,#T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row5_col5,#T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row6_col5,#T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row7_col5,#T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row8_col5,#T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row9_col2,#T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row10_col5{\n",
              "            font-weight:  bold;\n",
              "        }</style><table id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >pca</th>        <th class=\"col_heading level0 col1\" >kpca</th>        <th class=\"col_heading level0 col2\" >dsebm</th>        <th class=\"col_heading level0 col3\" >ae</th>        <th class=\"col_heading level0 col4\" >vae</th>        <th class=\"col_heading level0 col5\" >ed-vae</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row0_col0\" class=\"data row0 col0\" >89.8±0.2</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row0_col1\" class=\"data row0 col1\" >90.6±0.2</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row0_col2\" class=\"data row0 col2\" >87.3±0.6</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row0_col3\" class=\"data row0 col3\" >89.7±0.4</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row0_col4\" class=\"data row0 col4\" >90.7±0.2</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row0_col5\" class=\"data row0 col5\" >91.1±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row1_col0\" class=\"data row1 col0\" >98.5±0.1</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row1_col1\" class=\"data row1 col1\" >98.2±0.1</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row1_col2\" class=\"data row1 col2\" >78.4±4.2</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row1_col3\" class=\"data row1 col3\" >98.0±0.2</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row1_col4\" class=\"data row1 col4\" >98.6±0.1</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row1_col5\" class=\"data row1 col5\" >98.7±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row2_col0\" class=\"data row2 col0\" >88.7±0.3</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row2_col1\" class=\"data row2 col1\" >89.1±0.2</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row2_col2\" class=\"data row2 col2\" >83.3±0.4</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row2_col3\" class=\"data row2 col3\" >86.7±0.4</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row2_col4\" class=\"data row2 col4\" >88.4±0.3</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row2_col5\" class=\"data row2 col5\" >89.1±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row3_col0\" class=\"data row3 col0\" >91.9±0.2</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row3_col1\" class=\"data row3 col1\" >92.6±0.4</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row3_col2\" class=\"data row3 col2\" >91.3±0.5</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row3_col3\" class=\"data row3 col3\" >90.5±0.5</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row3_col4\" class=\"data row3 col4\" >92.4±0.3</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row3_col5\" class=\"data row3 col5\" >92.8±0.3</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row4_col0\" class=\"data row4 col0\" >88.5±0.4</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row4_col1\" class=\"data row4 col1\" >88.5±0.4</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row4_col2\" class=\"data row4 col2\" >87.5±0.6</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row4_col3\" class=\"data row4 col3\" >88.7±0.3</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row4_col4\" class=\"data row4 col4\" >90.0±0.4</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row4_col5\" class=\"data row4 col5\" >90.9±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row5_col0\" class=\"data row5 col0\" >88.6±0.3</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row5_col1\" class=\"data row5 col1\" >88.8±0.3</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row5_col2\" class=\"data row5 col2\" >87.2±0.3</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row5_col3\" class=\"data row5 col3\" >87.6±0.2</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row5_col4\" class=\"data row5 col4\" >89.3±0.3</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row5_col5\" class=\"data row5 col5\" >89.5±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row6_col0\" class=\"data row6 col0\" >81.3±0.4</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row6_col1\" class=\"data row6 col1\" >82.1±0.3</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row6_col2\" class=\"data row6 col2\" >75.6±0.6</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row6_col3\" class=\"data row6 col3\" >77.6±0.5</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row6_col4\" class=\"data row6 col4\" >82.3±0.4</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row6_col5\" class=\"data row6 col5\" >83.1±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row7_col0\" class=\"data row7 col0\" >98.4±0.1</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row7_col1\" class=\"data row7 col1\" >98.4±0.1</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row7_col2\" class=\"data row7 col2\" >95.3±1.8</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row7_col3\" class=\"data row7 col3\" >98.1±0.1</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row7_col4\" class=\"data row7 col4\" >98.2±0.1</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row7_col5\" class=\"data row7 col5\" >98.5±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row8_col0\" class=\"data row8 col0\" >83.7±0.2</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row8_col1\" class=\"data row8 col1\" >84.0±0.3</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row8_col2\" class=\"data row8 col2\" >79.6±1.1</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row8_col3\" class=\"data row8 col3\" >82.1±0.7</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row8_col4\" class=\"data row8 col4\" >83.5±0.4</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row8_col5\" class=\"data row8 col5\" >84.8±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row9_col0\" class=\"data row9 col0\" >97.1±0.2</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row9_col1\" class=\"data row9 col1\" >96.6±0.2</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row9_col2\" class=\"data row9 col2\" >97.3±0.2</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row9_col3\" class=\"data row9 col3\" >97.1±0.2</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row9_col4\" class=\"data row9 col4\" >96.3±0.3</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row9_col5\" class=\"data row9 col5\" >97.1±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >mean</th>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row10_col0\" class=\"data row10 col0\" >90.7</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row10_col1\" class=\"data row10 col1\" >90.9</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row10_col2\" class=\"data row10 col2\" >86.3</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row10_col3\" class=\"data row10 col3\" >89.6</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row10_col4\" class=\"data row10 col4\" >91.0</td>\n",
              "                        <td id=\"T_4594f06e_bf33_11eb_b6ae_0242ac1c0002row10_col5\" class=\"data row10 col5\" >91.6</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f6d5c193b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CndoxB3bPiwm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "40434e29-0aad-499a-e8e4-cf4873465092"
      },
      "source": [
        "# PR-AUC\n",
        "df = pd.DataFrame((\n",
        "    round(avg_pr_elbo_final_results[column,'pr_auc_mean']*100,1).astype(str) + '±' + round(avg_pr_elbo_final_results[column,'pr_auc_std']*100/np.sqrt(reps),1).astype(str) for column in avg_pr_elbo_final_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_pr_elbo_final_results.keys().get_level_values(0)[::2]).T  \n",
        "df = df.append(pd.DataFrame((\n",
        "    #round(avg_pr_elbo_class_results[column,'pr_auc_mean']*100,1).astype(str) + '±' + round(avg_pr_elbo_class_results[column,'pr_auc_std']*100/np.sqrt(reps * len(df.index)),1).astype(str) for column in avg_pr_elbo_class_results.keys().get_level_values(0)[::2]\n",
        "    round(avg_pr_elbo_class_results[column,'pr_auc_mean']*100,1).astype(str) for column in avg_pr_elbo_class_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_pr_elbo_class_results.keys().get_level_values(0)[::2]).T)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pca</th>\n",
              "      <th>kpca</th>\n",
              "      <th>dsebm</th>\n",
              "      <th>ae</th>\n",
              "      <th>vae</th>\n",
              "      <th>ed-vae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>69.9±0.4</td>\n",
              "      <td>73.1±0.5</td>\n",
              "      <td>67.4±1.2</td>\n",
              "      <td>71.2±0.5</td>\n",
              "      <td>72.2±0.5</td>\n",
              "      <td>72.2±0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>94.0±0.2</td>\n",
              "      <td>93.4±0.2</td>\n",
              "      <td>63.9±5.3</td>\n",
              "      <td>91.9±0.7</td>\n",
              "      <td>94.4±0.2</td>\n",
              "      <td>94.8±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70.8±0.4</td>\n",
              "      <td>75.1±0.3</td>\n",
              "      <td>62.5±0.7</td>\n",
              "      <td>69.4±1.0</td>\n",
              "      <td>74.2±0.3</td>\n",
              "      <td>74.9±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>79.3±0.6</td>\n",
              "      <td>82.9±0.6</td>\n",
              "      <td>81.6±0.7</td>\n",
              "      <td>80.2±0.8</td>\n",
              "      <td>82.4±0.6</td>\n",
              "      <td>82.8±0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>76.2±0.5</td>\n",
              "      <td>76.3±0.6</td>\n",
              "      <td>71.2±1.6</td>\n",
              "      <td>74.0±0.5</td>\n",
              "      <td>78.6±0.6</td>\n",
              "      <td>80.0±0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>82.5±0.3</td>\n",
              "      <td>81.1±0.2</td>\n",
              "      <td>76.6±0.5</td>\n",
              "      <td>76.3±0.3</td>\n",
              "      <td>81.6±0.3</td>\n",
              "      <td>81.1±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>59.9±0.7</td>\n",
              "      <td>62.4±0.7</td>\n",
              "      <td>47.0±1.5</td>\n",
              "      <td>50.9±0.7</td>\n",
              "      <td>64.0±0.7</td>\n",
              "      <td>64.5±0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>96.3±0.1</td>\n",
              "      <td>96.1±0.1</td>\n",
              "      <td>91.2±2.7</td>\n",
              "      <td>94.7±0.1</td>\n",
              "      <td>95.8±0.2</td>\n",
              "      <td>96.3±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>61.4±0.4</td>\n",
              "      <td>65.8±0.4</td>\n",
              "      <td>46.5±1.8</td>\n",
              "      <td>52.7±1.3</td>\n",
              "      <td>59.3±0.7</td>\n",
              "      <td>60.8±0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>93.2±0.4</td>\n",
              "      <td>91.3±0.4</td>\n",
              "      <td>91.1±0.6</td>\n",
              "      <td>91.8±0.9</td>\n",
              "      <td>91.1±0.4</td>\n",
              "      <td>92.0±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>78.4</td>\n",
              "      <td>79.8</td>\n",
              "      <td>69.9</td>\n",
              "      <td>75.3</td>\n",
              "      <td>79.4</td>\n",
              "      <td>79.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           pca      kpca     dsebm        ae       vae    ed-vae\n",
              "0     69.9±0.4  73.1±0.5  67.4±1.2  71.2±0.5  72.2±0.5  72.2±0.6\n",
              "1     94.0±0.2  93.4±0.2  63.9±5.3  91.9±0.7  94.4±0.2  94.8±0.2\n",
              "2     70.8±0.4  75.1±0.3  62.5±0.7  69.4±1.0  74.2±0.3  74.9±0.4\n",
              "3     79.3±0.6  82.9±0.6  81.6±0.7  80.2±0.8  82.4±0.6  82.8±0.6\n",
              "4     76.2±0.5  76.3±0.6  71.2±1.6  74.0±0.5  78.6±0.6  80.0±0.5\n",
              "5     82.5±0.3  81.1±0.2  76.6±0.5  76.3±0.3  81.6±0.3  81.1±0.2\n",
              "6     59.9±0.7  62.4±0.7  47.0±1.5  50.9±0.7  64.0±0.7  64.5±0.7\n",
              "7     96.3±0.1  96.1±0.1  91.2±2.7  94.7±0.1  95.8±0.2  96.3±0.1\n",
              "8     61.4±0.4  65.8±0.4  46.5±1.8  52.7±1.3  59.3±0.7  60.8±0.7\n",
              "9     93.2±0.4  91.3±0.4  91.1±0.6  91.8±0.9  91.1±0.4  92.0±0.4\n",
              "mean      78.4      79.8      69.9      75.3      79.4      79.9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKOTKAHf_Rs-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "4d69504a-bf97-4a89-b366-d2f061e30598"
      },
      "source": [
        "df.style.apply(highlight_max, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row0_col1,#T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row1_col5,#T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row2_col1,#T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row3_col1,#T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row4_col5,#T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row5_col0,#T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row6_col5,#T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row7_col0,#T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row7_col5,#T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row8_col1,#T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row9_col0,#T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row10_col5{\n",
              "            font-weight:  bold;\n",
              "        }</style><table id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >pca</th>        <th class=\"col_heading level0 col1\" >kpca</th>        <th class=\"col_heading level0 col2\" >dsebm</th>        <th class=\"col_heading level0 col3\" >ae</th>        <th class=\"col_heading level0 col4\" >vae</th>        <th class=\"col_heading level0 col5\" >ed-vae</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row0_col0\" class=\"data row0 col0\" >69.9±0.4</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row0_col1\" class=\"data row0 col1\" >73.1±0.5</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row0_col2\" class=\"data row0 col2\" >67.4±1.2</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row0_col3\" class=\"data row0 col3\" >71.2±0.5</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row0_col4\" class=\"data row0 col4\" >72.2±0.5</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row0_col5\" class=\"data row0 col5\" >72.2±0.6</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row1_col0\" class=\"data row1 col0\" >94.0±0.2</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row1_col1\" class=\"data row1 col1\" >93.4±0.2</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row1_col2\" class=\"data row1 col2\" >63.9±5.3</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row1_col3\" class=\"data row1 col3\" >91.9±0.7</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row1_col4\" class=\"data row1 col4\" >94.4±0.2</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row1_col5\" class=\"data row1 col5\" >94.8±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row2_col0\" class=\"data row2 col0\" >70.8±0.4</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row2_col1\" class=\"data row2 col1\" >75.1±0.3</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row2_col2\" class=\"data row2 col2\" >62.5±0.7</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row2_col3\" class=\"data row2 col3\" >69.4±1.0</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row2_col4\" class=\"data row2 col4\" >74.2±0.3</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row2_col5\" class=\"data row2 col5\" >74.9±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row3_col0\" class=\"data row3 col0\" >79.3±0.6</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row3_col1\" class=\"data row3 col1\" >82.9±0.6</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row3_col2\" class=\"data row3 col2\" >81.6±0.7</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row3_col3\" class=\"data row3 col3\" >80.2±0.8</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row3_col4\" class=\"data row3 col4\" >82.4±0.6</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row3_col5\" class=\"data row3 col5\" >82.8±0.6</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row4_col0\" class=\"data row4 col0\" >76.2±0.5</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row4_col1\" class=\"data row4 col1\" >76.3±0.6</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row4_col2\" class=\"data row4 col2\" >71.2±1.6</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row4_col3\" class=\"data row4 col3\" >74.0±0.5</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row4_col4\" class=\"data row4 col4\" >78.6±0.6</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row4_col5\" class=\"data row4 col5\" >80.0±0.5</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row5_col0\" class=\"data row5 col0\" >82.5±0.3</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row5_col1\" class=\"data row5 col1\" >81.1±0.2</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row5_col2\" class=\"data row5 col2\" >76.6±0.5</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row5_col3\" class=\"data row5 col3\" >76.3±0.3</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row5_col4\" class=\"data row5 col4\" >81.6±0.3</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row5_col5\" class=\"data row5 col5\" >81.1±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row6_col0\" class=\"data row6 col0\" >59.9±0.7</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row6_col1\" class=\"data row6 col1\" >62.4±0.7</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row6_col2\" class=\"data row6 col2\" >47.0±1.5</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row6_col3\" class=\"data row6 col3\" >50.9±0.7</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row6_col4\" class=\"data row6 col4\" >64.0±0.7</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row6_col5\" class=\"data row6 col5\" >64.5±0.7</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row7_col0\" class=\"data row7 col0\" >96.3±0.1</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row7_col1\" class=\"data row7 col1\" >96.1±0.1</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row7_col2\" class=\"data row7 col2\" >91.2±2.7</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row7_col3\" class=\"data row7 col3\" >94.7±0.1</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row7_col4\" class=\"data row7 col4\" >95.8±0.2</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row7_col5\" class=\"data row7 col5\" >96.3±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row8_col0\" class=\"data row8 col0\" >61.4±0.4</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row8_col1\" class=\"data row8 col1\" >65.8±0.4</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row8_col2\" class=\"data row8 col2\" >46.5±1.8</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row8_col3\" class=\"data row8 col3\" >52.7±1.3</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row8_col4\" class=\"data row8 col4\" >59.3±0.7</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row8_col5\" class=\"data row8 col5\" >60.8±0.7</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row9_col0\" class=\"data row9 col0\" >93.2±0.4</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row9_col1\" class=\"data row9 col1\" >91.3±0.4</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row9_col2\" class=\"data row9 col2\" >91.1±0.6</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row9_col3\" class=\"data row9 col3\" >91.8±0.9</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row9_col4\" class=\"data row9 col4\" >91.1±0.4</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row9_col5\" class=\"data row9 col5\" >92.0±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >mean</th>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row10_col0\" class=\"data row10 col0\" >78.4</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row10_col1\" class=\"data row10 col1\" >79.8</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row10_col2\" class=\"data row10 col2\" >69.9</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row10_col3\" class=\"data row10 col3\" >75.3</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row10_col4\" class=\"data row10 col4\" >79.4</td>\n",
              "                        <td id=\"T_4588cf6e_bf33_11eb_b6ae_0242ac1c0002row10_col5\" class=\"data row10 col5\" >79.9</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f6dc0177450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gLW16yzqBM_"
      },
      "source": [
        "### $R_{error}$ \n",
        "Compare Reconstruction Error of VAE and ED-VAE to results of competitive models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMYUeB-nYNsl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "c8ac2d85-f89a-46e3-e034-1a566de8e6fe"
      },
      "source": [
        "# AUC\n",
        "df = pd.DataFrame((\n",
        "    round(avg_auc_rec_final_results[column,'auc_mean']*100,1).astype(str) + '±' + round(avg_auc_rec_final_results[column,'auc_std']*100/np.sqrt(reps),1).astype(str) for column in avg_auc_rec_final_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_auc_rec_final_results.keys().get_level_values(0)[::2]).T\n",
        "df = df.append(pd.DataFrame((\n",
        "    #round(avg_auc_rec_class_results[column,'auc_mean']*100,1).astype(str) + '±' + round(avg_auc_rec_class_results[column,'pr_auc_std']*100/np.sqrt(reps * len(df.index)),1).astype(str) for column in avg_auc_rec_class_results.keys().get_level_values(0)[::2]\n",
        "    round(avg_auc_rec_class_results[column,'auc_mean']*100,1).astype(str) for column in avg_auc_rec_class_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_auc_rec_class_results.keys().get_level_values(0)[::2]).T)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pca</th>\n",
              "      <th>kpca</th>\n",
              "      <th>dsebm</th>\n",
              "      <th>ae</th>\n",
              "      <th>vae</th>\n",
              "      <th>ed-vae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>89.8±0.2</td>\n",
              "      <td>90.6±0.2</td>\n",
              "      <td>87.3±0.6</td>\n",
              "      <td>89.7±0.4</td>\n",
              "      <td>89.6±0.2</td>\n",
              "      <td>90.1±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98.5±0.1</td>\n",
              "      <td>98.2±0.1</td>\n",
              "      <td>78.4±4.2</td>\n",
              "      <td>98.0±0.2</td>\n",
              "      <td>98.2±0.1</td>\n",
              "      <td>98.5±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>88.7±0.3</td>\n",
              "      <td>89.1±0.2</td>\n",
              "      <td>83.3±0.4</td>\n",
              "      <td>86.7±0.4</td>\n",
              "      <td>87.8±0.3</td>\n",
              "      <td>88.6±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91.9±0.2</td>\n",
              "      <td>92.6±0.4</td>\n",
              "      <td>91.3±0.5</td>\n",
              "      <td>90.5±0.5</td>\n",
              "      <td>91.6±0.2</td>\n",
              "      <td>92.1±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>88.5±0.4</td>\n",
              "      <td>88.5±0.4</td>\n",
              "      <td>87.5±0.6</td>\n",
              "      <td>88.7±0.3</td>\n",
              "      <td>90.1±0.4</td>\n",
              "      <td>91.2±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>88.6±0.3</td>\n",
              "      <td>88.8±0.3</td>\n",
              "      <td>87.2±0.3</td>\n",
              "      <td>87.6±0.2</td>\n",
              "      <td>88.5±0.3</td>\n",
              "      <td>88.5±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>81.3±0.4</td>\n",
              "      <td>82.1±0.3</td>\n",
              "      <td>75.6±0.6</td>\n",
              "      <td>77.6±0.5</td>\n",
              "      <td>82.0±0.5</td>\n",
              "      <td>82.7±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>98.4±0.1</td>\n",
              "      <td>98.4±0.1</td>\n",
              "      <td>95.3±1.8</td>\n",
              "      <td>98.1±0.1</td>\n",
              "      <td>97.7±0.1</td>\n",
              "      <td>98.1±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>83.7±0.2</td>\n",
              "      <td>84.0±0.3</td>\n",
              "      <td>79.6±1.1</td>\n",
              "      <td>82.1±0.7</td>\n",
              "      <td>81.3±0.3</td>\n",
              "      <td>82.7±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>97.1±0.2</td>\n",
              "      <td>96.6±0.2</td>\n",
              "      <td>97.3±0.2</td>\n",
              "      <td>97.1±0.2</td>\n",
              "      <td>95.9±0.3</td>\n",
              "      <td>96.9±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>90.7</td>\n",
              "      <td>90.9</td>\n",
              "      <td>86.3</td>\n",
              "      <td>89.6</td>\n",
              "      <td>90.3</td>\n",
              "      <td>91.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           pca      kpca     dsebm        ae       vae    ed-vae\n",
              "0     89.8±0.2  90.6±0.2  87.3±0.6  89.7±0.4  89.6±0.2  90.1±0.2\n",
              "1     98.5±0.1  98.2±0.1  78.4±4.2  98.0±0.2  98.2±0.1  98.5±0.1\n",
              "2     88.7±0.3  89.1±0.2  83.3±0.4  86.7±0.4  87.8±0.3  88.6±0.2\n",
              "3     91.9±0.2  92.6±0.4  91.3±0.5  90.5±0.5  91.6±0.2  92.1±0.2\n",
              "4     88.5±0.4  88.5±0.4  87.5±0.6  88.7±0.3  90.1±0.4  91.2±0.4\n",
              "5     88.6±0.3  88.8±0.3  87.2±0.3  87.6±0.2  88.5±0.3  88.5±0.2\n",
              "6     81.3±0.4  82.1±0.3  75.6±0.6  77.6±0.5  82.0±0.5  82.7±0.4\n",
              "7     98.4±0.1  98.4±0.1  95.3±1.8  98.1±0.1  97.7±0.1  98.1±0.1\n",
              "8     83.7±0.2  84.0±0.3  79.6±1.1  82.1±0.7  81.3±0.3  82.7±0.4\n",
              "9     97.1±0.2  96.6±0.2  97.3±0.2  97.1±0.2  95.9±0.3  96.9±0.2\n",
              "mean      90.7      90.9      86.3      89.6      90.3      91.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4Iq64We_WXg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "f55c161f-6bf7-410a-b71b-b6b5aecea58c"
      },
      "source": [
        "df.style.apply(highlight_max, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_45fae982_bf33_11eb_b6ae_0242ac1c0002row0_col1,#T_45fae982_bf33_11eb_b6ae_0242ac1c0002row1_col0,#T_45fae982_bf33_11eb_b6ae_0242ac1c0002row1_col5,#T_45fae982_bf33_11eb_b6ae_0242ac1c0002row2_col1,#T_45fae982_bf33_11eb_b6ae_0242ac1c0002row3_col1,#T_45fae982_bf33_11eb_b6ae_0242ac1c0002row4_col5,#T_45fae982_bf33_11eb_b6ae_0242ac1c0002row5_col1,#T_45fae982_bf33_11eb_b6ae_0242ac1c0002row6_col5,#T_45fae982_bf33_11eb_b6ae_0242ac1c0002row7_col0,#T_45fae982_bf33_11eb_b6ae_0242ac1c0002row7_col1,#T_45fae982_bf33_11eb_b6ae_0242ac1c0002row8_col1,#T_45fae982_bf33_11eb_b6ae_0242ac1c0002row9_col2,#T_45fae982_bf33_11eb_b6ae_0242ac1c0002row10_col5{\n",
              "            font-weight:  bold;\n",
              "        }</style><table id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >pca</th>        <th class=\"col_heading level0 col1\" >kpca</th>        <th class=\"col_heading level0 col2\" >dsebm</th>        <th class=\"col_heading level0 col3\" >ae</th>        <th class=\"col_heading level0 col4\" >vae</th>        <th class=\"col_heading level0 col5\" >ed-vae</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row0_col0\" class=\"data row0 col0\" >89.8±0.2</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row0_col1\" class=\"data row0 col1\" >90.6±0.2</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row0_col2\" class=\"data row0 col2\" >87.3±0.6</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row0_col3\" class=\"data row0 col3\" >89.7±0.4</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row0_col4\" class=\"data row0 col4\" >89.6±0.2</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row0_col5\" class=\"data row0 col5\" >90.1±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row1_col0\" class=\"data row1 col0\" >98.5±0.1</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row1_col1\" class=\"data row1 col1\" >98.2±0.1</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row1_col2\" class=\"data row1 col2\" >78.4±4.2</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row1_col3\" class=\"data row1 col3\" >98.0±0.2</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row1_col4\" class=\"data row1 col4\" >98.2±0.1</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row1_col5\" class=\"data row1 col5\" >98.5±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row2_col0\" class=\"data row2 col0\" >88.7±0.3</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row2_col1\" class=\"data row2 col1\" >89.1±0.2</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row2_col2\" class=\"data row2 col2\" >83.3±0.4</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row2_col3\" class=\"data row2 col3\" >86.7±0.4</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row2_col4\" class=\"data row2 col4\" >87.8±0.3</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row2_col5\" class=\"data row2 col5\" >88.6±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row3_col0\" class=\"data row3 col0\" >91.9±0.2</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row3_col1\" class=\"data row3 col1\" >92.6±0.4</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row3_col2\" class=\"data row3 col2\" >91.3±0.5</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row3_col3\" class=\"data row3 col3\" >90.5±0.5</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row3_col4\" class=\"data row3 col4\" >91.6±0.2</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row3_col5\" class=\"data row3 col5\" >92.1±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row4_col0\" class=\"data row4 col0\" >88.5±0.4</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row4_col1\" class=\"data row4 col1\" >88.5±0.4</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row4_col2\" class=\"data row4 col2\" >87.5±0.6</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row4_col3\" class=\"data row4 col3\" >88.7±0.3</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row4_col4\" class=\"data row4 col4\" >90.1±0.4</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row4_col5\" class=\"data row4 col5\" >91.2±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row5_col0\" class=\"data row5 col0\" >88.6±0.3</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row5_col1\" class=\"data row5 col1\" >88.8±0.3</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row5_col2\" class=\"data row5 col2\" >87.2±0.3</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row5_col3\" class=\"data row5 col3\" >87.6±0.2</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row5_col4\" class=\"data row5 col4\" >88.5±0.3</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row5_col5\" class=\"data row5 col5\" >88.5±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row6_col0\" class=\"data row6 col0\" >81.3±0.4</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row6_col1\" class=\"data row6 col1\" >82.1±0.3</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row6_col2\" class=\"data row6 col2\" >75.6±0.6</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row6_col3\" class=\"data row6 col3\" >77.6±0.5</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row6_col4\" class=\"data row6 col4\" >82.0±0.5</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row6_col5\" class=\"data row6 col5\" >82.7±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row7_col0\" class=\"data row7 col0\" >98.4±0.1</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row7_col1\" class=\"data row7 col1\" >98.4±0.1</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row7_col2\" class=\"data row7 col2\" >95.3±1.8</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row7_col3\" class=\"data row7 col3\" >98.1±0.1</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row7_col4\" class=\"data row7 col4\" >97.7±0.1</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row7_col5\" class=\"data row7 col5\" >98.1±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row8_col0\" class=\"data row8 col0\" >83.7±0.2</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row8_col1\" class=\"data row8 col1\" >84.0±0.3</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row8_col2\" class=\"data row8 col2\" >79.6±1.1</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row8_col3\" class=\"data row8 col3\" >82.1±0.7</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row8_col4\" class=\"data row8 col4\" >81.3±0.3</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row8_col5\" class=\"data row8 col5\" >82.7±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row9_col0\" class=\"data row9 col0\" >97.1±0.2</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row9_col1\" class=\"data row9 col1\" >96.6±0.2</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row9_col2\" class=\"data row9 col2\" >97.3±0.2</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row9_col3\" class=\"data row9 col3\" >97.1±0.2</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row9_col4\" class=\"data row9 col4\" >95.9±0.3</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row9_col5\" class=\"data row9 col5\" >96.9±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >mean</th>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row10_col0\" class=\"data row10 col0\" >90.7</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row10_col1\" class=\"data row10 col1\" >90.9</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row10_col2\" class=\"data row10 col2\" >86.3</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row10_col3\" class=\"data row10 col3\" >89.6</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row10_col4\" class=\"data row10 col4\" >90.3</td>\n",
              "                        <td id=\"T_45fae982_bf33_11eb_b6ae_0242ac1c0002row10_col5\" class=\"data row10 col5\" >91.0</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f6d5dae0490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PqgHo_YYNsk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "875e02d1-1df1-4b40-99cb-2807d9cdb597"
      },
      "source": [
        "# PR-AUC\n",
        "df = pd.DataFrame((\n",
        "    round(avg_pr_rec_final_results[column,'pr_auc_mean']*100,1).astype(str) + '±' + round(avg_pr_rec_final_results[column,'pr_auc_std']*100/np.sqrt(reps),1).astype(str) for column in avg_pr_rec_final_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_pr_rec_final_results.keys().get_level_values(0)[::2]).T\n",
        "df = df.append(pd.DataFrame((\n",
        "    #round(avg_pr_rec_class_results[column,'pr_auc_mean']*100,1).astype(str) + '±' + round(avg_pr_rec_class_results[column,'pr_auc_std']*100/np.sqrt(reps * len(df.index)),1).astype(str) for column in avg_pr_rec_class_results.keys().get_level_values(0)[::2]\n",
        "    round(avg_pr_rec_class_results[column,'pr_auc_mean']*100,1).astype(str) for column in avg_pr_rec_class_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_pr_rec_class_results.keys().get_level_values(0)[::2]).T)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pca</th>\n",
              "      <th>kpca</th>\n",
              "      <th>dsebm</th>\n",
              "      <th>ae</th>\n",
              "      <th>vae</th>\n",
              "      <th>ed-vae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>69.9±0.4</td>\n",
              "      <td>73.1±0.5</td>\n",
              "      <td>67.4±1.2</td>\n",
              "      <td>71.2±0.5</td>\n",
              "      <td>68.7±0.6</td>\n",
              "      <td>68.4±0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>94.0±0.2</td>\n",
              "      <td>93.4±0.2</td>\n",
              "      <td>63.9±5.3</td>\n",
              "      <td>91.9±0.7</td>\n",
              "      <td>93.7±0.2</td>\n",
              "      <td>94.3±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70.8±0.4</td>\n",
              "      <td>75.1±0.3</td>\n",
              "      <td>62.5±0.7</td>\n",
              "      <td>69.4±1.0</td>\n",
              "      <td>72.2±0.4</td>\n",
              "      <td>72.8±0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>79.3±0.6</td>\n",
              "      <td>82.9±0.6</td>\n",
              "      <td>81.6±0.7</td>\n",
              "      <td>80.2±0.8</td>\n",
              "      <td>80.1±0.6</td>\n",
              "      <td>80.6±0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>76.2±0.5</td>\n",
              "      <td>76.3±0.6</td>\n",
              "      <td>71.2±1.6</td>\n",
              "      <td>74.0±0.5</td>\n",
              "      <td>78.1±0.6</td>\n",
              "      <td>79.3±0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>82.5±0.3</td>\n",
              "      <td>81.1±0.2</td>\n",
              "      <td>76.6±0.5</td>\n",
              "      <td>76.3±0.3</td>\n",
              "      <td>81.0±0.3</td>\n",
              "      <td>80.3±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>59.9±0.7</td>\n",
              "      <td>62.4±0.7</td>\n",
              "      <td>47.0±1.5</td>\n",
              "      <td>50.9±0.7</td>\n",
              "      <td>63.1±0.7</td>\n",
              "      <td>63.5±0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>96.3±0.1</td>\n",
              "      <td>96.1±0.1</td>\n",
              "      <td>91.2±2.7</td>\n",
              "      <td>94.7±0.1</td>\n",
              "      <td>95.0±0.3</td>\n",
              "      <td>95.7±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>61.4±0.4</td>\n",
              "      <td>65.8±0.4</td>\n",
              "      <td>46.5±1.8</td>\n",
              "      <td>52.7±1.3</td>\n",
              "      <td>55.0±0.6</td>\n",
              "      <td>56.5±0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>93.2±0.4</td>\n",
              "      <td>91.3±0.4</td>\n",
              "      <td>91.1±0.6</td>\n",
              "      <td>91.8±0.9</td>\n",
              "      <td>90.5±0.5</td>\n",
              "      <td>91.5±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>78.4</td>\n",
              "      <td>79.8</td>\n",
              "      <td>69.9</td>\n",
              "      <td>75.3</td>\n",
              "      <td>77.7</td>\n",
              "      <td>78.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           pca      kpca     dsebm        ae       vae    ed-vae\n",
              "0     69.9±0.4  73.1±0.5  67.4±1.2  71.2±0.5  68.7±0.6  68.4±0.6\n",
              "1     94.0±0.2  93.4±0.2  63.9±5.3  91.9±0.7  93.7±0.2  94.3±0.2\n",
              "2     70.8±0.4  75.1±0.3  62.5±0.7  69.4±1.0  72.2±0.4  72.8±0.5\n",
              "3     79.3±0.6  82.9±0.6  81.6±0.7  80.2±0.8  80.1±0.6  80.6±0.5\n",
              "4     76.2±0.5  76.3±0.6  71.2±1.6  74.0±0.5  78.1±0.6  79.3±0.6\n",
              "5     82.5±0.3  81.1±0.2  76.6±0.5  76.3±0.3  81.0±0.3  80.3±0.2\n",
              "6     59.9±0.7  62.4±0.7  47.0±1.5  50.9±0.7  63.1±0.7  63.5±0.7\n",
              "7     96.3±0.1  96.1±0.1  91.2±2.7  94.7±0.1  95.0±0.3  95.7±0.2\n",
              "8     61.4±0.4  65.8±0.4  46.5±1.8  52.7±1.3  55.0±0.6  56.5±0.7\n",
              "9     93.2±0.4  91.3±0.4  91.1±0.6  91.8±0.9  90.5±0.5  91.5±0.4\n",
              "mean      78.4      79.8      69.9      75.3      77.7      78.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb0xXtt0_VxV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "2da09d8b-7e17-4545-f774-bceeaa43ce1e"
      },
      "source": [
        "df.style.apply(highlight_max, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row0_col1,#T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row1_col5,#T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row2_col1,#T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row3_col1,#T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row4_col5,#T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row5_col0,#T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row6_col5,#T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row7_col0,#T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row8_col1,#T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row9_col0,#T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row10_col1{\n",
              "            font-weight:  bold;\n",
              "        }</style><table id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >pca</th>        <th class=\"col_heading level0 col1\" >kpca</th>        <th class=\"col_heading level0 col2\" >dsebm</th>        <th class=\"col_heading level0 col3\" >ae</th>        <th class=\"col_heading level0 col4\" >vae</th>        <th class=\"col_heading level0 col5\" >ed-vae</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row0_col0\" class=\"data row0 col0\" >69.9±0.4</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row0_col1\" class=\"data row0 col1\" >73.1±0.5</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row0_col2\" class=\"data row0 col2\" >67.4±1.2</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row0_col3\" class=\"data row0 col3\" >71.2±0.5</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row0_col4\" class=\"data row0 col4\" >68.7±0.6</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row0_col5\" class=\"data row0 col5\" >68.4±0.6</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row1_col0\" class=\"data row1 col0\" >94.0±0.2</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row1_col1\" class=\"data row1 col1\" >93.4±0.2</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row1_col2\" class=\"data row1 col2\" >63.9±5.3</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row1_col3\" class=\"data row1 col3\" >91.9±0.7</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row1_col4\" class=\"data row1 col4\" >93.7±0.2</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row1_col5\" class=\"data row1 col5\" >94.3±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row2_col0\" class=\"data row2 col0\" >70.8±0.4</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row2_col1\" class=\"data row2 col1\" >75.1±0.3</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row2_col2\" class=\"data row2 col2\" >62.5±0.7</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row2_col3\" class=\"data row2 col3\" >69.4±1.0</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row2_col4\" class=\"data row2 col4\" >72.2±0.4</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row2_col5\" class=\"data row2 col5\" >72.8±0.5</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row3_col0\" class=\"data row3 col0\" >79.3±0.6</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row3_col1\" class=\"data row3 col1\" >82.9±0.6</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row3_col2\" class=\"data row3 col2\" >81.6±0.7</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row3_col3\" class=\"data row3 col3\" >80.2±0.8</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row3_col4\" class=\"data row3 col4\" >80.1±0.6</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row3_col5\" class=\"data row3 col5\" >80.6±0.5</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row4_col0\" class=\"data row4 col0\" >76.2±0.5</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row4_col1\" class=\"data row4 col1\" >76.3±0.6</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row4_col2\" class=\"data row4 col2\" >71.2±1.6</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row4_col3\" class=\"data row4 col3\" >74.0±0.5</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row4_col4\" class=\"data row4 col4\" >78.1±0.6</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row4_col5\" class=\"data row4 col5\" >79.3±0.6</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row5_col0\" class=\"data row5 col0\" >82.5±0.3</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row5_col1\" class=\"data row5 col1\" >81.1±0.2</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row5_col2\" class=\"data row5 col2\" >76.6±0.5</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row5_col3\" class=\"data row5 col3\" >76.3±0.3</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row5_col4\" class=\"data row5 col4\" >81.0±0.3</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row5_col5\" class=\"data row5 col5\" >80.3±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row6_col0\" class=\"data row6 col0\" >59.9±0.7</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row6_col1\" class=\"data row6 col1\" >62.4±0.7</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row6_col2\" class=\"data row6 col2\" >47.0±1.5</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row6_col3\" class=\"data row6 col3\" >50.9±0.7</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row6_col4\" class=\"data row6 col4\" >63.1±0.7</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row6_col5\" class=\"data row6 col5\" >63.5±0.7</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row7_col0\" class=\"data row7 col0\" >96.3±0.1</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row7_col1\" class=\"data row7 col1\" >96.1±0.1</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row7_col2\" class=\"data row7 col2\" >91.2±2.7</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row7_col3\" class=\"data row7 col3\" >94.7±0.1</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row7_col4\" class=\"data row7 col4\" >95.0±0.3</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row7_col5\" class=\"data row7 col5\" >95.7±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row8_col0\" class=\"data row8 col0\" >61.4±0.4</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row8_col1\" class=\"data row8 col1\" >65.8±0.4</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row8_col2\" class=\"data row8 col2\" >46.5±1.8</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row8_col3\" class=\"data row8 col3\" >52.7±1.3</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row8_col4\" class=\"data row8 col4\" >55.0±0.6</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row8_col5\" class=\"data row8 col5\" >56.5±0.7</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row9_col0\" class=\"data row9 col0\" >93.2±0.4</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row9_col1\" class=\"data row9 col1\" >91.3±0.4</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row9_col2\" class=\"data row9 col2\" >91.1±0.6</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row9_col3\" class=\"data row9 col3\" >91.8±0.9</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row9_col4\" class=\"data row9 col4\" >90.5±0.5</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row9_col5\" class=\"data row9 col5\" >91.5±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >mean</th>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row10_col0\" class=\"data row10 col0\" >78.4</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row10_col1\" class=\"data row10 col1\" >79.8</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row10_col2\" class=\"data row10 col2\" >69.9</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row10_col3\" class=\"data row10 col3\" >75.3</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row10_col4\" class=\"data row10 col4\" >77.7</td>\n",
              "                        <td id=\"T_45eefb9a_bf33_11eb_b6ae_0242ac1c0002row10_col5\" class=\"data row10 col5\" >78.3</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f6d5da47950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fx4aOFCn6Oi"
      },
      "source": [
        "# Results - ED-VAE vs. VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJFMhZDan6Ok"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQzHFiI2n6Ok"
      },
      "source": [
        "index_labels = normal_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUMzjU1xXE7W"
      },
      "source": [
        "avg_results = np.mean(results, axis=0)\n",
        "std_results = np.std(results, axis=0)\n",
        "avg_class_results = np.mean(results, axis=(0, 1))\n",
        "std_class_results = np.std(results, axis=(0, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj39c6vCU5S7"
      },
      "source": [
        "avg_results = avg_results[:,4:6]\n",
        "std_results = std_results[:,4:6]\n",
        "avg_class_results = avg_class_results[4:6]\n",
        "std_class_results = std_class_results[4:6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lOSYEitn6Ok"
      },
      "source": [
        "pr_header = [np.array(['vae', 'vae',             \n",
        "                    'ed-vae', 'ed-vae',\n",
        "                    ]), \n",
        "np.array(['pr_auc_mean','pr_auc_std',\n",
        "          'pr_auc_mean','pr_auc_std',\n",
        "          ])] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwu4Lynin6Ol"
      },
      "source": [
        "auc_header = [np.array([\n",
        "                    'vae', 'vae',\n",
        "                    'ed-vae', 'ed-vae',\n",
        "                    ]), \n",
        "np.array(['auc_mean','auc_std',\n",
        "          'auc_mean','auc_std',\n",
        "          ])] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7F1TOjVn6Om"
      },
      "source": [
        "### $ELBO$ \n",
        "Compare ELBO of VAE and ED-VAE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHgn949xn6Om",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "ea420eb9-ec78-4904-e784-5a634abcf274"
      },
      "source": [
        "# AUC\n",
        "avg_auc_elbo_class_results = pd.DataFrame((avg_class_results[0,3], std_class_results[0,3], \n",
        "                                  avg_class_results[1,3], std_class_results[1,3],\n",
        "                                  ), \n",
        "                                  index = auc_header).T\n",
        "avg_auc_elbo_class_results = avg_auc_elbo_class_results.rename(index={0: \"mean\"})\n",
        "avg_auc_elbo_final_results = pd.DataFrame((avg_results[:,0,3], std_results[:,0,3],\n",
        "                                  avg_results[:,1,3], std_results[:,1,3], \n",
        "                                  ), \n",
        "                                  index = auc_header, columns = index_labels).T\n",
        "avg_auc_elbo_final_results.append(avg_auc_elbo_class_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">vae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ed-vae</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.906740</td>\n",
              "      <td>0.007390</td>\n",
              "      <td>0.911173</td>\n",
              "      <td>0.007674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.985576</td>\n",
              "      <td>0.002004</td>\n",
              "      <td>0.987114</td>\n",
              "      <td>0.001906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.884042</td>\n",
              "      <td>0.007990</td>\n",
              "      <td>0.891146</td>\n",
              "      <td>0.007604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.924055</td>\n",
              "      <td>0.009302</td>\n",
              "      <td>0.927871</td>\n",
              "      <td>0.008745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.899538</td>\n",
              "      <td>0.013268</td>\n",
              "      <td>0.908718</td>\n",
              "      <td>0.013040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.893064</td>\n",
              "      <td>0.008791</td>\n",
              "      <td>0.895072</td>\n",
              "      <td>0.007228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.823253</td>\n",
              "      <td>0.012089</td>\n",
              "      <td>0.830588</td>\n",
              "      <td>0.011563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.982244</td>\n",
              "      <td>0.003357</td>\n",
              "      <td>0.985006</td>\n",
              "      <td>0.002306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.835084</td>\n",
              "      <td>0.011485</td>\n",
              "      <td>0.848064</td>\n",
              "      <td>0.012047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.963205</td>\n",
              "      <td>0.007989</td>\n",
              "      <td>0.970858</td>\n",
              "      <td>0.006165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.909680</td>\n",
              "      <td>0.053844</td>\n",
              "      <td>0.915561</td>\n",
              "      <td>0.051721</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           vae              ed-vae          \n",
              "      auc_mean   auc_std  auc_mean   auc_std\n",
              "0     0.906740  0.007390  0.911173  0.007674\n",
              "1     0.985576  0.002004  0.987114  0.001906\n",
              "2     0.884042  0.007990  0.891146  0.007604\n",
              "3     0.924055  0.009302  0.927871  0.008745\n",
              "4     0.899538  0.013268  0.908718  0.013040\n",
              "5     0.893064  0.008791  0.895072  0.007228\n",
              "6     0.823253  0.012089  0.830588  0.011563\n",
              "7     0.982244  0.003357  0.985006  0.002306\n",
              "8     0.835084  0.011485  0.848064  0.012047\n",
              "9     0.963205  0.007989  0.970858  0.006165\n",
              "mean  0.909680  0.053844  0.915561  0.051721"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeysyUvDn6Om",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "f976773d-d188-4abd-f263-351fb22e1d04"
      },
      "source": [
        "# PR-AUC\n",
        "avg_pr_elbo_class_results = pd.DataFrame((avg_class_results[0,2], std_class_results[0,2], \n",
        "                                  avg_class_results[1,2], std_class_results[1,2],\n",
        "                                  ), \n",
        "                                  index = pr_header).T\n",
        "avg_pr_elbo_class_results = avg_pr_elbo_class_results.rename(index={0: \"mean\"})\n",
        "avg_pr_elbo_final_results = pd.DataFrame((avg_results[:,0,2], std_results[:,0,2],\n",
        "                                  avg_results[:,1,2], std_results[:,1,2],\n",
        "                                  ), \n",
        "                                  index = pr_header, columns = index_labels).T\n",
        "avg_pr_elbo_final_results.append(avg_pr_elbo_class_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">vae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ed-vae</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.722367</td>\n",
              "      <td>0.016622</td>\n",
              "      <td>0.721989</td>\n",
              "      <td>0.018962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.944248</td>\n",
              "      <td>0.007205</td>\n",
              "      <td>0.947529</td>\n",
              "      <td>0.007014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.741947</td>\n",
              "      <td>0.010923</td>\n",
              "      <td>0.749466</td>\n",
              "      <td>0.012310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.824475</td>\n",
              "      <td>0.018503</td>\n",
              "      <td>0.828265</td>\n",
              "      <td>0.018536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.786449</td>\n",
              "      <td>0.018267</td>\n",
              "      <td>0.799682</td>\n",
              "      <td>0.017247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.816291</td>\n",
              "      <td>0.007996</td>\n",
              "      <td>0.811389</td>\n",
              "      <td>0.007388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.639569</td>\n",
              "      <td>0.023570</td>\n",
              "      <td>0.645248</td>\n",
              "      <td>0.022122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.958223</td>\n",
              "      <td>0.006442</td>\n",
              "      <td>0.962574</td>\n",
              "      <td>0.004556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.592811</td>\n",
              "      <td>0.020648</td>\n",
              "      <td>0.608472</td>\n",
              "      <td>0.021543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.910692</td>\n",
              "      <td>0.014042</td>\n",
              "      <td>0.919511</td>\n",
              "      <td>0.011703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.793707</td>\n",
              "      <td>0.117990</td>\n",
              "      <td>0.799412</td>\n",
              "      <td>0.116207</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             vae                 ed-vae           \n",
              "     pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std\n",
              "0       0.722367   0.016622    0.721989   0.018962\n",
              "1       0.944248   0.007205    0.947529   0.007014\n",
              "2       0.741947   0.010923    0.749466   0.012310\n",
              "3       0.824475   0.018503    0.828265   0.018536\n",
              "4       0.786449   0.018267    0.799682   0.017247\n",
              "5       0.816291   0.007996    0.811389   0.007388\n",
              "6       0.639569   0.023570    0.645248   0.022122\n",
              "7       0.958223   0.006442    0.962574   0.004556\n",
              "8       0.592811   0.020648    0.608472   0.021543\n",
              "9       0.910692   0.014042    0.919511   0.011703\n",
              "mean    0.793707   0.117990    0.799412   0.116207"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToWIOp_gn6Ol"
      },
      "source": [
        "### $R_{error}$ \n",
        "Compare Reconstruction Error of VAE and ED-VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk77PCc8n6Ol",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "ecf792fb-1d8c-4a66-e902-828d751c1ee4"
      },
      "source": [
        "# AUC\n",
        "avg_auc_rec_class_results = pd.DataFrame((avg_class_results[0,1], std_class_results[0,1], \n",
        "                                  avg_class_results[1,1], std_class_results[1,1],\n",
        "                                  ), \n",
        "                                  index = auc_header).T\n",
        "avg_auc_rec_class_results = avg_auc_rec_class_results.rename(index={0: \"mean\"})\n",
        "avg_auc_rec_final_results = pd.DataFrame((avg_results[:,0,1], std_results[:,0,1], \n",
        "                                  avg_results[:,1,1], std_results[:,1,1],\n",
        "                                  ), \n",
        "                                  index = auc_header, columns = index_labels).T\n",
        "avg_auc_rec_final_results.append(avg_auc_rec_class_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">vae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ed-vae</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.896063</td>\n",
              "      <td>0.007094</td>\n",
              "      <td>0.901122</td>\n",
              "      <td>0.007483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.982152</td>\n",
              "      <td>0.002555</td>\n",
              "      <td>0.985460</td>\n",
              "      <td>0.002292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.878164</td>\n",
              "      <td>0.008535</td>\n",
              "      <td>0.886226</td>\n",
              "      <td>0.007555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.915553</td>\n",
              "      <td>0.007754</td>\n",
              "      <td>0.920695</td>\n",
              "      <td>0.007345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.901077</td>\n",
              "      <td>0.013091</td>\n",
              "      <td>0.911860</td>\n",
              "      <td>0.012613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.884665</td>\n",
              "      <td>0.008748</td>\n",
              "      <td>0.885300</td>\n",
              "      <td>0.007125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.819804</td>\n",
              "      <td>0.014603</td>\n",
              "      <td>0.826755</td>\n",
              "      <td>0.013618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.977047</td>\n",
              "      <td>0.004266</td>\n",
              "      <td>0.981493</td>\n",
              "      <td>0.002973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.812620</td>\n",
              "      <td>0.010624</td>\n",
              "      <td>0.827066</td>\n",
              "      <td>0.011497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.959224</td>\n",
              "      <td>0.010769</td>\n",
              "      <td>0.969056</td>\n",
              "      <td>0.007599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.902637</td>\n",
              "      <td>0.056620</td>\n",
              "      <td>0.909503</td>\n",
              "      <td>0.054988</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           vae              ed-vae          \n",
              "      auc_mean   auc_std  auc_mean   auc_std\n",
              "0     0.896063  0.007094  0.901122  0.007483\n",
              "1     0.982152  0.002555  0.985460  0.002292\n",
              "2     0.878164  0.008535  0.886226  0.007555\n",
              "3     0.915553  0.007754  0.920695  0.007345\n",
              "4     0.901077  0.013091  0.911860  0.012613\n",
              "5     0.884665  0.008748  0.885300  0.007125\n",
              "6     0.819804  0.014603  0.826755  0.013618\n",
              "7     0.977047  0.004266  0.981493  0.002973\n",
              "8     0.812620  0.010624  0.827066  0.011497\n",
              "9     0.959224  0.010769  0.969056  0.007599\n",
              "mean  0.902637  0.056620  0.909503  0.054988"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXvMmzqAn6Ol",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "9aff9cec-1f50-4b18-bf5d-7a37be86f313"
      },
      "source": [
        "# PR-AUC\n",
        "avg_pr_rec_class_results = pd.DataFrame((avg_class_results[0,0], std_class_results[0,0], \n",
        "                                  avg_class_results[1,0], std_class_results[1,0],\n",
        "                                  ), \n",
        "                                  index = pr_header).T\n",
        "avg_pr_rec_class_results = avg_pr_rec_class_results.rename(index={0: \"mean\"})\n",
        "avg_pr_rec_final_results = pd.DataFrame((avg_results[:,0,0], std_results[:,0,0], \n",
        "                                  avg_results[:,1,0], std_results[:,1,0],\n",
        "                                  ), \n",
        "                                  index = pr_header, columns = index_labels).T\n",
        "avg_pr_rec_final_results.append(avg_pr_rec_class_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">vae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ed-vae</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.686710</td>\n",
              "      <td>0.017583</td>\n",
              "      <td>0.683710</td>\n",
              "      <td>0.019027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.936850</td>\n",
              "      <td>0.007662</td>\n",
              "      <td>0.943020</td>\n",
              "      <td>0.007366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.721591</td>\n",
              "      <td>0.013055</td>\n",
              "      <td>0.727865</td>\n",
              "      <td>0.014579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.801492</td>\n",
              "      <td>0.017408</td>\n",
              "      <td>0.805554</td>\n",
              "      <td>0.017027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.780542</td>\n",
              "      <td>0.019491</td>\n",
              "      <td>0.793460</td>\n",
              "      <td>0.018910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.809740</td>\n",
              "      <td>0.008844</td>\n",
              "      <td>0.802923</td>\n",
              "      <td>0.007537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.631358</td>\n",
              "      <td>0.022082</td>\n",
              "      <td>0.635030</td>\n",
              "      <td>0.021455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.950122</td>\n",
              "      <td>0.008087</td>\n",
              "      <td>0.956836</td>\n",
              "      <td>0.005809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.549982</td>\n",
              "      <td>0.020126</td>\n",
              "      <td>0.564549</td>\n",
              "      <td>0.021504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.904508</td>\n",
              "      <td>0.016123</td>\n",
              "      <td>0.914632</td>\n",
              "      <td>0.013445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.777290</td>\n",
              "      <td>0.126473</td>\n",
              "      <td>0.782758</td>\n",
              "      <td>0.126155</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             vae                 ed-vae           \n",
              "     pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std\n",
              "0       0.686710   0.017583    0.683710   0.019027\n",
              "1       0.936850   0.007662    0.943020   0.007366\n",
              "2       0.721591   0.013055    0.727865   0.014579\n",
              "3       0.801492   0.017408    0.805554   0.017027\n",
              "4       0.780542   0.019491    0.793460   0.018910\n",
              "5       0.809740   0.008844    0.802923   0.007537\n",
              "6       0.631358   0.022082    0.635030   0.021455\n",
              "7       0.950122   0.008087    0.956836   0.005809\n",
              "8       0.549982   0.020126    0.564549   0.021504\n",
              "9       0.904508   0.016123    0.914632   0.013445\n",
              "mean    0.777290   0.126473    0.782758   0.126155"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7OjI1hRnpgq"
      },
      "source": [
        "## Formated for Publication\n",
        "Mean and SEM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwvN9KbJnpgs"
      },
      "source": [
        "#### $ELBO$ \n",
        "Compare ELBO of VAE and ED-VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT6XAfk0npgw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "f468b08f-55c2-4cf1-9129-8e465daaead2"
      },
      "source": [
        "# AUC\n",
        "df = pd.DataFrame((\n",
        "    round(avg_auc_elbo_final_results[column,'auc_mean']*100,1).astype(str) + '±' + round(avg_auc_elbo_final_results[column,'auc_std']*100/np.sqrt(reps),1).astype(str) for column in avg_auc_elbo_final_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_auc_elbo_final_results.keys().get_level_values(0)[::2]).T\n",
        "df = df.append(pd.DataFrame((\n",
        "    #round(avg_auc_elbo_class_results[column,'auc_mean']*100,1).astype(str) + '±' + round(avg_auc_elbo_class_results[column,'pr_auc_std']*100/np.sqrt(reps * len(df.index)),1).astype(str) for column in avg_auc_elbo_class_results.keys().get_level_values(0)[::2]\n",
        "    round(avg_auc_elbo_class_results[column,'auc_mean']*100,1).astype(str) for column in avg_auc_elbo_class_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_auc_elbo_class_results.keys().get_level_values(0)[::2]).T)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vae</th>\n",
              "      <th>ed-vae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>90.7±0.2</td>\n",
              "      <td>91.1±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98.6±0.1</td>\n",
              "      <td>98.7±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>88.4±0.3</td>\n",
              "      <td>89.1±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>92.4±0.3</td>\n",
              "      <td>92.8±0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>90.0±0.4</td>\n",
              "      <td>90.9±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>89.3±0.3</td>\n",
              "      <td>89.5±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>82.3±0.4</td>\n",
              "      <td>83.1±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>98.2±0.1</td>\n",
              "      <td>98.5±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>83.5±0.4</td>\n",
              "      <td>84.8±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>96.3±0.3</td>\n",
              "      <td>97.1±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>91.0</td>\n",
              "      <td>91.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           vae    ed-vae\n",
              "0     90.7±0.2  91.1±0.2\n",
              "1     98.6±0.1  98.7±0.1\n",
              "2     88.4±0.3  89.1±0.2\n",
              "3     92.4±0.3  92.8±0.3\n",
              "4     90.0±0.4  90.9±0.4\n",
              "5     89.3±0.3  89.5±0.2\n",
              "6     82.3±0.4  83.1±0.4\n",
              "7     98.2±0.1  98.5±0.1\n",
              "8     83.5±0.4  84.8±0.4\n",
              "9     96.3±0.3  97.1±0.2\n",
              "mean      91.0      91.6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs-rtL8Pnpgx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "cd612a07-7f25-4f8b-9bcf-82d2f2e18d0f"
      },
      "source": [
        "df.style.apply(highlight_max, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_480d2028_bf33_11eb_b6ae_0242ac1c0002row0_col1,#T_480d2028_bf33_11eb_b6ae_0242ac1c0002row1_col1,#T_480d2028_bf33_11eb_b6ae_0242ac1c0002row2_col1,#T_480d2028_bf33_11eb_b6ae_0242ac1c0002row3_col1,#T_480d2028_bf33_11eb_b6ae_0242ac1c0002row4_col1,#T_480d2028_bf33_11eb_b6ae_0242ac1c0002row5_col1,#T_480d2028_bf33_11eb_b6ae_0242ac1c0002row6_col1,#T_480d2028_bf33_11eb_b6ae_0242ac1c0002row7_col1,#T_480d2028_bf33_11eb_b6ae_0242ac1c0002row8_col1,#T_480d2028_bf33_11eb_b6ae_0242ac1c0002row9_col1,#T_480d2028_bf33_11eb_b6ae_0242ac1c0002row10_col1{\n",
              "            font-weight:  bold;\n",
              "        }</style><table id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >vae</th>        <th class=\"col_heading level0 col1\" >ed-vae</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row0_col0\" class=\"data row0 col0\" >90.7±0.2</td>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row0_col1\" class=\"data row0 col1\" >91.1±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row1_col0\" class=\"data row1 col0\" >98.6±0.1</td>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row1_col1\" class=\"data row1 col1\" >98.7±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row2_col0\" class=\"data row2 col0\" >88.4±0.3</td>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row2_col1\" class=\"data row2 col1\" >89.1±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row3_col0\" class=\"data row3 col0\" >92.4±0.3</td>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row3_col1\" class=\"data row3 col1\" >92.8±0.3</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row4_col0\" class=\"data row4 col0\" >90.0±0.4</td>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row4_col1\" class=\"data row4 col1\" >90.9±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row5_col0\" class=\"data row5 col0\" >89.3±0.3</td>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row5_col1\" class=\"data row5 col1\" >89.5±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row6_col0\" class=\"data row6 col0\" >82.3±0.4</td>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row6_col1\" class=\"data row6 col1\" >83.1±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row7_col0\" class=\"data row7 col0\" >98.2±0.1</td>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row7_col1\" class=\"data row7 col1\" >98.5±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row8_col0\" class=\"data row8 col0\" >83.5±0.4</td>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row8_col1\" class=\"data row8 col1\" >84.8±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row9_col0\" class=\"data row9 col0\" >96.3±0.3</td>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row9_col1\" class=\"data row9 col1\" >97.1±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >mean</th>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row10_col0\" class=\"data row10 col0\" >91.0</td>\n",
              "                        <td id=\"T_480d2028_bf33_11eb_b6ae_0242ac1c0002row10_col1\" class=\"data row10 col1\" >91.6</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f6d5c6ac3d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs_ceZCCnpgw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "5a6d4ca7-08f8-4527-8624-bc6fac4f799c"
      },
      "source": [
        "# PR-AUC\n",
        "df = pd.DataFrame((\n",
        "    round(avg_pr_elbo_final_results[column,'pr_auc_mean']*100,1).astype(str) + '±' + round(avg_pr_elbo_final_results[column,'pr_auc_std']*100/np.sqrt(reps),1).astype(str) for column in avg_pr_elbo_final_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_pr_elbo_final_results.keys().get_level_values(0)[::2]).T  \n",
        "df = df.append(pd.DataFrame((\n",
        "    #round(avg_pr_elbo_class_results[column,'pr_auc_mean']*100,1).astype(str) + '±' + round(avg_pr_elbo_class_results[column,'pr_auc_std']*100/np.sqrt(reps * len(df.index)),1).astype(str) for column in avg_pr_elbo_class_results.keys().get_level_values(0)[::2]\n",
        "    round(avg_pr_elbo_class_results[column,'pr_auc_mean']*100,1).astype(str) for column in avg_pr_elbo_class_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_pr_elbo_class_results.keys().get_level_values(0)[::2]).T)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vae</th>\n",
              "      <th>ed-vae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>72.2±0.5</td>\n",
              "      <td>72.2±0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>94.4±0.2</td>\n",
              "      <td>94.8±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>74.2±0.3</td>\n",
              "      <td>74.9±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>82.4±0.6</td>\n",
              "      <td>82.8±0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>78.6±0.6</td>\n",
              "      <td>80.0±0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>81.6±0.3</td>\n",
              "      <td>81.1±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>64.0±0.7</td>\n",
              "      <td>64.5±0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>95.8±0.2</td>\n",
              "      <td>96.3±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>59.3±0.7</td>\n",
              "      <td>60.8±0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>91.1±0.4</td>\n",
              "      <td>92.0±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>79.4</td>\n",
              "      <td>79.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           vae    ed-vae\n",
              "0     72.2±0.5  72.2±0.6\n",
              "1     94.4±0.2  94.8±0.2\n",
              "2     74.2±0.3  74.9±0.4\n",
              "3     82.4±0.6  82.8±0.6\n",
              "4     78.6±0.6  80.0±0.5\n",
              "5     81.6±0.3  81.1±0.2\n",
              "6     64.0±0.7  64.5±0.7\n",
              "7     95.8±0.2  96.3±0.1\n",
              "8     59.3±0.7  60.8±0.7\n",
              "9     91.1±0.4  92.0±0.4\n",
              "mean      79.4      79.9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rJfWOCqnpgw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "cebca0ae-ff5b-4c24-83e4-5af48726cb67"
      },
      "source": [
        "df.style.apply(highlight_max, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_4801172e_bf33_11eb_b6ae_0242ac1c0002row0_col0,#T_4801172e_bf33_11eb_b6ae_0242ac1c0002row0_col1,#T_4801172e_bf33_11eb_b6ae_0242ac1c0002row1_col1,#T_4801172e_bf33_11eb_b6ae_0242ac1c0002row2_col1,#T_4801172e_bf33_11eb_b6ae_0242ac1c0002row3_col1,#T_4801172e_bf33_11eb_b6ae_0242ac1c0002row4_col1,#T_4801172e_bf33_11eb_b6ae_0242ac1c0002row5_col0,#T_4801172e_bf33_11eb_b6ae_0242ac1c0002row6_col1,#T_4801172e_bf33_11eb_b6ae_0242ac1c0002row7_col1,#T_4801172e_bf33_11eb_b6ae_0242ac1c0002row8_col1,#T_4801172e_bf33_11eb_b6ae_0242ac1c0002row9_col1,#T_4801172e_bf33_11eb_b6ae_0242ac1c0002row10_col1{\n",
              "            font-weight:  bold;\n",
              "        }</style><table id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >vae</th>        <th class=\"col_heading level0 col1\" >ed-vae</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row0_col0\" class=\"data row0 col0\" >72.2±0.5</td>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row0_col1\" class=\"data row0 col1\" >72.2±0.6</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row1_col0\" class=\"data row1 col0\" >94.4±0.2</td>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row1_col1\" class=\"data row1 col1\" >94.8±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row2_col0\" class=\"data row2 col0\" >74.2±0.3</td>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row2_col1\" class=\"data row2 col1\" >74.9±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row3_col0\" class=\"data row3 col0\" >82.4±0.6</td>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row3_col1\" class=\"data row3 col1\" >82.8±0.6</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row4_col0\" class=\"data row4 col0\" >78.6±0.6</td>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row4_col1\" class=\"data row4 col1\" >80.0±0.5</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row5_col0\" class=\"data row5 col0\" >81.6±0.3</td>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row5_col1\" class=\"data row5 col1\" >81.1±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row6_col0\" class=\"data row6 col0\" >64.0±0.7</td>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row6_col1\" class=\"data row6 col1\" >64.5±0.7</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row7_col0\" class=\"data row7 col0\" >95.8±0.2</td>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row7_col1\" class=\"data row7 col1\" >96.3±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row8_col0\" class=\"data row8 col0\" >59.3±0.7</td>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row8_col1\" class=\"data row8 col1\" >60.8±0.7</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row9_col0\" class=\"data row9 col0\" >91.1±0.4</td>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row9_col1\" class=\"data row9 col1\" >92.0±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >mean</th>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row10_col0\" class=\"data row10 col0\" >79.4</td>\n",
              "                        <td id=\"T_4801172e_bf33_11eb_b6ae_0242ac1c0002row10_col1\" class=\"data row10 col1\" >79.9</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f6d5c1a1ad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW6jgjyvnpgx"
      },
      "source": [
        "### $R_{error}$\n",
        "Compare Reconstruction Error of VAE and ED-VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyX16C3ynpgz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "278ec758-83a4-4ac0-9b6c-6b74a1c7548f"
      },
      "source": [
        "# AUC\n",
        "df = pd.DataFrame((\n",
        "    round(avg_auc_rec_final_results[column,'auc_mean']*100,1).astype(str) + '±' + round(avg_auc_rec_final_results[column,'auc_std']*100/np.sqrt(reps),1).astype(str) for column in avg_auc_rec_final_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_auc_rec_final_results.keys().get_level_values(0)[::2]).T\n",
        "df = df.append(pd.DataFrame((\n",
        "    #round(avg_auc_rec_class_results[column,'auc_mean']*100,1).astype(str) + '±' + round(avg_auc_rec_class_results[column,'pr_auc_std']*100/np.sqrt(reps * len(df.index)),1).astype(str) for column in avg_auc_rec_class_results.keys().get_level_values(0)[::2]\n",
        "    round(avg_auc_rec_class_results[column,'auc_mean']*100,1).astype(str) for column in avg_auc_rec_class_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_auc_rec_class_results.keys().get_level_values(0)[::2]).T)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vae</th>\n",
              "      <th>ed-vae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>89.6±0.2</td>\n",
              "      <td>90.1±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98.2±0.1</td>\n",
              "      <td>98.5±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>87.8±0.3</td>\n",
              "      <td>88.6±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91.6±0.2</td>\n",
              "      <td>92.1±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>90.1±0.4</td>\n",
              "      <td>91.2±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>88.5±0.3</td>\n",
              "      <td>88.5±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>82.0±0.5</td>\n",
              "      <td>82.7±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>97.7±0.1</td>\n",
              "      <td>98.1±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>81.3±0.3</td>\n",
              "      <td>82.7±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>95.9±0.3</td>\n",
              "      <td>96.9±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>90.3</td>\n",
              "      <td>91.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           vae    ed-vae\n",
              "0     89.6±0.2  90.1±0.2\n",
              "1     98.2±0.1  98.5±0.1\n",
              "2     87.8±0.3  88.6±0.2\n",
              "3     91.6±0.2  92.1±0.2\n",
              "4     90.1±0.4  91.2±0.4\n",
              "5     88.5±0.3  88.5±0.2\n",
              "6     82.0±0.5  82.7±0.4\n",
              "7     97.7±0.1  98.1±0.1\n",
              "8     81.3±0.3  82.7±0.4\n",
              "9     95.9±0.3  96.9±0.2\n",
              "mean      90.3      91.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zZv0rPOnpg0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "a9a8d2d2-3bee-40a7-d947-8a063a7cd0fa"
      },
      "source": [
        "df.style.apply(highlight_max, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_48608c22_bf33_11eb_b6ae_0242ac1c0002row0_col1,#T_48608c22_bf33_11eb_b6ae_0242ac1c0002row1_col1,#T_48608c22_bf33_11eb_b6ae_0242ac1c0002row2_col1,#T_48608c22_bf33_11eb_b6ae_0242ac1c0002row3_col1,#T_48608c22_bf33_11eb_b6ae_0242ac1c0002row4_col1,#T_48608c22_bf33_11eb_b6ae_0242ac1c0002row5_col0,#T_48608c22_bf33_11eb_b6ae_0242ac1c0002row5_col1,#T_48608c22_bf33_11eb_b6ae_0242ac1c0002row6_col1,#T_48608c22_bf33_11eb_b6ae_0242ac1c0002row7_col1,#T_48608c22_bf33_11eb_b6ae_0242ac1c0002row8_col1,#T_48608c22_bf33_11eb_b6ae_0242ac1c0002row9_col1,#T_48608c22_bf33_11eb_b6ae_0242ac1c0002row10_col1{\n",
              "            font-weight:  bold;\n",
              "        }</style><table id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >vae</th>        <th class=\"col_heading level0 col1\" >ed-vae</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row0_col0\" class=\"data row0 col0\" >89.6±0.2</td>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row0_col1\" class=\"data row0 col1\" >90.1±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row1_col0\" class=\"data row1 col0\" >98.2±0.1</td>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row1_col1\" class=\"data row1 col1\" >98.5±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row2_col0\" class=\"data row2 col0\" >87.8±0.3</td>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row2_col1\" class=\"data row2 col1\" >88.6±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row3_col0\" class=\"data row3 col0\" >91.6±0.2</td>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row3_col1\" class=\"data row3 col1\" >92.1±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row4_col0\" class=\"data row4 col0\" >90.1±0.4</td>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row4_col1\" class=\"data row4 col1\" >91.2±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row5_col0\" class=\"data row5 col0\" >88.5±0.3</td>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row5_col1\" class=\"data row5 col1\" >88.5±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row6_col0\" class=\"data row6 col0\" >82.0±0.5</td>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row6_col1\" class=\"data row6 col1\" >82.7±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row7_col0\" class=\"data row7 col0\" >97.7±0.1</td>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row7_col1\" class=\"data row7 col1\" >98.1±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row8_col0\" class=\"data row8 col0\" >81.3±0.3</td>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row8_col1\" class=\"data row8 col1\" >82.7±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row9_col0\" class=\"data row9 col0\" >95.9±0.3</td>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row9_col1\" class=\"data row9 col1\" >96.9±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >mean</th>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row10_col0\" class=\"data row10 col0\" >90.3</td>\n",
              "                        <td id=\"T_48608c22_bf33_11eb_b6ae_0242ac1c0002row10_col1\" class=\"data row10 col1\" >91.0</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f6d5c2bb090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgo09D1Wnpgz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "09d12149-5585-49dd-9db8-d9fab51d9e1d"
      },
      "source": [
        "# PR-AUC\n",
        "df = pd.DataFrame((\n",
        "    round(avg_pr_rec_final_results[column,'pr_auc_mean']*100,1).astype(str) + '±' + round(avg_pr_rec_final_results[column,'pr_auc_std']*100/np.sqrt(reps),1).astype(str) for column in avg_pr_rec_final_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_pr_rec_final_results.keys().get_level_values(0)[::2]).T\n",
        "df = df.append(pd.DataFrame((\n",
        "    #round(avg_pr_rec_class_results[column,'pr_auc_mean']*100,1).astype(str) + '±' + round(avg_pr_rec_class_results[column,'pr_auc_std']*100/np.sqrt(reps * len(df.index)),1).astype(str) for column in avg_pr_rec_class_results.keys().get_level_values(0)[::2]\n",
        "    round(avg_pr_rec_class_results[column,'pr_auc_mean']*100,1).astype(str) for column in avg_pr_rec_class_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_pr_rec_class_results.keys().get_level_values(0)[::2]).T)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vae</th>\n",
              "      <th>ed-vae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>68.7±0.6</td>\n",
              "      <td>68.4±0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>93.7±0.2</td>\n",
              "      <td>94.3±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>72.2±0.4</td>\n",
              "      <td>72.8±0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80.1±0.6</td>\n",
              "      <td>80.6±0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>78.1±0.6</td>\n",
              "      <td>79.3±0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>81.0±0.3</td>\n",
              "      <td>80.3±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>63.1±0.7</td>\n",
              "      <td>63.5±0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>95.0±0.3</td>\n",
              "      <td>95.7±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>55.0±0.6</td>\n",
              "      <td>56.5±0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>90.5±0.5</td>\n",
              "      <td>91.5±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>77.7</td>\n",
              "      <td>78.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           vae    ed-vae\n",
              "0     68.7±0.6  68.4±0.6\n",
              "1     93.7±0.2  94.3±0.2\n",
              "2     72.2±0.4  72.8±0.5\n",
              "3     80.1±0.6  80.6±0.5\n",
              "4     78.1±0.6  79.3±0.6\n",
              "5     81.0±0.3  80.3±0.2\n",
              "6     63.1±0.7  63.5±0.7\n",
              "7     95.0±0.3  95.7±0.2\n",
              "8     55.0±0.6  56.5±0.7\n",
              "9     90.5±0.5  91.5±0.4\n",
              "mean      77.7      78.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBA2dwdEnpgz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "f29913b9-eed3-4d9a-b71a-eb5e2840ca34"
      },
      "source": [
        "df.style.apply(highlight_max, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row0_col0,#T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row1_col1,#T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row2_col1,#T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row3_col1,#T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row4_col1,#T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row5_col0,#T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row6_col1,#T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row7_col1,#T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row8_col1,#T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row9_col1,#T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row10_col1{\n",
              "            font-weight:  bold;\n",
              "        }</style><table id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >vae</th>        <th class=\"col_heading level0 col1\" >ed-vae</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row0_col0\" class=\"data row0 col0\" >68.7±0.6</td>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row0_col1\" class=\"data row0 col1\" >68.4±0.6</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row1_col0\" class=\"data row1 col0\" >93.7±0.2</td>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row1_col1\" class=\"data row1 col1\" >94.3±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row2_col0\" class=\"data row2 col0\" >72.2±0.4</td>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row2_col1\" class=\"data row2 col1\" >72.8±0.5</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row3_col0\" class=\"data row3 col0\" >80.1±0.6</td>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row3_col1\" class=\"data row3 col1\" >80.6±0.5</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row4_col0\" class=\"data row4 col0\" >78.1±0.6</td>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row4_col1\" class=\"data row4 col1\" >79.3±0.6</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row5_col0\" class=\"data row5 col0\" >81.0±0.3</td>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row5_col1\" class=\"data row5 col1\" >80.3±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row6_col0\" class=\"data row6 col0\" >63.1±0.7</td>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row6_col1\" class=\"data row6 col1\" >63.5±0.7</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row7_col0\" class=\"data row7 col0\" >95.0±0.3</td>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row7_col1\" class=\"data row7 col1\" >95.7±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row8_col0\" class=\"data row8 col0\" >55.0±0.6</td>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row8_col1\" class=\"data row8 col1\" >56.5±0.7</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row9_col0\" class=\"data row9 col0\" >90.5±0.5</td>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row9_col1\" class=\"data row9 col1\" >91.5±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >mean</th>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row10_col0\" class=\"data row10 col0\" >77.7</td>\n",
              "                        <td id=\"T_4856a96e_bf33_11eb_b6ae_0242ac1c0002row10_col1\" class=\"data row10 col1\" >78.3</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f6d5c68e590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    }
  ]
}