{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main Experiment - MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anon12a/ed-vae/blob/main/Main_Experiment_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuGBmuIP2-3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3588db16-df05-445f-b8c9-84f40886c89d"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "from keras.layers import *\n",
        "from keras.layers import Layer, Dense, Activation, Flatten, Lambda, Conv2D, Conv2DTranspose, BatchNormalization, Reshape\n",
        "from keras.models import Model, Input, Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.losses import mse\n",
        "from keras import backend as K\n",
        "from keras import optimizers, initializers, regularizers, constraints\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from keras.datasets import mnist, fashion_mnist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDM00KrzsQDN"
      },
      "source": [
        "%matplotlib inline "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_37I8fOyzoqM"
      },
      "source": [
        "#Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NMF0_qm95ju"
      },
      "source": [
        "def flatten_data(data):\n",
        "\n",
        "  data = np.reshape(data,(-1, original_dim))\n",
        "  \n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7J_-RM_zu9N"
      },
      "source": [
        "#Losses and Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLHN4RV-ijiK"
      },
      "source": [
        "def reconstruction_error(model):\n",
        "\n",
        "    recon_error = mse(K.reshape(model.input, [-1]), K.reshape(model.output, [-1]))  \n",
        "    recon_error *= original_dim\n",
        "    recon_error = K.mean(recon_error)\n",
        "\n",
        "    return recon_error     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9gRiLBzOQhL"
      },
      "source": [
        "def kl_divergence(encoder):\n",
        "\n",
        "    kl = K.mean(- 0.5 * K.sum(1 + encoder.get_output_at(1)[1] - K.square(encoder.get_output_at(1)[0]) - K.exp(encoder.get_output_at(1)[1]), axis=-1))\n",
        "\n",
        "    return kl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRx30fLElcLn"
      },
      "source": [
        "def per_example_reconstruction_error(model, data):\n",
        "\n",
        "    decoded = model.predict(data, batch_size=batch_size)\n",
        "    recon_error = mse(np.reshape(data,(-1,original_dim)), np.reshape(decoded,(-1,original_dim)))\n",
        "    recon_error *= original_dim\n",
        "\n",
        "    return tf.Session().run(recon_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYQ567VGbAS6"
      },
      "source": [
        "# reconstruction error of the expected latent representation \n",
        "def per_example_elr_reconstruction_error(encoder, decoder, data):\n",
        "\n",
        "    z_mean, z_log_var, z = encoder.predict(data, batch_size=batch_size)\n",
        "    decoded = decoder.predict(z_mean, batch_size=batch_size)\n",
        "    recon_error = mse(np.reshape(data,(-1,original_dim)), np.reshape(decoded,(-1,original_dim)))\n",
        "    recon_error *= original_dim\n",
        "\n",
        "    return tf.Session().run(recon_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z9EoorcRUc3"
      },
      "source": [
        "def per_example_kl_divergence(encoder, data):\n",
        "\n",
        "    z_mean, z_log_var, z = encoder.predict(data, batch_size=batch_size)\n",
        "\n",
        "    kl = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "    kl = K.sum(kl, axis=-1)\n",
        "    kl *= -0.5\n",
        "\n",
        "    return tf.Session().run(kl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qkn5Zlr1JFkH"
      },
      "source": [
        "def pr_auc(x, y):\n",
        "    precision, recall, _ = precision_recall_curve(x, y, pos_label=1)\n",
        "    pr_auc = auc(recall, precision)\n",
        "    \n",
        "    return pr_auc    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dADdxoGUJO6F"
      },
      "source": [
        "def roc_auc(x, y):\n",
        "    fpr, tpr, thresholds = roc_curve(x, y, pos_label=1)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    return roc_auc "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkK2NAigwrHP"
      },
      "source": [
        "# Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8MJGnfLcKx3"
      },
      "source": [
        "## Convolutional Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BOMeH0iwrHS"
      },
      "source": [
        "def conv_encoder(input_side=32, n_channels=3, representation_dim=512, filter_size = 64, representation_activation='sigmoid', intermediate_activation='relu', batch_norm = False):\n",
        "  \n",
        "    input_shape = (input_side, input_side, n_channels)\n",
        "\n",
        "    input = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(filter_size, kernel_size=(3, 3), strides=(2, 2), padding='same')(input)\n",
        "    if batch_norm == True:\n",
        "      x = BatchNormalization()(x)\n",
        "    x = Activation(intermediate_activation)(x)\n",
        "\n",
        "    x = Conv2D(filter_size, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "    if batch_norm == True:\n",
        "      x = BatchNormalization()(x) \n",
        "    x = Activation(intermediate_activation)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(filter_size * input_side//4 * input_side//4)(x)\n",
        "    if batch_norm == True:\n",
        "      x = BatchNormalization()(x) \n",
        "    x = Activation(intermediate_activation)(x)\n",
        "\n",
        "    x = Dense(representation_dim)(x)\n",
        "    if batch_norm == True:\n",
        "      x = BatchNormalization()(x)\n",
        "    encoded = Activation(representation_activation)(x)   \n",
        "\n",
        "    return Model(input, encoded, name=\"encoder\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKf5kMSMwrHS"
      },
      "source": [
        "def conv_decoder(output_side=32, n_channels=3, representation_dim=512, filter_size = 64, activation='relu', batch_norm = False):\n",
        "\n",
        "    encoded_input = Input(shape=(representation_dim,))\n",
        "\n",
        "    x = Dense(filter_size * output_side//4 * output_side//4)(encoded_input)\n",
        "    if batch_norm == True:\n",
        "      x = BatchNormalization()(x) \n",
        "    x = Activation(activation)(x)\n",
        "\n",
        "    conv_shape = (output_side//4, output_side//4, filter_size)\n",
        "    x = Reshape(conv_shape)(x)\n",
        "    \n",
        "    x = Conv2DTranspose(filter_size, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "    if batch_norm == True:\n",
        "      x = BatchNormalization()(x)    \n",
        "    x = Activation(activation)(x)\n",
        "\n",
        "    x = Conv2DTranspose(filter_size, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "    if batch_norm == True:\n",
        "      x = BatchNormalization()(x)     \n",
        "    x = Activation(activation)(x)\n",
        "\n",
        "    x = Conv2DTranspose(n_channels, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
        "    if batch_norm == True:\n",
        "      x = BatchNormalization()(x)    \n",
        "    decoded = Activation('sigmoid')(x)\n",
        "\n",
        "    return Model(encoded_input, decoded, name=\"decoder\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXuaAZ8gieCp"
      },
      "source": [
        "def convolutional_autoencoder(encoder, decoder):\n",
        "\n",
        "    input = Input(batch_shape=encoder.input_shape)\n",
        "    output = decoder(encoder(input))\n",
        "\n",
        "    cae = Model(input, output, name='cae')\n",
        "\n",
        "    return cae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1JqywGXcURQ"
      },
      "source": [
        "## Convolutional Variational Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWkLuk7zwrHT"
      },
      "source": [
        "def cvae_encoder(input_side=32, n_channels=3, representation_dim=512, filter_size = 64, intermediate_activation='relu', batch_norm=False):  \n",
        "    input_shape = (input_side, input_side, n_channels)\n",
        "\n",
        "    input = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(filter_size, kernel_size=(3, 3), strides=(2, 2), padding='same')(input)\n",
        "    x = Activation(intermediate_activation)(x)\n",
        "\n",
        "    x = Conv2D(filter_size, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = Activation(intermediate_activation)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(filter_size * input_side//4 * input_side//4)(x)\n",
        "    x = Activation(intermediate_activation)(x)\n",
        "\n",
        "    z_mean = Dense(representation_dim, name='z_mean')(x)\n",
        "    z_log_var = Dense(representation_dim, name='z_log_var')(x)\n",
        "    z = Lambda(sampling, output_shape=(representation_dim,), name='z')([z_mean, z_log_var])\n",
        "\n",
        "    return Model(input, [z_mean, z_log_var, z], name=\"encoder\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPvLRAowwrHT"
      },
      "source": [
        "def cvae_decoder(output_side=32, n_channels=3, representation_dim=512, filter_size = 64, activation='relu', batch_norm=False):\n",
        "    \n",
        "    encoded_input = Input(shape=(representation_dim,))\n",
        "\n",
        "    x = Dense(filter_size * output_side//4 * output_side//4)(encoded_input)\n",
        "    x = Activation(activation)(x)\n",
        "\n",
        "    conv_shape = (output_side//4, output_side//4, filter_size)\n",
        "    x = Reshape(conv_shape)(x)\n",
        "\n",
        "    x = Conv2DTranspose(filter_size, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = Activation(activation)(x)\n",
        "\n",
        "    x = Conv2DTranspose(filter_size, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = Activation(activation)(x)\n",
        "\n",
        "    x = Conv2DTranspose(n_channels, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
        "    decoded = Activation('sigmoid')(x)\n",
        "\n",
        "    return Model(encoded_input, decoded, name=\"decoder\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw4n1DELN7Yx"
      },
      "source": [
        "def convolutional_variational_autoencoder(encoder, decoder):\n",
        "\n",
        "    input = Input(batch_shape=encoder.input_shape)\n",
        "    output = decoder(encoder(input)[2])\n",
        "\n",
        "    cvae = Model(input, output, name='cvae')\n",
        "\n",
        "    return cvae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9c4wxcgv8ck"
      },
      "source": [
        "# Reparamaterization Trick\n",
        "# instead of sampling from Q(z|X), sample eps = N(0,I)\n",
        "# z = z_mean + sqrt(var)*eps\n",
        "def sampling(args):\n",
        "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
        "    # Arguments:\n",
        "        args (tensor): mean and log of variance of Q(z|X)\n",
        "    # Returns:\n",
        "        z (tensor): sampled latent vector\n",
        "    \"\"\"\n",
        "    z_mean, z_log_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    # by default, random_normal has mean=0 and std=1.0\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k58jQ7bov8ci"
      },
      "source": [
        "#Comparable Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4phvCkiGv8cl"
      },
      "source": [
        "## Convolutional Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T8CjuUmv8cl"
      },
      "source": [
        "def cae_1(x_train, y_train, x_val, x_test, y_test, epochs, batch_size, learning_rate, input_side, n_channels, latent_dim, filter_size, batch_norm = False):\n",
        "\n",
        "  encoder = conv_encoder(input_side=image_shape[0], n_channels=image_shape[2], representation_dim=latent_dim, filter_size = filter_size, batch_norm = batch_norm)\n",
        "  decoder = conv_decoder(output_side=image_shape[0], n_channels=image_shape[2], representation_dim=latent_dim, filter_size = filter_size, batch_norm = batch_norm)\n",
        "  cae = convolutional_autoencoder(encoder, decoder) \n",
        "\n",
        "  #encoder.summary()\n",
        "  #decoder.summary() \n",
        "\n",
        "  recon_error = reconstruction_error(cae)\n",
        "\n",
        "  cae.add_loss(recon_error)\n",
        "  adam = optimizers.Adam(lr=learning_rate)\n",
        "  cae.compile(optimizer=adam)\n",
        "\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', patience = 20, verbose=1)\n",
        "\n",
        "  history = cae.fit(x_train,\n",
        "                  epochs=epochs,\n",
        "                  batch_size=batch_size,\n",
        "                  validation_data=(x_val, None),\n",
        "                  callbacks=[es],\n",
        "                  verbose=0)\n",
        "  \n",
        "  rec_results = per_example_reconstruction_error(cae, x_test)\n",
        "\n",
        "  pr_auc_rec_result = pr_auc(y_test, rec_results)\n",
        "  roc_auc_rec_result = roc_auc(y_test, rec_results)\n",
        "\n",
        "  return pr_auc_rec_result, roc_auc_rec_result, pr_auc_rec_result, roc_auc_rec_result, pr_auc_rec_result, roc_auc_rec_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LxR44S4v8cn"
      },
      "source": [
        "## PCA (via SVD)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFQudufmv8cn"
      },
      "source": [
        "def pca_1(x_train, y_train, x_val, x_test, y_test, input_side, n_channels, latent_dim):\n",
        "\n",
        "    pca = PCA(n_components=latent_dim, svd_solver='full')\n",
        "\n",
        "    pca.fit(flatten_data(x_train))\n",
        "    encoded = pca.transform(flatten_data(x_test))\n",
        "    recon = pca.inverse_transform(encoded)\n",
        "\n",
        "    recon_error = mse(flatten_data(x_test), recon)\n",
        "    recon_error *= original_dim\n",
        "    recon_error = tf.Session().run(recon_error)\n",
        "\n",
        "    pr_auc_result = pr_auc(y_test, recon_error)\n",
        "    roc_auc_result = roc_auc(y_test, recon_error)\n",
        "\n",
        "    return pr_auc_result, roc_auc_result, pr_auc_result, roc_auc_result, pr_auc_result, roc_auc_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnTUn4Y0v8cn"
      },
      "source": [
        "## KernalPCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5sOtCQzv8co"
      },
      "source": [
        "def kpca_1(x_train, y_train, x_val, x_test, y_test, input_side, n_channels, latent_dim):\n",
        "\n",
        "    kpca = KernelPCA(n_components=latent_dim, kernel='rbf', fit_inverse_transform=\"True\")\n",
        "\n",
        "    kpca.fit(flatten_data(x_train))\n",
        "    encoded = kpca.transform(flatten_data(x_test))\n",
        "    recon = kpca.inverse_transform(encoded)\n",
        "\n",
        "    recon_error = mse(flatten_data(x_test), recon)\n",
        "    recon_error *= original_dim\n",
        "    recon_error = tf.Session().run(recon_error)\n",
        "\n",
        "    pr_auc_result = pr_auc(y_test, recon_error)\n",
        "    roc_auc_result = roc_auc(y_test, recon_error)\n",
        "\n",
        "    return pr_auc_result, roc_auc_result, pr_auc_result, roc_auc_result, pr_auc_result, roc_auc_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzN5hz2zv8co"
      },
      "source": [
        "## Deep Structured Energy Based Anomaly Detection (DSEBM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuevRaI2v8co"
      },
      "source": [
        "# From the following implementation: https://github.com/izikgo/AnomalyDetectionTransformations/blob/master/models/dsebm.py\n",
        "# Licensed under the MIT License\n",
        "class Prior(Layer):\n",
        "    def __init__(self,\n",
        "                 bias_initializer='zeros',\n",
        "                 bias_regularizer=None,\n",
        "                 bias_constraint=None,\n",
        "                 **kwargs):\n",
        "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
        "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
        "        super(Prior, self).__init__(**kwargs)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "        self.input_spec = InputSpec(min_ndim=2)\n",
        "        self.bias = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.bias = self.add_weight(shape=input_shape[1:],\n",
        "                                    initializer=self.bias_initializer,\n",
        "                                    name='bias',\n",
        "                                    regularizer=self.bias_regularizer,\n",
        "                                    constraint=self.bias_constraint)\n",
        "        super(Prior, self).build(input_shape)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], 1\n",
        "\n",
        "    def call(self, x, **kwargs):\n",
        "        return K.sum(K.batch_flatten(K.square(K.bias_add(x, -self.bias))), axis=-1, keepdims=True)\n",
        "\n",
        "\n",
        "def create_energy_model(encoder_mdl):\n",
        "    x_in = Input(batch_shape=encoder_mdl.input_shape)\n",
        "\n",
        "    encoded = encoder_mdl(x_in)\n",
        "    prior = Prior()(x_in)\n",
        "    energy = Lambda(lambda args: 0.5*args[0] - K.sum(K.batch_flatten(args[1]), axis=-1, keepdims=True),\n",
        "                    output_shape=(1,))([prior, encoded])\n",
        "    return Model(x_in, energy)\n",
        "\n",
        "\n",
        "def create_reconstruction_model(energy_mdl):\n",
        "    x_in = Input(batch_shape=energy_mdl.input_shape)\n",
        "    x = GaussianNoise(stddev=.5)(x_in)  # only active in training\n",
        "    energy = energy_mdl(x)\n",
        "    rec = Lambda(lambda args: args[1] - K.gradients(args[0], args[1]),\n",
        "                 output_shape=energy_mdl.input_shape[1:])([energy, x])\n",
        "\n",
        "    return Model(x_in, rec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q5-xD8RlNdy"
      },
      "source": [
        "def dsebm_1(x_train, y_train, x_val, x_test, y_test, epochs, batch_size, learning_rate, input_side, n_channels, latent_dim, filter_size):\n",
        "  \n",
        "  encoder_mdl = conv_encoder(input_side=image_shape[0], n_channels=image_shape[2], representation_dim=latent_dim, filter_size=filter_size)\n",
        "  energy_mdl = create_energy_model(encoder_mdl)\n",
        "  reconstruction_mdl = create_reconstruction_model(energy_mdl)\n",
        "\n",
        "  adam = optimizers.Adam(lr=learning_rate)\n",
        "  reconstruction_mdl.compile(optimizer=adam, loss=\"mse\")\n",
        "\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', patience = 20, verbose=1)\n",
        "\n",
        "  history = reconstruction_mdl.fit(x=x_train, y=x_train, \n",
        "                  epochs=epochs,\n",
        "                  batch_size=batch_size,\n",
        "                  validation_data=(x_val, x_val),\n",
        "                  callbacks=[es],\n",
        "                  verbose=0)\n",
        "  \n",
        "  scores = -energy_mdl.predict(x_test, batch_size)\n",
        "\n",
        "  pr_auc_result = pr_auc(y_test, -scores)\n",
        "  roc_auc_result = roc_auc(y_test, -scores)\n",
        "\n",
        "  return pr_auc_result, roc_auc_result, pr_auc_result, roc_auc_result, pr_auc_result, roc_auc_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmRR7TMZmzRE"
      },
      "source": [
        "# ED-VAE and VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CgCYNSDmzRF"
      },
      "source": [
        "def edvae_vae_comparison(x_train, y_train, x_val, x_test, y_test, epochs, batch_size, learning_rate, input_side, n_channels, latent_dim, filter_size, batch_norm=False, beta = 1.0):\n",
        "\n",
        "  encoder = cvae_encoder(input_side=image_shape[0], n_channels=image_shape[2], representation_dim=latent_dim, filter_size = filter_size, batch_norm = batch_norm)\n",
        "  decoder = cvae_decoder(output_side=image_shape[0], n_channels=image_shape[2], representation_dim=latent_dim, filter_size = filter_size, batch_norm = batch_norm)\n",
        "  cae = convolutional_variational_autoencoder(encoder, decoder) \n",
        "\n",
        "  #encoder.summary()\n",
        "  #decoder.summary() \n",
        "\n",
        "  recon_error = reconstruction_error(cae)\n",
        "  kl = kl_divergence(encoder)\n",
        "  loss = beta * kl + recon_error\n",
        "\n",
        "  cae.add_loss(loss)\n",
        "  \n",
        "  adam = optimizers.Adam(lr=learning_rate)\n",
        "  cae.compile(optimizer=adam)\n",
        "\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', patience = 20, verbose=1)\n",
        "\n",
        "  history = cae.fit(x_train,\n",
        "                  epochs=epochs,\n",
        "                  batch_size=batch_size,\n",
        "                  validation_data=(x_val, None),\n",
        "                  callbacks=[es],\n",
        "                  verbose=0)\n",
        "  \n",
        "  # vae results \n",
        "  kl_results = per_example_kl_divergence(encoder, x_test)\n",
        "  rec_results = per_example_reconstruction_error(cae, x_test)\n",
        "  elbo_results = beta * kl_results + rec_results\n",
        "\n",
        "  pr_auc_rec_result = pr_auc(y_test, rec_results)\n",
        "  roc_auc_rec_result = roc_auc(y_test, rec_results)\n",
        "\n",
        "  pr_auc_elbo_result = pr_auc(y_test, elbo_results)\n",
        "  roc_auc_elbo_result = roc_auc(y_test, elbo_results)\n",
        "\n",
        "  pr_auc_kl_result = pr_auc(y_test, kl_results)\n",
        "  roc_auc_kl_result = roc_auc(y_test, kl_results) \n",
        "    \n",
        "  # ed-vae results\n",
        "  kl_results = per_example_kl_divergence(encoder, x_test)\n",
        "  rec_results = per_example_elr_reconstruction_error(encoder, decoder, x_test)\n",
        "  elbo_results = beta * kl_results + rec_results\n",
        "\n",
        "  elr_pr_auc_rec_result = pr_auc(y_test, rec_results)\n",
        "  elr_roc_auc_rec_result = roc_auc(y_test, rec_results)\n",
        "\n",
        "  elr_pr_auc_elbo_result = pr_auc(y_test, elbo_results)\n",
        "  elr_roc_auc_elbo_result = roc_auc(y_test, elbo_results)\n",
        "\n",
        "  elr_pr_auc_kl_result = pr_auc(y_test, kl_results )\n",
        "  elr_roc_auc_kl_result = roc_auc(y_test, kl_results )\n",
        "\n",
        "  return np.array([[pr_auc_rec_result, roc_auc_rec_result, pr_auc_elbo_result, roc_auc_elbo_result, pr_auc_kl_result, roc_auc_kl_result],\n",
        "                   [elr_pr_auc_rec_result, elr_roc_auc_rec_result, elr_pr_auc_elbo_result, elr_roc_auc_elbo_result, elr_pr_auc_kl_result, elr_roc_auc_kl_result]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVzUrWfJn0b-"
      },
      "source": [
        "# Data Preperation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtIp8y44wXXB"
      },
      "source": [
        "def load_mnist():\n",
        "\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "  x_train = x_train.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
        "  x_test = x_test.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
        "\n",
        "  #print('x_train shape:', x_train.shape)\n",
        "  #print(x_train.shape[0], 'train samples')\n",
        "  #print(x_test.shape[0], 'test samples')\n",
        "\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHNv17T-0KUO"
      },
      "source": [
        "def load_fashion_mnist():\n",
        "\n",
        "  (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "  x_train =  x_train.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
        "  x_test = x_test.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
        "\n",
        "  #print('x_train shape:', x_train.shape)\n",
        "  #print(x_train.shape[0], 'train samples')\n",
        "  #print(x_test.shape[0], 'test samples')\n",
        "\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cJ8bRAIGFjx"
      },
      "source": [
        "# create training set without anomalies and test set with a ratio p of anomalies. E.g. p = 0.2 \n",
        "# creates a test set where 20% of the test set are anomalies\n",
        "def create_data(X_train, Y_train, X_test, Y_test, normal_class, p = .1):\n",
        "\n",
        "    X_norm_train_filter = np.where(np.isin(Y_train, normal_class))\n",
        "    X_norm_test_filter = np.where(np.isin(Y_test, normal_class))\n",
        "    X_anom_test_filter = np.where(np.isin(Y_test, normal_class, invert = True))\n",
        "\n",
        "    # a = (# of normal instances)/(1 - ratio of outliers)) * ratio of outliers\n",
        "    # e.g. if p = .2 20% of the test set is anomalies\n",
        "    a = math.floor(((len(X_norm_test_filter[0]))/(1-p))*p)\n",
        "\n",
        "    X_anom_test_filter = (np.random.choice(X_anom_test_filter[0], a, replace=False),)\n",
        "    X_test_filter = (np.concatenate((X_norm_test_filter[0], X_anom_test_filter[0]), axis=None),)\n",
        "\n",
        "    X_train, Y_train = X_train[X_norm_train_filter[0]], Y_train[X_norm_train_filter]\n",
        "    X_test_norm, Y_test_norm = X_test[X_norm_test_filter[0]], Y_test[X_norm_test_filter]\n",
        "    Y_test_class_labels = Y_test[X_test_filter]\n",
        "    X_test, Y_test, = X_test[X_test_filter[0]], Y_test[X_test_filter]\n",
        "\n",
        "    Y_test[np.isin(Y_test_class_labels, normal_class)] = 0\n",
        "    Y_test[np.isin(Y_test_class_labels, normal_class, invert = True)] = 1\n",
        "    \n",
        "    return X_train, Y_train, X_test, Y_test, Y_test_class_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08AoBB68n-Sq"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNZQXGB0HTwt"
      },
      "source": [
        "image_shape = (28, 28, 1)\n",
        "original_dim = image_shape[0] * image_shape[1] * image_shape[2]\n",
        "input_shape = image_shape\n",
        "batch_size = 128\n",
        "latent_dim = 32\n",
        "beta = 1.0\n",
        "epochs = 1000\n",
        "learning_rate = 0.0001\n",
        "activation = 'relu'\n",
        "filter_size = 32\n",
        "p = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_tUDUIpn4aZ"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lmO4TbIFZia"
      },
      "source": [
        "normal_classes = np.arange(0,10)\n",
        "num_models = 6\n",
        "num_measures = 6\n",
        "reps = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5BptUPsqeqP"
      },
      "source": [
        "def models(x_train, y_train, x_val, x_test, y_test):\n",
        "\n",
        "  pca_1_results = pca_1(x_train, y_train, x_val, x_test, y_test, image_shape[0], image_shape[2], latent_dim)\n",
        "  kpca_1_results = kpca_1(x_train, y_train, x_val, x_test, y_test, image_shape[0], image_shape[2], latent_dim)\n",
        "  dsebm_1_results = dsebm_1(x_train, y_train, x_val, x_test, y_test, epochs, batch_size, learning_rate, image_shape[0], image_shape[2], latent_dim, filter_size)\n",
        "  cae_1_results = cae_1(x_train, y_train, x_val, x_test, y_test, epochs, batch_size, learning_rate, image_shape[0], image_shape[2], latent_dim, filter_size, batch_norm=False)\n",
        "  edvae_vae_comparison_results = edvae_vae_comparison(x_train, y_train, x_val, x_test, y_test, epochs, batch_size, learning_rate, image_shape[0], image_shape[2], latent_dim, filter_size, beta = beta)\n",
        "  \n",
        "  return pca_1_results, kpca_1_results, dsebm_1_results, cae_1_results, edvae_vae_comparison_results[0], edvae_vae_comparison_results[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep-pTu2z7GMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e25749cb-eb3c-47ab-ab52-7d3cd1968188"
      },
      "source": [
        "results = np.zeros((reps, len(normal_classes), num_models, num_measures))\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for rep in tqdm(range(reps), desc=\"reps\"):\n",
        "  for normal in tqdm(range(len(normal_classes)), desc=\"anomaly\"):\n",
        "    x_train, y_train, x_test, y_test = load_mnist()\n",
        "    x_train, y_train, x_test, y_test, y_test_class_labels = create_data(x_train, y_train, x_test, y_test, normal_classes[normal], p = p)\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
        "    results[rep, normal] = models(x_train, y_train, x_val, x_test, y_test)\n",
        "    tf.keras.backend.clear_session() #release gpu memory"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reps:   0%|          | 0/10 [00:00<?, ?it/s]\n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 00092: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00201: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00318: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [03:09<28:24, 189.37s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00051: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00140: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00282: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [06:01<24:33, 184.18s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00075: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00270: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00337: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [09:27<22:15, 190.82s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00051: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00172: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00322: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [12:21<18:33, 185.65s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00041: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00213: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00353: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [15:23<15:23, 184.60s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00040: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00186: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00292: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [17:48<11:31, 172.77s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00061: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00174: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00235: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [20:14<08:14, 164.69s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00040: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00263: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00259: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [23:16<05:39, 169.94s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00052: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00204: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00337: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [26:16<02:52, 172.82s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00039: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00202: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00272: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [28:56<00:00, 173.66s/it]\n",
            "reps:  10%|█         | 1/10 [28:56<4:20:29, 1736.66s/it]\n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00070: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00217: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00311: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [03:04<27:44, 184.99s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00207: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00191: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00304: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [07:10<27:05, 203.21s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00091: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00205: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00356: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [10:29<23:33, 201.96s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00058: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00151: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00292: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [13:12<19:01, 190.19s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00130: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00185: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00405: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [16:48<16:29, 197.86s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00040: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00173: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00277: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [19:05<11:59, 179.78s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00045: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00186: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00349: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [22:01<08:55, 178.42s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00117: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00239: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00385: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [25:58<06:32, 196.15s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00050: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00161: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00393: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [29:04<03:13, 193.15s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00039: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00254: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00401: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [32:37<00:00, 195.78s/it]\n",
            "reps:  20%|██        | 2/10 [1:01:34<4:00:23, 1803.00s/it]\n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00039: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00210: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00289: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [02:46<24:59, 166.56s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00039: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00139: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00304: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [05:40<22:31, 168.91s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00043: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00239: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00387: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [09:05<20:58, 179.74s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00067: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00158: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00411: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [12:28<18:39, 186.57s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00053: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00209: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00421: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [15:51<15:58, 191.65s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00048: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00148: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00480: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [18:58<12:40, 190.21s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00058: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00220: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00269: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [21:45<09:09, 183.07s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00058: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00181: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00328: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [24:49<06:06, 183.29s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00049: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00151: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00319: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [27:26<02:55, 175.58s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00043: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00153: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00344: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [30:15<00:00, 181.59s/it]\n",
            "reps:  30%|███       | 3/10 [1:31:50<3:30:48, 1806.88s/it]\n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00043: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00180: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00212: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [02:17<20:33, 137.08s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00046: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00154: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00167: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [04:33<18:15, 136.97s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00060: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00149: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00290: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [07:10<16:40, 142.89s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00056: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00197: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00386: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [10:33<16:05, 160.93s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00046: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00222: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00365: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [13:42<14:07, 169.46s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00044: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00205: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00300: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [16:16<10:58, 164.57s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00047: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00235: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00320: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [19:17<08:28, 169.63s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00043: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00163: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00212: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [21:39<05:22, 161.29s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00051: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00229: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00440: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [25:13<02:57, 177.08s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00044: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00174: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00403: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [28:25<00:00, 170.56s/it]\n",
            "reps:  40%|████      | 4/10 [2:00:16<2:57:39, 1776.50s/it]\n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00087: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00211: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00379: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [03:27<31:08, 207.66s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00047: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00187: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00208: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [06:08<25:48, 193.52s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00044: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00196: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00355: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [09:12<22:15, 190.81s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00062: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00230: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00511: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [13:22<20:51, 208.52s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00080: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00276: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00300: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [16:39<17:05, 205.09s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00067: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00182: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00229: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [18:54<12:15, 183.96s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00224: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00248: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00434: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [23:21<10:26, 208.99s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00052: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00170: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00338: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [26:24<06:42, 201.25s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00050: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00889: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00418: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [32:43<04:14, 254.35s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00050: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00210: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00320: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [35:41<00:00, 214.11s/it]\n",
            "reps:  50%|█████     | 5/10 [2:35:57<2:37:09, 1885.89s/it]\n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00043: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00135: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00327: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [02:39<23:52, 159.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00106: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00154: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00207: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [05:28<21:37, 162.22s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00050: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00271: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00302: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [08:38<19:54, 170.70s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00048: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00197: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00268: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [11:23<16:53, 168.97s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00085: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00151: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00236: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [13:50<13:30, 162.11s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00082: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00205: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00334: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [16:41<11:00, 165.01s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00044: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00181: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00209: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [18:58<07:49, 156.42s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00039: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00141: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00280: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [21:33<05:12, 156.07s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00070: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00185: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00345: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [24:35<02:43, 163.90s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00043: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00179: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00452: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [28:01<00:00, 168.18s/it]\n",
            "reps:  60%|██████    | 6/10 [3:03:58<2:01:38, 1824.67s/it]\n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00073: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00218: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00335: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [03:13<28:58, 193.19s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00080: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00155: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00233: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [06:02<24:47, 185.98s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00061: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00181: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00495: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [09:46<23:02, 197.52s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00055: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00156: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00348: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [12:45<19:10, 191.78s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00045: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00210: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00217: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [15:10<14:49, 177.87s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00058: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00246: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00372: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [18:16<12:00, 180.23s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00099: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00179: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00415: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [21:45<09:26, 188.86s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00073: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00208: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00269: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [24:45<06:12, 186.18s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00056: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00285: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00284: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [27:52<03:06, 186.62s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00044: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00167: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00382: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [30:55<00:00, 185.55s/it]\n",
            "reps:  70%|███████   | 7/10 [3:34:54<1:31:41, 1833.93s/it]\n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00059: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00202: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00302: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [02:53<26:04, 173.88s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00043: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00206: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00379: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [06:34<25:02, 187.79s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00199: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00197: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00469: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [10:54<24:26, 209.57s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00049: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00231: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00185: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [13:24<19:10, 191.75s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00057: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00273: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00287: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [16:29<15:48, 189.73s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00083: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00304: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00292: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [19:34<12:33, 188.38s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00048: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00166: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00311: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [22:16<09:01, 180.36s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00042: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00232: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00318: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [25:27<06:07, 183.66s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00061: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00152: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00407: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [28:36<03:05, 185.28s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00102: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00224: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00257: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [31:37<00:00, 189.72s/it]\n",
            "reps:  80%|████████  | 8/10 [4:06:31<1:01:45, 1852.90s/it]\n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00185: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00184: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00248: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [03:10<28:37, 190.79s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00095: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00185: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00197: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [06:03<24:42, 185.37s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00164: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00181: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00371: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [09:42<22:48, 195.51s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00069: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00149: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00354: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [12:46<19:11, 191.97s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00094: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00135: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00322: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [15:36<15:27, 185.42s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00057: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00193: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00373: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [18:27<12:04, 181.18s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00173: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00242: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00238: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [21:45<09:17, 185.98s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00064: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00278: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00290: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [25:08<06:22, 191.33s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00235: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00186: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00453: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [29:28<03:31, 211.91s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00052: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00196: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00363: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [32:37<00:00, 195.72s/it]\n",
            "reps:  90%|█████████ | 9/10 [4:39:08<31:24, 1884.19s/it]  \n",
            "anomaly:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00174: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00175: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00346: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  10%|█         | 1/10 [03:32<31:52, 212.53s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00039: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00189: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00264: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  20%|██        | 2/10 [06:30<26:56, 202.08s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00081: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00236: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00461: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  30%|███       | 3/10 [10:27<24:47, 212.52s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00039: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00203: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00233: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  40%|████      | 4/10 [13:01<19:30, 195.15s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00115: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00273: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00299: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  50%|█████     | 5/10 [16:26<16:30, 198.08s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00044: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00258: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00295: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  60%|██████    | 6/10 [19:11<12:32, 188.20s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00046: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00203: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00327: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  70%|███████   | 7/10 [22:08<09:14, 184.86s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00063: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00223: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00375: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  80%|████████  | 8/10 [25:42<06:26, 193.35s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00047: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00217: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00445: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly:  90%|█████████ | 9/10 [29:14<03:19, 199.21s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:530: RuntimeWarning: invalid value encountered in multiply\n",
            "  v *= signs[:, np.newaxis]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00043: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00161: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00316: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "anomaly: 100%|██████████| 10/10 [31:58<00:00, 191.87s/it]\n",
            "reps: 100%|██████████| 10/10 [5:11:07<00:00, 1866.76s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNIiuLGQvLSb"
      },
      "source": [
        "# Results - ED-VAE vs. Comparable Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9U7oiHrfKCe"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRz6rJQvbYfE"
      },
      "source": [
        "index_labels = normal_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6C3oarV5luz"
      },
      "source": [
        "avg_results = np.mean(results, axis=0)\n",
        "std_results = np.std(results, axis=0)\n",
        "avg_class_results = np.mean(results, axis=(0, 1))\n",
        "std_class_results = np.std(results, axis=(0, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYqOKCHdRiBl"
      },
      "source": [
        "pr_header = [np.array(['pca','pca',\n",
        "                    'kpca','kpca',\n",
        "                    'dsebm','dsebm',\n",
        "                    'ae','ae',\n",
        "                    'vae', 'vae',             \n",
        "                    'ed-vae', 'ed-vae',\n",
        "                    ]), \n",
        "np.array(['pr_auc_mean','pr_auc_std',\n",
        "          'pr_auc_mean','pr_auc_std',\n",
        "          'pr_auc_mean','pr_auc_std',\n",
        "          'pr_auc_mean','pr_auc_std',\n",
        "          'pr_auc_mean','pr_auc_std',\n",
        "          'pr_auc_mean','pr_auc_std',\n",
        "          ])] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2kKWVNYTPHo"
      },
      "source": [
        "auc_header = [np.array(['pca','pca',\n",
        "                    'kpca','kpca',\n",
        "                    'dsebm','dsebm',\n",
        "                    'ae','ae',\n",
        "                    'vae', 'vae',             \n",
        "                    'ed-vae', 'ed-vae',\n",
        "                    ]), \n",
        "np.array(['auc_mean','auc_std',\n",
        "          'auc_mean','auc_std',\n",
        "          'auc_mean','auc_std',\n",
        "          'auc_mean','auc_std',\n",
        "          'auc_mean','auc_std',\n",
        "          'auc_mean','auc_std',\n",
        "          ])] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtMsETaBRYPH"
      },
      "source": [
        "### $ELBO$\n",
        "Compare ELBO of VAE and ED-VAE to results of competitive models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkpQ6aLEUIP9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "7b490f4e-28e1-4d9b-f87f-f29d2eae3e88"
      },
      "source": [
        "# AUC\n",
        "avg_auc_elbo_class_results = pd.DataFrame((avg_class_results[0,3], std_class_results[0,3], \n",
        "                                  avg_class_results[1,3], std_class_results[1,3],\n",
        "                                  avg_class_results[2,3], std_class_results[2,3],  \n",
        "                                  avg_class_results[3,3], std_class_results[3,3], \n",
        "                                  avg_class_results[4,3], std_class_results[4,3], \n",
        "                                  avg_class_results[5,3], std_class_results[5,3], \n",
        "                                  ), \n",
        "                                  index = auc_header).T\n",
        "avg_auc_elbo_class_results = avg_auc_elbo_class_results.rename(index={0: \"mean\"})\n",
        "avg_auc_elbo_final_results = pd.DataFrame((avg_results[:,0,3], std_results[:,0,3],\n",
        "                                  avg_results[:,1,3], std_results[:,1,3], \n",
        "                                  avg_results[:,2,3], std_results[:,2,3], \n",
        "                                  avg_results[:,3,3], std_results[:,3,3], \n",
        "                                  avg_results[:,4,3], std_results[:,4,3],  \n",
        "                                  avg_results[:,5,3], std_results[:,5,3], \n",
        "                                  ), \n",
        "                                  index = auc_header, columns = index_labels).T\n",
        "avg_auc_elbo_final_results.append(avg_auc_elbo_class_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">pca</th>\n",
              "      <th colspan=\"2\" halign=\"left\">kpca</th>\n",
              "      <th colspan=\"2\" halign=\"left\">dsebm</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">vae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ed-vae</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.991902</td>\n",
              "      <td>0.001006</td>\n",
              "      <td>0.989760</td>\n",
              "      <td>0.001497</td>\n",
              "      <td>0.536940</td>\n",
              "      <td>0.246504</td>\n",
              "      <td>0.969052</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.997490</td>\n",
              "      <td>0.000596</td>\n",
              "      <td>0.998040</td>\n",
              "      <td>0.000399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.998884</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>0.998158</td>\n",
              "      <td>0.000112</td>\n",
              "      <td>0.982074</td>\n",
              "      <td>0.009387</td>\n",
              "      <td>0.987335</td>\n",
              "      <td>0.001369</td>\n",
              "      <td>0.999143</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.998971</td>\n",
              "      <td>0.000175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.924497</td>\n",
              "      <td>0.007101</td>\n",
              "      <td>0.896655</td>\n",
              "      <td>0.009141</td>\n",
              "      <td>0.518324</td>\n",
              "      <td>0.132393</td>\n",
              "      <td>0.780557</td>\n",
              "      <td>0.007687</td>\n",
              "      <td>0.930162</td>\n",
              "      <td>0.013765</td>\n",
              "      <td>0.953000</td>\n",
              "      <td>0.011181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.952098</td>\n",
              "      <td>0.004585</td>\n",
              "      <td>0.938679</td>\n",
              "      <td>0.007595</td>\n",
              "      <td>0.508091</td>\n",
              "      <td>0.038067</td>\n",
              "      <td>0.858054</td>\n",
              "      <td>0.009869</td>\n",
              "      <td>0.945802</td>\n",
              "      <td>0.011802</td>\n",
              "      <td>0.957721</td>\n",
              "      <td>0.009410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.943417</td>\n",
              "      <td>0.004557</td>\n",
              "      <td>0.945677</td>\n",
              "      <td>0.004942</td>\n",
              "      <td>0.692532</td>\n",
              "      <td>0.064927</td>\n",
              "      <td>0.882161</td>\n",
              "      <td>0.009189</td>\n",
              "      <td>0.949664</td>\n",
              "      <td>0.007648</td>\n",
              "      <td>0.963341</td>\n",
              "      <td>0.009216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.974173</td>\n",
              "      <td>0.003210</td>\n",
              "      <td>0.950427</td>\n",
              "      <td>0.004540</td>\n",
              "      <td>0.556980</td>\n",
              "      <td>0.024939</td>\n",
              "      <td>0.725093</td>\n",
              "      <td>0.011491</td>\n",
              "      <td>0.958067</td>\n",
              "      <td>0.004985</td>\n",
              "      <td>0.966591</td>\n",
              "      <td>0.005621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.983505</td>\n",
              "      <td>0.001988</td>\n",
              "      <td>0.973489</td>\n",
              "      <td>0.002965</td>\n",
              "      <td>0.584922</td>\n",
              "      <td>0.131559</td>\n",
              "      <td>0.868427</td>\n",
              "      <td>0.006613</td>\n",
              "      <td>0.988640</td>\n",
              "      <td>0.003114</td>\n",
              "      <td>0.993058</td>\n",
              "      <td>0.001855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.970885</td>\n",
              "      <td>0.003842</td>\n",
              "      <td>0.964386</td>\n",
              "      <td>0.005171</td>\n",
              "      <td>0.757129</td>\n",
              "      <td>0.026946</td>\n",
              "      <td>0.912264</td>\n",
              "      <td>0.008214</td>\n",
              "      <td>0.965191</td>\n",
              "      <td>0.006841</td>\n",
              "      <td>0.972690</td>\n",
              "      <td>0.004912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.854871</td>\n",
              "      <td>0.016547</td>\n",
              "      <td>0.854343</td>\n",
              "      <td>0.016311</td>\n",
              "      <td>0.463918</td>\n",
              "      <td>0.102268</td>\n",
              "      <td>0.779581</td>\n",
              "      <td>0.024401</td>\n",
              "      <td>0.894889</td>\n",
              "      <td>0.013219</td>\n",
              "      <td>0.910885</td>\n",
              "      <td>0.015663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.963962</td>\n",
              "      <td>0.001586</td>\n",
              "      <td>0.954091</td>\n",
              "      <td>0.001989</td>\n",
              "      <td>0.663246</td>\n",
              "      <td>0.054227</td>\n",
              "      <td>0.880227</td>\n",
              "      <td>0.006204</td>\n",
              "      <td>0.975738</td>\n",
              "      <td>0.003147</td>\n",
              "      <td>0.982728</td>\n",
              "      <td>0.002057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.955819</td>\n",
              "      <td>0.040362</td>\n",
              "      <td>0.946566</td>\n",
              "      <td>0.041466</td>\n",
              "      <td>0.626416</td>\n",
              "      <td>0.182221</td>\n",
              "      <td>0.864275</td>\n",
              "      <td>0.079840</td>\n",
              "      <td>0.960479</td>\n",
              "      <td>0.031821</td>\n",
              "      <td>0.969702</td>\n",
              "      <td>0.026312</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           pca                kpca               dsebm                  ae  \\\n",
              "      auc_mean   auc_std  auc_mean   auc_std  auc_mean   auc_std  auc_mean   \n",
              "0     0.991902  0.001006  0.989760  0.001497  0.536940  0.246504  0.969052   \n",
              "1     0.998884  0.000132  0.998158  0.000112  0.982074  0.009387  0.987335   \n",
              "2     0.924497  0.007101  0.896655  0.009141  0.518324  0.132393  0.780557   \n",
              "3     0.952098  0.004585  0.938679  0.007595  0.508091  0.038067  0.858054   \n",
              "4     0.943417  0.004557  0.945677  0.004942  0.692532  0.064927  0.882161   \n",
              "5     0.974173  0.003210  0.950427  0.004540  0.556980  0.024939  0.725093   \n",
              "6     0.983505  0.001988  0.973489  0.002965  0.584922  0.131559  0.868427   \n",
              "7     0.970885  0.003842  0.964386  0.005171  0.757129  0.026946  0.912264   \n",
              "8     0.854871  0.016547  0.854343  0.016311  0.463918  0.102268  0.779581   \n",
              "9     0.963962  0.001586  0.954091  0.001989  0.663246  0.054227  0.880227   \n",
              "mean  0.955819  0.040362  0.946566  0.041466  0.626416  0.182221  0.864275   \n",
              "\n",
              "                     vae              ed-vae            \n",
              "       auc_std  auc_mean   auc_std  auc_mean   auc_std  \n",
              "0     0.003922  0.997490  0.000596  0.998040  0.000399  \n",
              "1     0.001369  0.999143  0.000108  0.998971  0.000175  \n",
              "2     0.007687  0.930162  0.013765  0.953000  0.011181  \n",
              "3     0.009869  0.945802  0.011802  0.957721  0.009410  \n",
              "4     0.009189  0.949664  0.007648  0.963341  0.009216  \n",
              "5     0.011491  0.958067  0.004985  0.966591  0.005621  \n",
              "6     0.006613  0.988640  0.003114  0.993058  0.001855  \n",
              "7     0.008214  0.965191  0.006841  0.972690  0.004912  \n",
              "8     0.024401  0.894889  0.013219  0.910885  0.015663  \n",
              "9     0.006204  0.975738  0.003147  0.982728  0.002057  \n",
              "mean  0.079840  0.960479  0.031821  0.969702  0.026312  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLcLg1j-Rots",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "beedf2f2-d0d1-4974-be04-e28948336405"
      },
      "source": [
        "# PR-AUC\n",
        "avg_pr_elbo_class_results = pd.DataFrame((avg_class_results[0,2], std_class_results[0,2], \n",
        "                                  avg_class_results[1,2], std_class_results[1,2],\n",
        "                                  avg_class_results[2,2], std_class_results[2,2],  \n",
        "                                  avg_class_results[3,2], std_class_results[3,2], \n",
        "                                  avg_class_results[4,2], std_class_results[4,2], \n",
        "                                  avg_class_results[5,2], std_class_results[5,2], \n",
        "                                  ), \n",
        "                                  index = pr_header).T\n",
        "avg_pr_elbo_class_results = avg_pr_elbo_class_results.rename(index={0: \"mean\"})\n",
        "avg_pr_elbo_final_results = pd.DataFrame((avg_results[:,0,2], std_results[:,0,2],\n",
        "                                  avg_results[:,1,2], std_results[:,1,2], \n",
        "                                  avg_results[:,2,2], std_results[:,2,2], \n",
        "                                  avg_results[:,3,2], std_results[:,3,2], \n",
        "                                  avg_results[:,4,2], std_results[:,4,2],  \n",
        "                                  avg_results[:,5,2], std_results[:,5,2], \n",
        "                                  ), \n",
        "                                  index = pr_header, columns = index_labels).T\n",
        "avg_pr_elbo_final_results.append(avg_pr_elbo_class_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">pca</th>\n",
              "      <th colspan=\"2\" halign=\"left\">kpca</th>\n",
              "      <th colspan=\"2\" halign=\"left\">dsebm</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">vae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ed-vae</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.962871</td>\n",
              "      <td>0.003811</td>\n",
              "      <td>0.956042</td>\n",
              "      <td>0.005334</td>\n",
              "      <td>0.319372</td>\n",
              "      <td>0.287440</td>\n",
              "      <td>0.884234</td>\n",
              "      <td>0.011367</td>\n",
              "      <td>0.988285</td>\n",
              "      <td>0.003438</td>\n",
              "      <td>0.990907</td>\n",
              "      <td>0.001923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.995024</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>0.991530</td>\n",
              "      <td>0.000569</td>\n",
              "      <td>0.935702</td>\n",
              "      <td>0.031284</td>\n",
              "      <td>0.954844</td>\n",
              "      <td>0.005402</td>\n",
              "      <td>0.996292</td>\n",
              "      <td>0.000464</td>\n",
              "      <td>0.995649</td>\n",
              "      <td>0.000759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.808741</td>\n",
              "      <td>0.012070</td>\n",
              "      <td>0.743827</td>\n",
              "      <td>0.016023</td>\n",
              "      <td>0.278496</td>\n",
              "      <td>0.108636</td>\n",
              "      <td>0.498710</td>\n",
              "      <td>0.015766</td>\n",
              "      <td>0.846786</td>\n",
              "      <td>0.021684</td>\n",
              "      <td>0.882667</td>\n",
              "      <td>0.021451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.808417</td>\n",
              "      <td>0.013630</td>\n",
              "      <td>0.799806</td>\n",
              "      <td>0.016731</td>\n",
              "      <td>0.253902</td>\n",
              "      <td>0.028191</td>\n",
              "      <td>0.613603</td>\n",
              "      <td>0.024578</td>\n",
              "      <td>0.860224</td>\n",
              "      <td>0.023341</td>\n",
              "      <td>0.883761</td>\n",
              "      <td>0.020190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.876223</td>\n",
              "      <td>0.010232</td>\n",
              "      <td>0.863651</td>\n",
              "      <td>0.010238</td>\n",
              "      <td>0.446265</td>\n",
              "      <td>0.069021</td>\n",
              "      <td>0.666866</td>\n",
              "      <td>0.017487</td>\n",
              "      <td>0.894577</td>\n",
              "      <td>0.013628</td>\n",
              "      <td>0.912480</td>\n",
              "      <td>0.015687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.907688</td>\n",
              "      <td>0.009187</td>\n",
              "      <td>0.836815</td>\n",
              "      <td>0.011848</td>\n",
              "      <td>0.300565</td>\n",
              "      <td>0.022210</td>\n",
              "      <td>0.443555</td>\n",
              "      <td>0.016242</td>\n",
              "      <td>0.884872</td>\n",
              "      <td>0.011750</td>\n",
              "      <td>0.900353</td>\n",
              "      <td>0.011562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.948166</td>\n",
              "      <td>0.004434</td>\n",
              "      <td>0.912611</td>\n",
              "      <td>0.006725</td>\n",
              "      <td>0.320903</td>\n",
              "      <td>0.093916</td>\n",
              "      <td>0.546778</td>\n",
              "      <td>0.013287</td>\n",
              "      <td>0.962311</td>\n",
              "      <td>0.008520</td>\n",
              "      <td>0.973199</td>\n",
              "      <td>0.005970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.913185</td>\n",
              "      <td>0.009281</td>\n",
              "      <td>0.894678</td>\n",
              "      <td>0.011315</td>\n",
              "      <td>0.586697</td>\n",
              "      <td>0.028410</td>\n",
              "      <td>0.751677</td>\n",
              "      <td>0.014373</td>\n",
              "      <td>0.913266</td>\n",
              "      <td>0.011386</td>\n",
              "      <td>0.924547</td>\n",
              "      <td>0.009787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.698792</td>\n",
              "      <td>0.019722</td>\n",
              "      <td>0.682095</td>\n",
              "      <td>0.018040</td>\n",
              "      <td>0.213635</td>\n",
              "      <td>0.071373</td>\n",
              "      <td>0.460720</td>\n",
              "      <td>0.066113</td>\n",
              "      <td>0.809002</td>\n",
              "      <td>0.019917</td>\n",
              "      <td>0.845131</td>\n",
              "      <td>0.016582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.879265</td>\n",
              "      <td>0.005546</td>\n",
              "      <td>0.831620</td>\n",
              "      <td>0.008073</td>\n",
              "      <td>0.435122</td>\n",
              "      <td>0.046868</td>\n",
              "      <td>0.622364</td>\n",
              "      <td>0.017670</td>\n",
              "      <td>0.920291</td>\n",
              "      <td>0.008016</td>\n",
              "      <td>0.936706</td>\n",
              "      <td>0.005146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.879837</td>\n",
              "      <td>0.084099</td>\n",
              "      <td>0.851267</td>\n",
              "      <td>0.090129</td>\n",
              "      <td>0.409066</td>\n",
              "      <td>0.231569</td>\n",
              "      <td>0.644335</td>\n",
              "      <td>0.166980</td>\n",
              "      <td>0.907590</td>\n",
              "      <td>0.059939</td>\n",
              "      <td>0.924540</td>\n",
              "      <td>0.049106</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             pca                   kpca                  dsebm             \\\n",
              "     pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std   \n",
              "0       0.962871   0.003811    0.956042   0.005334    0.319372   0.287440   \n",
              "1       0.995024   0.000561    0.991530   0.000569    0.935702   0.031284   \n",
              "2       0.808741   0.012070    0.743827   0.016023    0.278496   0.108636   \n",
              "3       0.808417   0.013630    0.799806   0.016731    0.253902   0.028191   \n",
              "4       0.876223   0.010232    0.863651   0.010238    0.446265   0.069021   \n",
              "5       0.907688   0.009187    0.836815   0.011848    0.300565   0.022210   \n",
              "6       0.948166   0.004434    0.912611   0.006725    0.320903   0.093916   \n",
              "7       0.913185   0.009281    0.894678   0.011315    0.586697   0.028410   \n",
              "8       0.698792   0.019722    0.682095   0.018040    0.213635   0.071373   \n",
              "9       0.879265   0.005546    0.831620   0.008073    0.435122   0.046868   \n",
              "mean    0.879837   0.084099    0.851267   0.090129    0.409066   0.231569   \n",
              "\n",
              "              ae                    vae                 ed-vae             \n",
              "     pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std  \n",
              "0       0.884234   0.011367    0.988285   0.003438    0.990907   0.001923  \n",
              "1       0.954844   0.005402    0.996292   0.000464    0.995649   0.000759  \n",
              "2       0.498710   0.015766    0.846786   0.021684    0.882667   0.021451  \n",
              "3       0.613603   0.024578    0.860224   0.023341    0.883761   0.020190  \n",
              "4       0.666866   0.017487    0.894577   0.013628    0.912480   0.015687  \n",
              "5       0.443555   0.016242    0.884872   0.011750    0.900353   0.011562  \n",
              "6       0.546778   0.013287    0.962311   0.008520    0.973199   0.005970  \n",
              "7       0.751677   0.014373    0.913266   0.011386    0.924547   0.009787  \n",
              "8       0.460720   0.066113    0.809002   0.019917    0.845131   0.016582  \n",
              "9       0.622364   0.017670    0.920291   0.008016    0.936706   0.005146  \n",
              "mean    0.644335   0.166980    0.907590   0.059939    0.924540   0.049106  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrzSPJk9RE93"
      },
      "source": [
        "### $R_{error}$\n",
        "Compare Reconstruction Error of VAE and ED-VAE to results of competitive models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nx6NOTySnLL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "05e23191-f8e2-44f4-91b9-78b74c2e1a08"
      },
      "source": [
        "# AUC\n",
        "avg_auc_rec_class_results = pd.DataFrame((avg_class_results[0,1], std_class_results[0,1], \n",
        "                                  avg_class_results[1,1], std_class_results[1,1],\n",
        "                                  avg_class_results[2,1], std_class_results[2,1],  \n",
        "                                  avg_class_results[3,1], std_class_results[3,1], \n",
        "                                  avg_class_results[4,1], std_class_results[4,1], \n",
        "                                  avg_class_results[5,1], std_class_results[5,1], \n",
        "                                  ), \n",
        "                                  index = auc_header).T\n",
        "avg_auc_rec_class_results = avg_auc_rec_class_results.rename(index={0: \"mean\"})\n",
        "avg_auc_rec_final_results = pd.DataFrame((avg_results[:,0,1], std_results[:,0,1], \n",
        "                                  avg_results[:,1,1], std_results[:,1,1],\n",
        "                                  avg_results[:,2,1], std_results[:,2,1],  \n",
        "                                  avg_results[:,3,1], std_results[:,3,1], \n",
        "                                  avg_results[:,4,1], std_results[:,4,1], \n",
        "                                  avg_results[:,5,1], std_results[:,5,1], \n",
        "                                  ), \n",
        "                                  index = auc_header, columns = index_labels).T\n",
        "avg_auc_rec_final_results.append(avg_auc_rec_class_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">pca</th>\n",
              "      <th colspan=\"2\" halign=\"left\">kpca</th>\n",
              "      <th colspan=\"2\" halign=\"left\">dsebm</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">vae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ed-vae</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.991902</td>\n",
              "      <td>0.001006</td>\n",
              "      <td>0.989760</td>\n",
              "      <td>0.001497</td>\n",
              "      <td>0.536940</td>\n",
              "      <td>0.246504</td>\n",
              "      <td>0.969052</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.997371</td>\n",
              "      <td>0.000639</td>\n",
              "      <td>0.997917</td>\n",
              "      <td>0.000565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.998884</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>0.998158</td>\n",
              "      <td>0.000112</td>\n",
              "      <td>0.982074</td>\n",
              "      <td>0.009387</td>\n",
              "      <td>0.987335</td>\n",
              "      <td>0.001369</td>\n",
              "      <td>0.999397</td>\n",
              "      <td>0.000117</td>\n",
              "      <td>0.999129</td>\n",
              "      <td>0.000161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.924497</td>\n",
              "      <td>0.007101</td>\n",
              "      <td>0.896655</td>\n",
              "      <td>0.009141</td>\n",
              "      <td>0.518324</td>\n",
              "      <td>0.132393</td>\n",
              "      <td>0.780557</td>\n",
              "      <td>0.007687</td>\n",
              "      <td>0.927271</td>\n",
              "      <td>0.013782</td>\n",
              "      <td>0.956265</td>\n",
              "      <td>0.009806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.952098</td>\n",
              "      <td>0.004585</td>\n",
              "      <td>0.938679</td>\n",
              "      <td>0.007595</td>\n",
              "      <td>0.508091</td>\n",
              "      <td>0.038067</td>\n",
              "      <td>0.858054</td>\n",
              "      <td>0.009869</td>\n",
              "      <td>0.941618</td>\n",
              "      <td>0.010844</td>\n",
              "      <td>0.956757</td>\n",
              "      <td>0.008551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.943417</td>\n",
              "      <td>0.004557</td>\n",
              "      <td>0.945677</td>\n",
              "      <td>0.004942</td>\n",
              "      <td>0.692532</td>\n",
              "      <td>0.064927</td>\n",
              "      <td>0.882161</td>\n",
              "      <td>0.009189</td>\n",
              "      <td>0.946698</td>\n",
              "      <td>0.010322</td>\n",
              "      <td>0.963841</td>\n",
              "      <td>0.011562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.974173</td>\n",
              "      <td>0.003210</td>\n",
              "      <td>0.950427</td>\n",
              "      <td>0.004540</td>\n",
              "      <td>0.556980</td>\n",
              "      <td>0.024939</td>\n",
              "      <td>0.725093</td>\n",
              "      <td>0.011491</td>\n",
              "      <td>0.958839</td>\n",
              "      <td>0.004844</td>\n",
              "      <td>0.968716</td>\n",
              "      <td>0.005531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.983505</td>\n",
              "      <td>0.001988</td>\n",
              "      <td>0.973489</td>\n",
              "      <td>0.002965</td>\n",
              "      <td>0.584922</td>\n",
              "      <td>0.131559</td>\n",
              "      <td>0.868427</td>\n",
              "      <td>0.006613</td>\n",
              "      <td>0.990615</td>\n",
              "      <td>0.002973</td>\n",
              "      <td>0.994452</td>\n",
              "      <td>0.001617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.970885</td>\n",
              "      <td>0.003842</td>\n",
              "      <td>0.964386</td>\n",
              "      <td>0.005171</td>\n",
              "      <td>0.757129</td>\n",
              "      <td>0.026946</td>\n",
              "      <td>0.912264</td>\n",
              "      <td>0.008214</td>\n",
              "      <td>0.960097</td>\n",
              "      <td>0.007662</td>\n",
              "      <td>0.969931</td>\n",
              "      <td>0.005128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.854871</td>\n",
              "      <td>0.016547</td>\n",
              "      <td>0.854343</td>\n",
              "      <td>0.016311</td>\n",
              "      <td>0.463918</td>\n",
              "      <td>0.102268</td>\n",
              "      <td>0.779581</td>\n",
              "      <td>0.024401</td>\n",
              "      <td>0.895123</td>\n",
              "      <td>0.013470</td>\n",
              "      <td>0.910591</td>\n",
              "      <td>0.017666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.963962</td>\n",
              "      <td>0.001586</td>\n",
              "      <td>0.954091</td>\n",
              "      <td>0.001989</td>\n",
              "      <td>0.663246</td>\n",
              "      <td>0.054227</td>\n",
              "      <td>0.880227</td>\n",
              "      <td>0.006204</td>\n",
              "      <td>0.978472</td>\n",
              "      <td>0.003114</td>\n",
              "      <td>0.985888</td>\n",
              "      <td>0.001568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.955819</td>\n",
              "      <td>0.040362</td>\n",
              "      <td>0.946566</td>\n",
              "      <td>0.041466</td>\n",
              "      <td>0.626416</td>\n",
              "      <td>0.182221</td>\n",
              "      <td>0.864275</td>\n",
              "      <td>0.079840</td>\n",
              "      <td>0.959550</td>\n",
              "      <td>0.032739</td>\n",
              "      <td>0.970349</td>\n",
              "      <td>0.026622</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           pca                kpca               dsebm                  ae  \\\n",
              "      auc_mean   auc_std  auc_mean   auc_std  auc_mean   auc_std  auc_mean   \n",
              "0     0.991902  0.001006  0.989760  0.001497  0.536940  0.246504  0.969052   \n",
              "1     0.998884  0.000132  0.998158  0.000112  0.982074  0.009387  0.987335   \n",
              "2     0.924497  0.007101  0.896655  0.009141  0.518324  0.132393  0.780557   \n",
              "3     0.952098  0.004585  0.938679  0.007595  0.508091  0.038067  0.858054   \n",
              "4     0.943417  0.004557  0.945677  0.004942  0.692532  0.064927  0.882161   \n",
              "5     0.974173  0.003210  0.950427  0.004540  0.556980  0.024939  0.725093   \n",
              "6     0.983505  0.001988  0.973489  0.002965  0.584922  0.131559  0.868427   \n",
              "7     0.970885  0.003842  0.964386  0.005171  0.757129  0.026946  0.912264   \n",
              "8     0.854871  0.016547  0.854343  0.016311  0.463918  0.102268  0.779581   \n",
              "9     0.963962  0.001586  0.954091  0.001989  0.663246  0.054227  0.880227   \n",
              "mean  0.955819  0.040362  0.946566  0.041466  0.626416  0.182221  0.864275   \n",
              "\n",
              "                     vae              ed-vae            \n",
              "       auc_std  auc_mean   auc_std  auc_mean   auc_std  \n",
              "0     0.003922  0.997371  0.000639  0.997917  0.000565  \n",
              "1     0.001369  0.999397  0.000117  0.999129  0.000161  \n",
              "2     0.007687  0.927271  0.013782  0.956265  0.009806  \n",
              "3     0.009869  0.941618  0.010844  0.956757  0.008551  \n",
              "4     0.009189  0.946698  0.010322  0.963841  0.011562  \n",
              "5     0.011491  0.958839  0.004844  0.968716  0.005531  \n",
              "6     0.006613  0.990615  0.002973  0.994452  0.001617  \n",
              "7     0.008214  0.960097  0.007662  0.969931  0.005128  \n",
              "8     0.024401  0.895123  0.013470  0.910591  0.017666  \n",
              "9     0.006204  0.978472  0.003114  0.985888  0.001568  \n",
              "mean  0.079840  0.959550  0.032739  0.970349  0.026622  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOb8UOKU6jOM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "e5cc012e-32ca-4069-8a91-cba528b4851d"
      },
      "source": [
        "# PR-AUC\n",
        "avg_pr_rec_class_results = pd.DataFrame((avg_class_results[0,0], std_class_results[0,0], \n",
        "                                  avg_class_results[1,0], std_class_results[1,0],\n",
        "                                  avg_class_results[2,0], std_class_results[2,0],  \n",
        "                                  avg_class_results[3,0], std_class_results[3,0], \n",
        "                                  avg_class_results[4,0], std_class_results[4,0], \n",
        "                                  avg_class_results[5,0], std_class_results[5,0], \n",
        "                                  ), \n",
        "                                  index = pr_header).T\n",
        "avg_pr_rec_class_results = avg_pr_rec_class_results.rename(index={0: \"mean\"})\n",
        "avg_pr_rec_final_results = pd.DataFrame((avg_results[:,0,0], std_results[:,0,0], \n",
        "                                  avg_results[:,1,0], std_results[:,1,0],\n",
        "                                  avg_results[:,2,0], std_results[:,2,0],  \n",
        "                                  avg_results[:,3,0], std_results[:,3,0], \n",
        "                                  avg_results[:,4,0], std_results[:,4,0], \n",
        "                                  avg_results[:,5,0], std_results[:,5,0], \n",
        "                                  ), \n",
        "                                  index = pr_header, columns = index_labels).T\n",
        "avg_pr_rec_final_results.append(avg_pr_rec_class_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">pca</th>\n",
              "      <th colspan=\"2\" halign=\"left\">kpca</th>\n",
              "      <th colspan=\"2\" halign=\"left\">dsebm</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">vae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ed-vae</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.962871</td>\n",
              "      <td>0.003811</td>\n",
              "      <td>0.956042</td>\n",
              "      <td>0.005334</td>\n",
              "      <td>0.319372</td>\n",
              "      <td>0.287440</td>\n",
              "      <td>0.884234</td>\n",
              "      <td>0.011367</td>\n",
              "      <td>0.988409</td>\n",
              "      <td>0.003320</td>\n",
              "      <td>0.990896</td>\n",
              "      <td>0.002023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.995024</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>0.991530</td>\n",
              "      <td>0.000569</td>\n",
              "      <td>0.935702</td>\n",
              "      <td>0.031284</td>\n",
              "      <td>0.954844</td>\n",
              "      <td>0.005402</td>\n",
              "      <td>0.997493</td>\n",
              "      <td>0.000477</td>\n",
              "      <td>0.996406</td>\n",
              "      <td>0.000687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.808741</td>\n",
              "      <td>0.012070</td>\n",
              "      <td>0.743827</td>\n",
              "      <td>0.016023</td>\n",
              "      <td>0.278496</td>\n",
              "      <td>0.108636</td>\n",
              "      <td>0.498710</td>\n",
              "      <td>0.015766</td>\n",
              "      <td>0.842210</td>\n",
              "      <td>0.022451</td>\n",
              "      <td>0.886398</td>\n",
              "      <td>0.020869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.808417</td>\n",
              "      <td>0.013630</td>\n",
              "      <td>0.799806</td>\n",
              "      <td>0.016731</td>\n",
              "      <td>0.253902</td>\n",
              "      <td>0.028191</td>\n",
              "      <td>0.613603</td>\n",
              "      <td>0.024578</td>\n",
              "      <td>0.857914</td>\n",
              "      <td>0.020537</td>\n",
              "      <td>0.884915</td>\n",
              "      <td>0.016641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.876223</td>\n",
              "      <td>0.010232</td>\n",
              "      <td>0.863651</td>\n",
              "      <td>0.010238</td>\n",
              "      <td>0.446265</td>\n",
              "      <td>0.069021</td>\n",
              "      <td>0.666866</td>\n",
              "      <td>0.017487</td>\n",
              "      <td>0.897972</td>\n",
              "      <td>0.015864</td>\n",
              "      <td>0.917361</td>\n",
              "      <td>0.018964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.907688</td>\n",
              "      <td>0.009187</td>\n",
              "      <td>0.836815</td>\n",
              "      <td>0.011848</td>\n",
              "      <td>0.300565</td>\n",
              "      <td>0.022210</td>\n",
              "      <td>0.443555</td>\n",
              "      <td>0.016242</td>\n",
              "      <td>0.894223</td>\n",
              "      <td>0.010736</td>\n",
              "      <td>0.910305</td>\n",
              "      <td>0.011131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.948166</td>\n",
              "      <td>0.004434</td>\n",
              "      <td>0.912611</td>\n",
              "      <td>0.006725</td>\n",
              "      <td>0.320903</td>\n",
              "      <td>0.093916</td>\n",
              "      <td>0.546778</td>\n",
              "      <td>0.013287</td>\n",
              "      <td>0.967355</td>\n",
              "      <td>0.007963</td>\n",
              "      <td>0.977310</td>\n",
              "      <td>0.005809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.913185</td>\n",
              "      <td>0.009281</td>\n",
              "      <td>0.894678</td>\n",
              "      <td>0.011315</td>\n",
              "      <td>0.586697</td>\n",
              "      <td>0.028410</td>\n",
              "      <td>0.751677</td>\n",
              "      <td>0.014373</td>\n",
              "      <td>0.909373</td>\n",
              "      <td>0.011026</td>\n",
              "      <td>0.921433</td>\n",
              "      <td>0.009237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.698792</td>\n",
              "      <td>0.019722</td>\n",
              "      <td>0.682095</td>\n",
              "      <td>0.018040</td>\n",
              "      <td>0.213635</td>\n",
              "      <td>0.071373</td>\n",
              "      <td>0.460720</td>\n",
              "      <td>0.066113</td>\n",
              "      <td>0.818364</td>\n",
              "      <td>0.018461</td>\n",
              "      <td>0.855947</td>\n",
              "      <td>0.016364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.879265</td>\n",
              "      <td>0.005546</td>\n",
              "      <td>0.831620</td>\n",
              "      <td>0.008073</td>\n",
              "      <td>0.435122</td>\n",
              "      <td>0.046868</td>\n",
              "      <td>0.622364</td>\n",
              "      <td>0.017670</td>\n",
              "      <td>0.928812</td>\n",
              "      <td>0.007496</td>\n",
              "      <td>0.945767</td>\n",
              "      <td>0.004407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.879837</td>\n",
              "      <td>0.084099</td>\n",
              "      <td>0.851267</td>\n",
              "      <td>0.090129</td>\n",
              "      <td>0.409066</td>\n",
              "      <td>0.231569</td>\n",
              "      <td>0.644335</td>\n",
              "      <td>0.166980</td>\n",
              "      <td>0.910212</td>\n",
              "      <td>0.059524</td>\n",
              "      <td>0.928674</td>\n",
              "      <td>0.047152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             pca                   kpca                  dsebm             \\\n",
              "     pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std   \n",
              "0       0.962871   0.003811    0.956042   0.005334    0.319372   0.287440   \n",
              "1       0.995024   0.000561    0.991530   0.000569    0.935702   0.031284   \n",
              "2       0.808741   0.012070    0.743827   0.016023    0.278496   0.108636   \n",
              "3       0.808417   0.013630    0.799806   0.016731    0.253902   0.028191   \n",
              "4       0.876223   0.010232    0.863651   0.010238    0.446265   0.069021   \n",
              "5       0.907688   0.009187    0.836815   0.011848    0.300565   0.022210   \n",
              "6       0.948166   0.004434    0.912611   0.006725    0.320903   0.093916   \n",
              "7       0.913185   0.009281    0.894678   0.011315    0.586697   0.028410   \n",
              "8       0.698792   0.019722    0.682095   0.018040    0.213635   0.071373   \n",
              "9       0.879265   0.005546    0.831620   0.008073    0.435122   0.046868   \n",
              "mean    0.879837   0.084099    0.851267   0.090129    0.409066   0.231569   \n",
              "\n",
              "              ae                    vae                 ed-vae             \n",
              "     pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std  \n",
              "0       0.884234   0.011367    0.988409   0.003320    0.990896   0.002023  \n",
              "1       0.954844   0.005402    0.997493   0.000477    0.996406   0.000687  \n",
              "2       0.498710   0.015766    0.842210   0.022451    0.886398   0.020869  \n",
              "3       0.613603   0.024578    0.857914   0.020537    0.884915   0.016641  \n",
              "4       0.666866   0.017487    0.897972   0.015864    0.917361   0.018964  \n",
              "5       0.443555   0.016242    0.894223   0.010736    0.910305   0.011131  \n",
              "6       0.546778   0.013287    0.967355   0.007963    0.977310   0.005809  \n",
              "7       0.751677   0.014373    0.909373   0.011026    0.921433   0.009237  \n",
              "8       0.460720   0.066113    0.818364   0.018461    0.855947   0.016364  \n",
              "9       0.622364   0.017670    0.928812   0.007496    0.945767   0.004407  \n",
              "mean    0.644335   0.166980    0.910212   0.059524    0.928674   0.047152  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPi0xeGAnpVi"
      },
      "source": [
        "## Formated for Publication\n",
        "Mean and SEM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5RBEX7PyD3y"
      },
      "source": [
        "# returns the list for df.style.apply() method\n",
        "def highlight_max(s):\n",
        "    s = s.str.split(pat='±',expand=True)[0]\n",
        "    is_max = s == s.max()\n",
        "    #print(s)\n",
        "    #print(is_max)\n",
        "    #return ['background: lightgreen' if cell else '' for cell in is_max]\n",
        "    return ['font-weight: bold' if cell else '' for cell in is_max]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1KDkJyD5-0K"
      },
      "source": [
        "###ELBO\n",
        "Compare ELBO of VAE and ED-VAE to results of competitive models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poEcAPrgPiwp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "32e3dbd5-1f07-4ef5-fc4f-a083e568b7e5"
      },
      "source": [
        "# AUC\n",
        "df = pd.DataFrame((\n",
        "    round(avg_auc_elbo_final_results[column,'auc_mean']*100,1).astype(str) + '±' + round(avg_auc_elbo_final_results[column,'auc_std']*100/np.sqrt(reps),1).astype(str) for column in avg_auc_elbo_final_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_auc_elbo_final_results.keys().get_level_values(0)[::2]).T\n",
        "df = df.append(pd.DataFrame((\n",
        "    #round(avg_auc_elbo_class_results[column,'auc_mean']*100,1).astype(str) + '±' + round(avg_auc_elbo_class_results[column,'pr_auc_std']*100/np.sqrt(reps * len(df.index)),1).astype(str) for column in avg_auc_elbo_class_results.keys().get_level_values(0)[::2]\n",
        "    round(avg_auc_elbo_class_results[column,'auc_mean']*100,1).astype(str) for column in avg_auc_elbo_class_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_auc_elbo_class_results.keys().get_level_values(0)[::2]).T)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pca</th>\n",
              "      <th>kpca</th>\n",
              "      <th>dsebm</th>\n",
              "      <th>ae</th>\n",
              "      <th>vae</th>\n",
              "      <th>ed-vae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>99.2±0.0</td>\n",
              "      <td>99.0±0.0</td>\n",
              "      <td>53.7±7.8</td>\n",
              "      <td>96.9±0.1</td>\n",
              "      <td>99.7±0.0</td>\n",
              "      <td>99.8±0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>99.9±0.0</td>\n",
              "      <td>99.8±0.0</td>\n",
              "      <td>98.2±0.3</td>\n",
              "      <td>98.7±0.0</td>\n",
              "      <td>99.9±0.0</td>\n",
              "      <td>99.9±0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>92.4±0.2</td>\n",
              "      <td>89.7±0.3</td>\n",
              "      <td>51.8±4.2</td>\n",
              "      <td>78.1±0.2</td>\n",
              "      <td>93.0±0.4</td>\n",
              "      <td>95.3±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95.2±0.1</td>\n",
              "      <td>93.9±0.2</td>\n",
              "      <td>50.8±1.2</td>\n",
              "      <td>85.8±0.3</td>\n",
              "      <td>94.6±0.4</td>\n",
              "      <td>95.8±0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>94.3±0.1</td>\n",
              "      <td>94.6±0.2</td>\n",
              "      <td>69.3±2.1</td>\n",
              "      <td>88.2±0.3</td>\n",
              "      <td>95.0±0.2</td>\n",
              "      <td>96.3±0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>97.4±0.1</td>\n",
              "      <td>95.0±0.1</td>\n",
              "      <td>55.7±0.8</td>\n",
              "      <td>72.5±0.4</td>\n",
              "      <td>95.8±0.2</td>\n",
              "      <td>96.7±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>98.4±0.1</td>\n",
              "      <td>97.3±0.1</td>\n",
              "      <td>58.5±4.2</td>\n",
              "      <td>86.8±0.2</td>\n",
              "      <td>98.9±0.1</td>\n",
              "      <td>99.3±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>97.1±0.1</td>\n",
              "      <td>96.4±0.2</td>\n",
              "      <td>75.7±0.9</td>\n",
              "      <td>91.2±0.3</td>\n",
              "      <td>96.5±0.2</td>\n",
              "      <td>97.3±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>85.5±0.5</td>\n",
              "      <td>85.4±0.5</td>\n",
              "      <td>46.4±3.2</td>\n",
              "      <td>78.0±0.8</td>\n",
              "      <td>89.5±0.4</td>\n",
              "      <td>91.1±0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>96.4±0.1</td>\n",
              "      <td>95.4±0.1</td>\n",
              "      <td>66.3±1.7</td>\n",
              "      <td>88.0±0.2</td>\n",
              "      <td>97.6±0.1</td>\n",
              "      <td>98.3±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>95.6</td>\n",
              "      <td>94.7</td>\n",
              "      <td>62.6</td>\n",
              "      <td>86.4</td>\n",
              "      <td>96.0</td>\n",
              "      <td>97.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           pca      kpca     dsebm        ae       vae    ed-vae\n",
              "0     99.2±0.0  99.0±0.0  53.7±7.8  96.9±0.1  99.7±0.0  99.8±0.0\n",
              "1     99.9±0.0  99.8±0.0  98.2±0.3  98.7±0.0  99.9±0.0  99.9±0.0\n",
              "2     92.4±0.2  89.7±0.3  51.8±4.2  78.1±0.2  93.0±0.4  95.3±0.4\n",
              "3     95.2±0.1  93.9±0.2  50.8±1.2  85.8±0.3  94.6±0.4  95.8±0.3\n",
              "4     94.3±0.1  94.6±0.2  69.3±2.1  88.2±0.3  95.0±0.2  96.3±0.3\n",
              "5     97.4±0.1  95.0±0.1  55.7±0.8  72.5±0.4  95.8±0.2  96.7±0.2\n",
              "6     98.4±0.1  97.3±0.1  58.5±4.2  86.8±0.2  98.9±0.1  99.3±0.1\n",
              "7     97.1±0.1  96.4±0.2  75.7±0.9  91.2±0.3  96.5±0.2  97.3±0.2\n",
              "8     85.5±0.5  85.4±0.5  46.4±3.2  78.0±0.8  89.5±0.4  91.1±0.5\n",
              "9     96.4±0.1  95.4±0.1  66.3±1.7  88.0±0.2  97.6±0.1  98.3±0.1\n",
              "mean      95.6      94.7      62.6      86.4      96.0      97.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_AOdoyy_SJ9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "36b9eeeb-bd59-4b3e-b27a-75083195f1ed"
      },
      "source": [
        "df.style.apply(highlight_max, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row0_col5,#T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row1_col0,#T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row1_col4,#T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row1_col5,#T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row2_col5,#T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row3_col5,#T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row4_col5,#T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row5_col0,#T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row6_col5,#T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row7_col5,#T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row8_col5,#T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row9_col5,#T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row10_col5{\n",
              "            font-weight:  bold;\n",
              "        }</style><table id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >pca</th>        <th class=\"col_heading level0 col1\" >kpca</th>        <th class=\"col_heading level0 col2\" >dsebm</th>        <th class=\"col_heading level0 col3\" >ae</th>        <th class=\"col_heading level0 col4\" >vae</th>        <th class=\"col_heading level0 col5\" >ed-vae</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row0_col0\" class=\"data row0 col0\" >99.2±0.0</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row0_col1\" class=\"data row0 col1\" >99.0±0.0</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row0_col2\" class=\"data row0 col2\" >53.7±7.8</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row0_col3\" class=\"data row0 col3\" >96.9±0.1</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row0_col4\" class=\"data row0 col4\" >99.7±0.0</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row0_col5\" class=\"data row0 col5\" >99.8±0.0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row1_col0\" class=\"data row1 col0\" >99.9±0.0</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row1_col1\" class=\"data row1 col1\" >99.8±0.0</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row1_col2\" class=\"data row1 col2\" >98.2±0.3</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row1_col3\" class=\"data row1 col3\" >98.7±0.0</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row1_col4\" class=\"data row1 col4\" >99.9±0.0</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row1_col5\" class=\"data row1 col5\" >99.9±0.0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row2_col0\" class=\"data row2 col0\" >92.4±0.2</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row2_col1\" class=\"data row2 col1\" >89.7±0.3</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row2_col2\" class=\"data row2 col2\" >51.8±4.2</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row2_col3\" class=\"data row2 col3\" >78.1±0.2</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row2_col4\" class=\"data row2 col4\" >93.0±0.4</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row2_col5\" class=\"data row2 col5\" >95.3±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row3_col0\" class=\"data row3 col0\" >95.2±0.1</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row3_col1\" class=\"data row3 col1\" >93.9±0.2</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row3_col2\" class=\"data row3 col2\" >50.8±1.2</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row3_col3\" class=\"data row3 col3\" >85.8±0.3</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row3_col4\" class=\"data row3 col4\" >94.6±0.4</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row3_col5\" class=\"data row3 col5\" >95.8±0.3</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row4_col0\" class=\"data row4 col0\" >94.3±0.1</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row4_col1\" class=\"data row4 col1\" >94.6±0.2</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row4_col2\" class=\"data row4 col2\" >69.3±2.1</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row4_col3\" class=\"data row4 col3\" >88.2±0.3</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row4_col4\" class=\"data row4 col4\" >95.0±0.2</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row4_col5\" class=\"data row4 col5\" >96.3±0.3</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row5_col0\" class=\"data row5 col0\" >97.4±0.1</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row5_col1\" class=\"data row5 col1\" >95.0±0.1</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row5_col2\" class=\"data row5 col2\" >55.7±0.8</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row5_col3\" class=\"data row5 col3\" >72.5±0.4</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row5_col4\" class=\"data row5 col4\" >95.8±0.2</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row5_col5\" class=\"data row5 col5\" >96.7±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row6_col0\" class=\"data row6 col0\" >98.4±0.1</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row6_col1\" class=\"data row6 col1\" >97.3±0.1</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row6_col2\" class=\"data row6 col2\" >58.5±4.2</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row6_col3\" class=\"data row6 col3\" >86.8±0.2</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row6_col4\" class=\"data row6 col4\" >98.9±0.1</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row6_col5\" class=\"data row6 col5\" >99.3±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row7_col0\" class=\"data row7 col0\" >97.1±0.1</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row7_col1\" class=\"data row7 col1\" >96.4±0.2</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row7_col2\" class=\"data row7 col2\" >75.7±0.9</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row7_col3\" class=\"data row7 col3\" >91.2±0.3</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row7_col4\" class=\"data row7 col4\" >96.5±0.2</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row7_col5\" class=\"data row7 col5\" >97.3±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row8_col0\" class=\"data row8 col0\" >85.5±0.5</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row8_col1\" class=\"data row8 col1\" >85.4±0.5</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row8_col2\" class=\"data row8 col2\" >46.4±3.2</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row8_col3\" class=\"data row8 col3\" >78.0±0.8</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row8_col4\" class=\"data row8 col4\" >89.5±0.4</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row8_col5\" class=\"data row8 col5\" >91.1±0.5</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row9_col0\" class=\"data row9 col0\" >96.4±0.1</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row9_col1\" class=\"data row9 col1\" >95.4±0.1</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row9_col2\" class=\"data row9 col2\" >66.3±1.7</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row9_col3\" class=\"data row9 col3\" >88.0±0.2</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row9_col4\" class=\"data row9 col4\" >97.6±0.1</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row9_col5\" class=\"data row9 col5\" >98.3±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >mean</th>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row10_col0\" class=\"data row10 col0\" >95.6</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row10_col1\" class=\"data row10 col1\" >94.7</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row10_col2\" class=\"data row10 col2\" >62.6</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row10_col3\" class=\"data row10 col3\" >86.4</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row10_col4\" class=\"data row10 col4\" >96.0</td>\n",
              "                        <td id=\"T_c4c07bfe_bf26_11eb_abda_0242ac1c0002row10_col5\" class=\"data row10 col5\" >97.0</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f1b8251fb10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CndoxB3bPiwm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "befa50e9-887c-4b1f-8240-b589779b1d33"
      },
      "source": [
        "# PR-AUC\n",
        "df = pd.DataFrame((\n",
        "    round(avg_pr_elbo_final_results[column,'pr_auc_mean']*100,1).astype(str) + '±' + round(avg_pr_elbo_final_results[column,'pr_auc_std']*100/np.sqrt(reps),1).astype(str) for column in avg_pr_elbo_final_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_pr_elbo_final_results.keys().get_level_values(0)[::2]).T  \n",
        "df = df.append(pd.DataFrame((\n",
        "    #round(avg_pr_elbo_class_results[column,'pr_auc_mean']*100,1).astype(str) + '±' + round(avg_pr_elbo_class_results[column,'pr_auc_std']*100/np.sqrt(reps * len(df.index)),1).astype(str) for column in avg_pr_elbo_class_results.keys().get_level_values(0)[::2]\n",
        "    round(avg_pr_elbo_class_results[column,'pr_auc_mean']*100,1).astype(str) for column in avg_pr_elbo_class_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_pr_elbo_class_results.keys().get_level_values(0)[::2]).T)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pca</th>\n",
              "      <th>kpca</th>\n",
              "      <th>dsebm</th>\n",
              "      <th>ae</th>\n",
              "      <th>vae</th>\n",
              "      <th>ed-vae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>96.3±0.1</td>\n",
              "      <td>95.6±0.2</td>\n",
              "      <td>31.9±9.1</td>\n",
              "      <td>88.4±0.4</td>\n",
              "      <td>98.8±0.1</td>\n",
              "      <td>99.1±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>99.5±0.0</td>\n",
              "      <td>99.2±0.0</td>\n",
              "      <td>93.6±1.0</td>\n",
              "      <td>95.5±0.2</td>\n",
              "      <td>99.6±0.0</td>\n",
              "      <td>99.6±0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>80.9±0.4</td>\n",
              "      <td>74.4±0.5</td>\n",
              "      <td>27.8±3.4</td>\n",
              "      <td>49.9±0.5</td>\n",
              "      <td>84.7±0.7</td>\n",
              "      <td>88.3±0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80.8±0.4</td>\n",
              "      <td>80.0±0.5</td>\n",
              "      <td>25.4±0.9</td>\n",
              "      <td>61.4±0.8</td>\n",
              "      <td>86.0±0.7</td>\n",
              "      <td>88.4±0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>87.6±0.3</td>\n",
              "      <td>86.4±0.3</td>\n",
              "      <td>44.6±2.2</td>\n",
              "      <td>66.7±0.6</td>\n",
              "      <td>89.5±0.4</td>\n",
              "      <td>91.2±0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>90.8±0.3</td>\n",
              "      <td>83.7±0.4</td>\n",
              "      <td>30.1±0.7</td>\n",
              "      <td>44.4±0.5</td>\n",
              "      <td>88.5±0.4</td>\n",
              "      <td>90.0±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>94.8±0.1</td>\n",
              "      <td>91.3±0.2</td>\n",
              "      <td>32.1±3.0</td>\n",
              "      <td>54.7±0.4</td>\n",
              "      <td>96.2±0.3</td>\n",
              "      <td>97.3±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>91.3±0.3</td>\n",
              "      <td>89.5±0.4</td>\n",
              "      <td>58.7±0.9</td>\n",
              "      <td>75.2±0.5</td>\n",
              "      <td>91.3±0.4</td>\n",
              "      <td>92.5±0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>69.9±0.6</td>\n",
              "      <td>68.2±0.6</td>\n",
              "      <td>21.4±2.3</td>\n",
              "      <td>46.1±2.1</td>\n",
              "      <td>80.9±0.6</td>\n",
              "      <td>84.5±0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>87.9±0.2</td>\n",
              "      <td>83.2±0.3</td>\n",
              "      <td>43.5±1.5</td>\n",
              "      <td>62.2±0.6</td>\n",
              "      <td>92.0±0.3</td>\n",
              "      <td>93.7±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>88.0</td>\n",
              "      <td>85.1</td>\n",
              "      <td>40.9</td>\n",
              "      <td>64.4</td>\n",
              "      <td>90.8</td>\n",
              "      <td>92.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           pca      kpca     dsebm        ae       vae    ed-vae\n",
              "0     96.3±0.1  95.6±0.2  31.9±9.1  88.4±0.4  98.8±0.1  99.1±0.1\n",
              "1     99.5±0.0  99.2±0.0  93.6±1.0  95.5±0.2  99.6±0.0  99.6±0.0\n",
              "2     80.9±0.4  74.4±0.5  27.8±3.4  49.9±0.5  84.7±0.7  88.3±0.7\n",
              "3     80.8±0.4  80.0±0.5  25.4±0.9  61.4±0.8  86.0±0.7  88.4±0.6\n",
              "4     87.6±0.3  86.4±0.3  44.6±2.2  66.7±0.6  89.5±0.4  91.2±0.5\n",
              "5     90.8±0.3  83.7±0.4  30.1±0.7  44.4±0.5  88.5±0.4  90.0±0.4\n",
              "6     94.8±0.1  91.3±0.2  32.1±3.0  54.7±0.4  96.2±0.3  97.3±0.2\n",
              "7     91.3±0.3  89.5±0.4  58.7±0.9  75.2±0.5  91.3±0.4  92.5±0.3\n",
              "8     69.9±0.6  68.2±0.6  21.4±2.3  46.1±2.1  80.9±0.6  84.5±0.5\n",
              "9     87.9±0.2  83.2±0.3  43.5±1.5  62.2±0.6  92.0±0.3  93.7±0.2\n",
              "mean      88.0      85.1      40.9      64.4      90.8      92.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKOTKAHf_Rs-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "8e3f9bd2-5379-4a36-b411-431d39d3503e"
      },
      "source": [
        "df.style.apply(highlight_max, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_c4b508fa_bf26_11eb_abda_0242ac1c0002row0_col5,#T_c4b508fa_bf26_11eb_abda_0242ac1c0002row1_col4,#T_c4b508fa_bf26_11eb_abda_0242ac1c0002row1_col5,#T_c4b508fa_bf26_11eb_abda_0242ac1c0002row2_col5,#T_c4b508fa_bf26_11eb_abda_0242ac1c0002row3_col5,#T_c4b508fa_bf26_11eb_abda_0242ac1c0002row4_col5,#T_c4b508fa_bf26_11eb_abda_0242ac1c0002row5_col0,#T_c4b508fa_bf26_11eb_abda_0242ac1c0002row6_col5,#T_c4b508fa_bf26_11eb_abda_0242ac1c0002row7_col5,#T_c4b508fa_bf26_11eb_abda_0242ac1c0002row8_col5,#T_c4b508fa_bf26_11eb_abda_0242ac1c0002row9_col5,#T_c4b508fa_bf26_11eb_abda_0242ac1c0002row10_col5{\n",
              "            font-weight:  bold;\n",
              "        }</style><table id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >pca</th>        <th class=\"col_heading level0 col1\" >kpca</th>        <th class=\"col_heading level0 col2\" >dsebm</th>        <th class=\"col_heading level0 col3\" >ae</th>        <th class=\"col_heading level0 col4\" >vae</th>        <th class=\"col_heading level0 col5\" >ed-vae</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row0_col0\" class=\"data row0 col0\" >96.3±0.1</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row0_col1\" class=\"data row0 col1\" >95.6±0.2</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row0_col2\" class=\"data row0 col2\" >31.9±9.1</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row0_col3\" class=\"data row0 col3\" >88.4±0.4</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row0_col4\" class=\"data row0 col4\" >98.8±0.1</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row0_col5\" class=\"data row0 col5\" >99.1±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row1_col0\" class=\"data row1 col0\" >99.5±0.0</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row1_col1\" class=\"data row1 col1\" >99.2±0.0</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row1_col2\" class=\"data row1 col2\" >93.6±1.0</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row1_col3\" class=\"data row1 col3\" >95.5±0.2</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row1_col4\" class=\"data row1 col4\" >99.6±0.0</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row1_col5\" class=\"data row1 col5\" >99.6±0.0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row2_col0\" class=\"data row2 col0\" >80.9±0.4</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row2_col1\" class=\"data row2 col1\" >74.4±0.5</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row2_col2\" class=\"data row2 col2\" >27.8±3.4</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row2_col3\" class=\"data row2 col3\" >49.9±0.5</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row2_col4\" class=\"data row2 col4\" >84.7±0.7</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row2_col5\" class=\"data row2 col5\" >88.3±0.7</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row3_col0\" class=\"data row3 col0\" >80.8±0.4</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row3_col1\" class=\"data row3 col1\" >80.0±0.5</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row3_col2\" class=\"data row3 col2\" >25.4±0.9</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row3_col3\" class=\"data row3 col3\" >61.4±0.8</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row3_col4\" class=\"data row3 col4\" >86.0±0.7</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row3_col5\" class=\"data row3 col5\" >88.4±0.6</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row4_col0\" class=\"data row4 col0\" >87.6±0.3</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row4_col1\" class=\"data row4 col1\" >86.4±0.3</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row4_col2\" class=\"data row4 col2\" >44.6±2.2</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row4_col3\" class=\"data row4 col3\" >66.7±0.6</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row4_col4\" class=\"data row4 col4\" >89.5±0.4</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row4_col5\" class=\"data row4 col5\" >91.2±0.5</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row5_col0\" class=\"data row5 col0\" >90.8±0.3</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row5_col1\" class=\"data row5 col1\" >83.7±0.4</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row5_col2\" class=\"data row5 col2\" >30.1±0.7</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row5_col3\" class=\"data row5 col3\" >44.4±0.5</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row5_col4\" class=\"data row5 col4\" >88.5±0.4</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row5_col5\" class=\"data row5 col5\" >90.0±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row6_col0\" class=\"data row6 col0\" >94.8±0.1</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row6_col1\" class=\"data row6 col1\" >91.3±0.2</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row6_col2\" class=\"data row6 col2\" >32.1±3.0</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row6_col3\" class=\"data row6 col3\" >54.7±0.4</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row6_col4\" class=\"data row6 col4\" >96.2±0.3</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row6_col5\" class=\"data row6 col5\" >97.3±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row7_col0\" class=\"data row7 col0\" >91.3±0.3</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row7_col1\" class=\"data row7 col1\" >89.5±0.4</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row7_col2\" class=\"data row7 col2\" >58.7±0.9</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row7_col3\" class=\"data row7 col3\" >75.2±0.5</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row7_col4\" class=\"data row7 col4\" >91.3±0.4</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row7_col5\" class=\"data row7 col5\" >92.5±0.3</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row8_col0\" class=\"data row8 col0\" >69.9±0.6</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row8_col1\" class=\"data row8 col1\" >68.2±0.6</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row8_col2\" class=\"data row8 col2\" >21.4±2.3</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row8_col3\" class=\"data row8 col3\" >46.1±2.1</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row8_col4\" class=\"data row8 col4\" >80.9±0.6</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row8_col5\" class=\"data row8 col5\" >84.5±0.5</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row9_col0\" class=\"data row9 col0\" >87.9±0.2</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row9_col1\" class=\"data row9 col1\" >83.2±0.3</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row9_col2\" class=\"data row9 col2\" >43.5±1.5</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row9_col3\" class=\"data row9 col3\" >62.2±0.6</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row9_col4\" class=\"data row9 col4\" >92.0±0.3</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row9_col5\" class=\"data row9 col5\" >93.7±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >mean</th>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row10_col0\" class=\"data row10 col0\" >88.0</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row10_col1\" class=\"data row10 col1\" >85.1</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row10_col2\" class=\"data row10 col2\" >40.9</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row10_col3\" class=\"data row10 col3\" >64.4</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row10_col4\" class=\"data row10 col4\" >90.8</td>\n",
              "                        <td id=\"T_c4b508fa_bf26_11eb_abda_0242ac1c0002row10_col5\" class=\"data row10 col5\" >92.5</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f1b82508490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gLW16yzqBM_"
      },
      "source": [
        "### $R_{error}$\n",
        "Compare Reconstruction Error of VAE and ED-VAE to results of competitive models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMYUeB-nYNsl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "94d311c1-0a65-44c2-900a-ce621736dff2"
      },
      "source": [
        "# AUC\n",
        "df = pd.DataFrame((\n",
        "    round(avg_auc_rec_final_results[column,'auc_mean']*100,1).astype(str) + '±' + round(avg_auc_rec_final_results[column,'auc_std']*100/np.sqrt(reps),1).astype(str) for column in avg_auc_rec_final_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_auc_rec_final_results.keys().get_level_values(0)[::2]).T\n",
        "df = df.append(pd.DataFrame((\n",
        "    #round(avg_auc_rec_class_results[column,'auc_mean']*100,1).astype(str) + '±' + round(avg_auc_rec_class_results[column,'pr_auc_std']*100/np.sqrt(reps * len(df.index)),1).astype(str) for column in avg_auc_rec_class_results.keys().get_level_values(0)[::2]\n",
        "    round(avg_auc_rec_class_results[column,'auc_mean']*100,1).astype(str) for column in avg_auc_rec_class_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_auc_rec_class_results.keys().get_level_values(0)[::2]).T)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pca</th>\n",
              "      <th>kpca</th>\n",
              "      <th>dsebm</th>\n",
              "      <th>ae</th>\n",
              "      <th>vae</th>\n",
              "      <th>ed-vae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>99.2±0.0</td>\n",
              "      <td>99.0±0.0</td>\n",
              "      <td>53.7±7.8</td>\n",
              "      <td>96.9±0.1</td>\n",
              "      <td>99.7±0.0</td>\n",
              "      <td>99.8±0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>99.9±0.0</td>\n",
              "      <td>99.8±0.0</td>\n",
              "      <td>98.2±0.3</td>\n",
              "      <td>98.7±0.0</td>\n",
              "      <td>99.9±0.0</td>\n",
              "      <td>99.9±0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>92.4±0.2</td>\n",
              "      <td>89.7±0.3</td>\n",
              "      <td>51.8±4.2</td>\n",
              "      <td>78.1±0.2</td>\n",
              "      <td>92.7±0.4</td>\n",
              "      <td>95.6±0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95.2±0.1</td>\n",
              "      <td>93.9±0.2</td>\n",
              "      <td>50.8±1.2</td>\n",
              "      <td>85.8±0.3</td>\n",
              "      <td>94.2±0.3</td>\n",
              "      <td>95.7±0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>94.3±0.1</td>\n",
              "      <td>94.6±0.2</td>\n",
              "      <td>69.3±2.1</td>\n",
              "      <td>88.2±0.3</td>\n",
              "      <td>94.7±0.3</td>\n",
              "      <td>96.4±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>97.4±0.1</td>\n",
              "      <td>95.0±0.1</td>\n",
              "      <td>55.7±0.8</td>\n",
              "      <td>72.5±0.4</td>\n",
              "      <td>95.9±0.2</td>\n",
              "      <td>96.9±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>98.4±0.1</td>\n",
              "      <td>97.3±0.1</td>\n",
              "      <td>58.5±4.2</td>\n",
              "      <td>86.8±0.2</td>\n",
              "      <td>99.1±0.1</td>\n",
              "      <td>99.4±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>97.1±0.1</td>\n",
              "      <td>96.4±0.2</td>\n",
              "      <td>75.7±0.9</td>\n",
              "      <td>91.2±0.3</td>\n",
              "      <td>96.0±0.2</td>\n",
              "      <td>97.0±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>85.5±0.5</td>\n",
              "      <td>85.4±0.5</td>\n",
              "      <td>46.4±3.2</td>\n",
              "      <td>78.0±0.8</td>\n",
              "      <td>89.5±0.4</td>\n",
              "      <td>91.1±0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>96.4±0.1</td>\n",
              "      <td>95.4±0.1</td>\n",
              "      <td>66.3±1.7</td>\n",
              "      <td>88.0±0.2</td>\n",
              "      <td>97.8±0.1</td>\n",
              "      <td>98.6±0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>95.6</td>\n",
              "      <td>94.7</td>\n",
              "      <td>62.6</td>\n",
              "      <td>86.4</td>\n",
              "      <td>96.0</td>\n",
              "      <td>97.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           pca      kpca     dsebm        ae       vae    ed-vae\n",
              "0     99.2±0.0  99.0±0.0  53.7±7.8  96.9±0.1  99.7±0.0  99.8±0.0\n",
              "1     99.9±0.0  99.8±0.0  98.2±0.3  98.7±0.0  99.9±0.0  99.9±0.0\n",
              "2     92.4±0.2  89.7±0.3  51.8±4.2  78.1±0.2  92.7±0.4  95.6±0.3\n",
              "3     95.2±0.1  93.9±0.2  50.8±1.2  85.8±0.3  94.2±0.3  95.7±0.3\n",
              "4     94.3±0.1  94.6±0.2  69.3±2.1  88.2±0.3  94.7±0.3  96.4±0.4\n",
              "5     97.4±0.1  95.0±0.1  55.7±0.8  72.5±0.4  95.9±0.2  96.9±0.2\n",
              "6     98.4±0.1  97.3±0.1  58.5±4.2  86.8±0.2  99.1±0.1  99.4±0.1\n",
              "7     97.1±0.1  96.4±0.2  75.7±0.9  91.2±0.3  96.0±0.2  97.0±0.2\n",
              "8     85.5±0.5  85.4±0.5  46.4±3.2  78.0±0.8  89.5±0.4  91.1±0.6\n",
              "9     96.4±0.1  95.4±0.1  66.3±1.7  88.0±0.2  97.8±0.1  98.6±0.0\n",
              "mean      95.6      94.7      62.6      86.4      96.0      97.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4Iq64We_WXg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "d19bfedc-cc28-4a3e-bc88-119de8fa5a55"
      },
      "source": [
        "df.style.apply(highlight_max, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_c52531fc_bf26_11eb_abda_0242ac1c0002row0_col5,#T_c52531fc_bf26_11eb_abda_0242ac1c0002row1_col0,#T_c52531fc_bf26_11eb_abda_0242ac1c0002row1_col4,#T_c52531fc_bf26_11eb_abda_0242ac1c0002row1_col5,#T_c52531fc_bf26_11eb_abda_0242ac1c0002row2_col5,#T_c52531fc_bf26_11eb_abda_0242ac1c0002row3_col5,#T_c52531fc_bf26_11eb_abda_0242ac1c0002row4_col5,#T_c52531fc_bf26_11eb_abda_0242ac1c0002row5_col0,#T_c52531fc_bf26_11eb_abda_0242ac1c0002row6_col5,#T_c52531fc_bf26_11eb_abda_0242ac1c0002row7_col0,#T_c52531fc_bf26_11eb_abda_0242ac1c0002row8_col5,#T_c52531fc_bf26_11eb_abda_0242ac1c0002row9_col5,#T_c52531fc_bf26_11eb_abda_0242ac1c0002row10_col5{\n",
              "            font-weight:  bold;\n",
              "        }</style><table id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >pca</th>        <th class=\"col_heading level0 col1\" >kpca</th>        <th class=\"col_heading level0 col2\" >dsebm</th>        <th class=\"col_heading level0 col3\" >ae</th>        <th class=\"col_heading level0 col4\" >vae</th>        <th class=\"col_heading level0 col5\" >ed-vae</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row0_col0\" class=\"data row0 col0\" >99.2±0.0</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row0_col1\" class=\"data row0 col1\" >99.0±0.0</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row0_col2\" class=\"data row0 col2\" >53.7±7.8</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row0_col3\" class=\"data row0 col3\" >96.9±0.1</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row0_col4\" class=\"data row0 col4\" >99.7±0.0</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row0_col5\" class=\"data row0 col5\" >99.8±0.0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row1_col0\" class=\"data row1 col0\" >99.9±0.0</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row1_col1\" class=\"data row1 col1\" >99.8±0.0</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row1_col2\" class=\"data row1 col2\" >98.2±0.3</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row1_col3\" class=\"data row1 col3\" >98.7±0.0</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row1_col4\" class=\"data row1 col4\" >99.9±0.0</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row1_col5\" class=\"data row1 col5\" >99.9±0.0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row2_col0\" class=\"data row2 col0\" >92.4±0.2</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row2_col1\" class=\"data row2 col1\" >89.7±0.3</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row2_col2\" class=\"data row2 col2\" >51.8±4.2</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row2_col3\" class=\"data row2 col3\" >78.1±0.2</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row2_col4\" class=\"data row2 col4\" >92.7±0.4</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row2_col5\" class=\"data row2 col5\" >95.6±0.3</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row3_col0\" class=\"data row3 col0\" >95.2±0.1</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row3_col1\" class=\"data row3 col1\" >93.9±0.2</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row3_col2\" class=\"data row3 col2\" >50.8±1.2</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row3_col3\" class=\"data row3 col3\" >85.8±0.3</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row3_col4\" class=\"data row3 col4\" >94.2±0.3</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row3_col5\" class=\"data row3 col5\" >95.7±0.3</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row4_col0\" class=\"data row4 col0\" >94.3±0.1</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row4_col1\" class=\"data row4 col1\" >94.6±0.2</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row4_col2\" class=\"data row4 col2\" >69.3±2.1</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row4_col3\" class=\"data row4 col3\" >88.2±0.3</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row4_col4\" class=\"data row4 col4\" >94.7±0.3</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row4_col5\" class=\"data row4 col5\" >96.4±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row5_col0\" class=\"data row5 col0\" >97.4±0.1</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row5_col1\" class=\"data row5 col1\" >95.0±0.1</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row5_col2\" class=\"data row5 col2\" >55.7±0.8</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row5_col3\" class=\"data row5 col3\" >72.5±0.4</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row5_col4\" class=\"data row5 col4\" >95.9±0.2</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row5_col5\" class=\"data row5 col5\" >96.9±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row6_col0\" class=\"data row6 col0\" >98.4±0.1</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row6_col1\" class=\"data row6 col1\" >97.3±0.1</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row6_col2\" class=\"data row6 col2\" >58.5±4.2</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row6_col3\" class=\"data row6 col3\" >86.8±0.2</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row6_col4\" class=\"data row6 col4\" >99.1±0.1</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row6_col5\" class=\"data row6 col5\" >99.4±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row7_col0\" class=\"data row7 col0\" >97.1±0.1</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row7_col1\" class=\"data row7 col1\" >96.4±0.2</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row7_col2\" class=\"data row7 col2\" >75.7±0.9</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row7_col3\" class=\"data row7 col3\" >91.2±0.3</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row7_col4\" class=\"data row7 col4\" >96.0±0.2</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row7_col5\" class=\"data row7 col5\" >97.0±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row8_col0\" class=\"data row8 col0\" >85.5±0.5</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row8_col1\" class=\"data row8 col1\" >85.4±0.5</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row8_col2\" class=\"data row8 col2\" >46.4±3.2</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row8_col3\" class=\"data row8 col3\" >78.0±0.8</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row8_col4\" class=\"data row8 col4\" >89.5±0.4</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row8_col5\" class=\"data row8 col5\" >91.1±0.6</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row9_col0\" class=\"data row9 col0\" >96.4±0.1</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row9_col1\" class=\"data row9 col1\" >95.4±0.1</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row9_col2\" class=\"data row9 col2\" >66.3±1.7</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row9_col3\" class=\"data row9 col3\" >88.0±0.2</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row9_col4\" class=\"data row9 col4\" >97.8±0.1</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row9_col5\" class=\"data row9 col5\" >98.6±0.0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >mean</th>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row10_col0\" class=\"data row10 col0\" >95.6</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row10_col1\" class=\"data row10 col1\" >94.7</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row10_col2\" class=\"data row10 col2\" >62.6</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row10_col3\" class=\"data row10 col3\" >86.4</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row10_col4\" class=\"data row10 col4\" >96.0</td>\n",
              "                        <td id=\"T_c52531fc_bf26_11eb_abda_0242ac1c0002row10_col5\" class=\"data row10 col5\" >97.0</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f1c10033410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PqgHo_YYNsk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "67f95961-a4d0-43a3-a684-a013e2650f1d"
      },
      "source": [
        "# PR-AUC\n",
        "df = pd.DataFrame((\n",
        "    round(avg_pr_rec_final_results[column,'pr_auc_mean']*100,1).astype(str) + '±' + round(avg_pr_rec_final_results[column,'pr_auc_std']*100/np.sqrt(reps),1).astype(str) for column in avg_pr_rec_final_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_pr_rec_final_results.keys().get_level_values(0)[::2]).T\n",
        "df = df.append(pd.DataFrame((\n",
        "    #round(avg_pr_rec_class_results[column,'pr_auc_mean']*100,1).astype(str) + '±' + round(avg_pr_rec_class_results[column,'pr_auc_std']*100/np.sqrt(reps * len(df.index)),1).astype(str) for column in avg_pr_rec_class_results.keys().get_level_values(0)[::2]\n",
        "    round(avg_pr_rec_class_results[column,'pr_auc_mean']*100,1).astype(str) for column in avg_pr_rec_class_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_pr_rec_class_results.keys().get_level_values(0)[::2]).T)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pca</th>\n",
              "      <th>kpca</th>\n",
              "      <th>dsebm</th>\n",
              "      <th>ae</th>\n",
              "      <th>vae</th>\n",
              "      <th>ed-vae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>96.3±0.1</td>\n",
              "      <td>95.6±0.2</td>\n",
              "      <td>31.9±9.1</td>\n",
              "      <td>88.4±0.4</td>\n",
              "      <td>98.8±0.1</td>\n",
              "      <td>99.1±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>99.5±0.0</td>\n",
              "      <td>99.2±0.0</td>\n",
              "      <td>93.6±1.0</td>\n",
              "      <td>95.5±0.2</td>\n",
              "      <td>99.7±0.0</td>\n",
              "      <td>99.6±0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>80.9±0.4</td>\n",
              "      <td>74.4±0.5</td>\n",
              "      <td>27.8±3.4</td>\n",
              "      <td>49.9±0.5</td>\n",
              "      <td>84.2±0.7</td>\n",
              "      <td>88.6±0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80.8±0.4</td>\n",
              "      <td>80.0±0.5</td>\n",
              "      <td>25.4±0.9</td>\n",
              "      <td>61.4±0.8</td>\n",
              "      <td>85.8±0.6</td>\n",
              "      <td>88.5±0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>87.6±0.3</td>\n",
              "      <td>86.4±0.3</td>\n",
              "      <td>44.6±2.2</td>\n",
              "      <td>66.7±0.6</td>\n",
              "      <td>89.8±0.5</td>\n",
              "      <td>91.7±0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>90.8±0.3</td>\n",
              "      <td>83.7±0.4</td>\n",
              "      <td>30.1±0.7</td>\n",
              "      <td>44.4±0.5</td>\n",
              "      <td>89.4±0.3</td>\n",
              "      <td>91.0±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>94.8±0.1</td>\n",
              "      <td>91.3±0.2</td>\n",
              "      <td>32.1±3.0</td>\n",
              "      <td>54.7±0.4</td>\n",
              "      <td>96.7±0.3</td>\n",
              "      <td>97.7±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>91.3±0.3</td>\n",
              "      <td>89.5±0.4</td>\n",
              "      <td>58.7±0.9</td>\n",
              "      <td>75.2±0.5</td>\n",
              "      <td>90.9±0.3</td>\n",
              "      <td>92.1±0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>69.9±0.6</td>\n",
              "      <td>68.2±0.6</td>\n",
              "      <td>21.4±2.3</td>\n",
              "      <td>46.1±2.1</td>\n",
              "      <td>81.8±0.6</td>\n",
              "      <td>85.6±0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>87.9±0.2</td>\n",
              "      <td>83.2±0.3</td>\n",
              "      <td>43.5±1.5</td>\n",
              "      <td>62.2±0.6</td>\n",
              "      <td>92.9±0.2</td>\n",
              "      <td>94.6±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>88.0</td>\n",
              "      <td>85.1</td>\n",
              "      <td>40.9</td>\n",
              "      <td>64.4</td>\n",
              "      <td>91.0</td>\n",
              "      <td>92.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           pca      kpca     dsebm        ae       vae    ed-vae\n",
              "0     96.3±0.1  95.6±0.2  31.9±9.1  88.4±0.4  98.8±0.1  99.1±0.1\n",
              "1     99.5±0.0  99.2±0.0  93.6±1.0  95.5±0.2  99.7±0.0  99.6±0.0\n",
              "2     80.9±0.4  74.4±0.5  27.8±3.4  49.9±0.5  84.2±0.7  88.6±0.7\n",
              "3     80.8±0.4  80.0±0.5  25.4±0.9  61.4±0.8  85.8±0.6  88.5±0.5\n",
              "4     87.6±0.3  86.4±0.3  44.6±2.2  66.7±0.6  89.8±0.5  91.7±0.6\n",
              "5     90.8±0.3  83.7±0.4  30.1±0.7  44.4±0.5  89.4±0.3  91.0±0.4\n",
              "6     94.8±0.1  91.3±0.2  32.1±3.0  54.7±0.4  96.7±0.3  97.7±0.2\n",
              "7     91.3±0.3  89.5±0.4  58.7±0.9  75.2±0.5  90.9±0.3  92.1±0.3\n",
              "8     69.9±0.6  68.2±0.6  21.4±2.3  46.1±2.1  81.8±0.6  85.6±0.5\n",
              "9     87.9±0.2  83.2±0.3  43.5±1.5  62.2±0.6  92.9±0.2  94.6±0.1\n",
              "mean      88.0      85.1      40.9      64.4      91.0      92.9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb0xXtt0_VxV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "245bc46b-ecb3-4866-db37-70aac200e110"
      },
      "source": [
        "df.style.apply(highlight_max, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_c519e248_bf26_11eb_abda_0242ac1c0002row0_col5,#T_c519e248_bf26_11eb_abda_0242ac1c0002row1_col4,#T_c519e248_bf26_11eb_abda_0242ac1c0002row2_col5,#T_c519e248_bf26_11eb_abda_0242ac1c0002row3_col5,#T_c519e248_bf26_11eb_abda_0242ac1c0002row4_col5,#T_c519e248_bf26_11eb_abda_0242ac1c0002row5_col5,#T_c519e248_bf26_11eb_abda_0242ac1c0002row6_col5,#T_c519e248_bf26_11eb_abda_0242ac1c0002row7_col5,#T_c519e248_bf26_11eb_abda_0242ac1c0002row8_col5,#T_c519e248_bf26_11eb_abda_0242ac1c0002row9_col5,#T_c519e248_bf26_11eb_abda_0242ac1c0002row10_col5{\n",
              "            font-weight:  bold;\n",
              "        }</style><table id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >pca</th>        <th class=\"col_heading level0 col1\" >kpca</th>        <th class=\"col_heading level0 col2\" >dsebm</th>        <th class=\"col_heading level0 col3\" >ae</th>        <th class=\"col_heading level0 col4\" >vae</th>        <th class=\"col_heading level0 col5\" >ed-vae</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row0_col0\" class=\"data row0 col0\" >96.3±0.1</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row0_col1\" class=\"data row0 col1\" >95.6±0.2</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row0_col2\" class=\"data row0 col2\" >31.9±9.1</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row0_col3\" class=\"data row0 col3\" >88.4±0.4</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row0_col4\" class=\"data row0 col4\" >98.8±0.1</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row0_col5\" class=\"data row0 col5\" >99.1±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row1_col0\" class=\"data row1 col0\" >99.5±0.0</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row1_col1\" class=\"data row1 col1\" >99.2±0.0</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row1_col2\" class=\"data row1 col2\" >93.6±1.0</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row1_col3\" class=\"data row1 col3\" >95.5±0.2</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row1_col4\" class=\"data row1 col4\" >99.7±0.0</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row1_col5\" class=\"data row1 col5\" >99.6±0.0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row2_col0\" class=\"data row2 col0\" >80.9±0.4</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row2_col1\" class=\"data row2 col1\" >74.4±0.5</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row2_col2\" class=\"data row2 col2\" >27.8±3.4</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row2_col3\" class=\"data row2 col3\" >49.9±0.5</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row2_col4\" class=\"data row2 col4\" >84.2±0.7</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row2_col5\" class=\"data row2 col5\" >88.6±0.7</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row3_col0\" class=\"data row3 col0\" >80.8±0.4</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row3_col1\" class=\"data row3 col1\" >80.0±0.5</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row3_col2\" class=\"data row3 col2\" >25.4±0.9</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row3_col3\" class=\"data row3 col3\" >61.4±0.8</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row3_col4\" class=\"data row3 col4\" >85.8±0.6</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row3_col5\" class=\"data row3 col5\" >88.5±0.5</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row4_col0\" class=\"data row4 col0\" >87.6±0.3</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row4_col1\" class=\"data row4 col1\" >86.4±0.3</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row4_col2\" class=\"data row4 col2\" >44.6±2.2</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row4_col3\" class=\"data row4 col3\" >66.7±0.6</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row4_col4\" class=\"data row4 col4\" >89.8±0.5</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row4_col5\" class=\"data row4 col5\" >91.7±0.6</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row5_col0\" class=\"data row5 col0\" >90.8±0.3</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row5_col1\" class=\"data row5 col1\" >83.7±0.4</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row5_col2\" class=\"data row5 col2\" >30.1±0.7</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row5_col3\" class=\"data row5 col3\" >44.4±0.5</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row5_col4\" class=\"data row5 col4\" >89.4±0.3</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row5_col5\" class=\"data row5 col5\" >91.0±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row6_col0\" class=\"data row6 col0\" >94.8±0.1</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row6_col1\" class=\"data row6 col1\" >91.3±0.2</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row6_col2\" class=\"data row6 col2\" >32.1±3.0</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row6_col3\" class=\"data row6 col3\" >54.7±0.4</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row6_col4\" class=\"data row6 col4\" >96.7±0.3</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row6_col5\" class=\"data row6 col5\" >97.7±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row7_col0\" class=\"data row7 col0\" >91.3±0.3</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row7_col1\" class=\"data row7 col1\" >89.5±0.4</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row7_col2\" class=\"data row7 col2\" >58.7±0.9</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row7_col3\" class=\"data row7 col3\" >75.2±0.5</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row7_col4\" class=\"data row7 col4\" >90.9±0.3</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row7_col5\" class=\"data row7 col5\" >92.1±0.3</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row8_col0\" class=\"data row8 col0\" >69.9±0.6</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row8_col1\" class=\"data row8 col1\" >68.2±0.6</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row8_col2\" class=\"data row8 col2\" >21.4±2.3</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row8_col3\" class=\"data row8 col3\" >46.1±2.1</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row8_col4\" class=\"data row8 col4\" >81.8±0.6</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row8_col5\" class=\"data row8 col5\" >85.6±0.5</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row9_col0\" class=\"data row9 col0\" >87.9±0.2</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row9_col1\" class=\"data row9 col1\" >83.2±0.3</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row9_col2\" class=\"data row9 col2\" >43.5±1.5</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row9_col3\" class=\"data row9 col3\" >62.2±0.6</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row9_col4\" class=\"data row9 col4\" >92.9±0.2</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row9_col5\" class=\"data row9 col5\" >94.6±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >mean</th>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row10_col0\" class=\"data row10 col0\" >88.0</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row10_col1\" class=\"data row10 col1\" >85.1</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row10_col2\" class=\"data row10 col2\" >40.9</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row10_col3\" class=\"data row10 col3\" >64.4</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row10_col4\" class=\"data row10 col4\" >91.0</td>\n",
              "                        <td id=\"T_c519e248_bf26_11eb_abda_0242ac1c0002row10_col5\" class=\"data row10 col5\" >92.9</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f1c10045a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fx4aOFCn6Oi"
      },
      "source": [
        "# Results - ED-VAE vs. VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJFMhZDan6Ok"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQzHFiI2n6Ok"
      },
      "source": [
        "index_labels = normal_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUMzjU1xXE7W"
      },
      "source": [
        "avg_results = np.mean(results, axis=0)\n",
        "std_results = np.std(results, axis=0)\n",
        "avg_class_results = np.mean(results, axis=(0, 1))\n",
        "std_class_results = np.std(results, axis=(0, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj39c6vCU5S7"
      },
      "source": [
        "avg_results = avg_results[:,4:6]\n",
        "std_results = std_results[:,4:6]\n",
        "avg_class_results = avg_class_results[4:6]\n",
        "std_class_results = std_class_results[4:6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lOSYEitn6Ok"
      },
      "source": [
        "pr_header = [np.array(['vae', 'vae',             \n",
        "                    'ed-vae', 'ed-vae',\n",
        "                    ]), \n",
        "np.array(['pr_auc_mean','pr_auc_std',\n",
        "          'pr_auc_mean','pr_auc_std',\n",
        "          ])] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwu4Lynin6Ol"
      },
      "source": [
        "auc_header = [np.array([\n",
        "                    'vae', 'vae',\n",
        "                    'ed-vae', 'ed-vae',\n",
        "                    ]), \n",
        "np.array(['auc_mean','auc_std',\n",
        "          'auc_mean','auc_std',\n",
        "          ])] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7F1TOjVn6Om"
      },
      "source": [
        "### $ELBO$\n",
        "Compare ELBO of VAE and ED-VAE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHgn949xn6Om",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "d75749cc-3aba-40da-b975-218ce82d5f0a"
      },
      "source": [
        "# AUC\n",
        "avg_auc_elbo_class_results = pd.DataFrame((avg_class_results[0,3], std_class_results[0,3], \n",
        "                                  avg_class_results[1,3], std_class_results[1,3],\n",
        "                                  ), \n",
        "                                  index = auc_header).T\n",
        "avg_auc_elbo_class_results = avg_auc_elbo_class_results.rename(index={0: \"mean\"})\n",
        "avg_auc_elbo_final_results = pd.DataFrame((avg_results[:,0,3], std_results[:,0,3],\n",
        "                                  avg_results[:,1,3], std_results[:,1,3], \n",
        "                                  ), \n",
        "                                  index = auc_header, columns = index_labels).T\n",
        "avg_auc_elbo_final_results.append(avg_auc_elbo_class_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">vae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ed-vae</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.997490</td>\n",
              "      <td>0.000596</td>\n",
              "      <td>0.998040</td>\n",
              "      <td>0.000399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.999143</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.998971</td>\n",
              "      <td>0.000175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.930162</td>\n",
              "      <td>0.013765</td>\n",
              "      <td>0.953000</td>\n",
              "      <td>0.011181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.945802</td>\n",
              "      <td>0.011802</td>\n",
              "      <td>0.957721</td>\n",
              "      <td>0.009410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.949664</td>\n",
              "      <td>0.007648</td>\n",
              "      <td>0.963341</td>\n",
              "      <td>0.009216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.958067</td>\n",
              "      <td>0.004985</td>\n",
              "      <td>0.966591</td>\n",
              "      <td>0.005621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.988640</td>\n",
              "      <td>0.003114</td>\n",
              "      <td>0.993058</td>\n",
              "      <td>0.001855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.965191</td>\n",
              "      <td>0.006841</td>\n",
              "      <td>0.972690</td>\n",
              "      <td>0.004912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.894889</td>\n",
              "      <td>0.013219</td>\n",
              "      <td>0.910885</td>\n",
              "      <td>0.015663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.975738</td>\n",
              "      <td>0.003147</td>\n",
              "      <td>0.982728</td>\n",
              "      <td>0.002057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.960479</td>\n",
              "      <td>0.031821</td>\n",
              "      <td>0.969702</td>\n",
              "      <td>0.026312</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           vae              ed-vae          \n",
              "      auc_mean   auc_std  auc_mean   auc_std\n",
              "0     0.997490  0.000596  0.998040  0.000399\n",
              "1     0.999143  0.000108  0.998971  0.000175\n",
              "2     0.930162  0.013765  0.953000  0.011181\n",
              "3     0.945802  0.011802  0.957721  0.009410\n",
              "4     0.949664  0.007648  0.963341  0.009216\n",
              "5     0.958067  0.004985  0.966591  0.005621\n",
              "6     0.988640  0.003114  0.993058  0.001855\n",
              "7     0.965191  0.006841  0.972690  0.004912\n",
              "8     0.894889  0.013219  0.910885  0.015663\n",
              "9     0.975738  0.003147  0.982728  0.002057\n",
              "mean  0.960479  0.031821  0.969702  0.026312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeysyUvDn6Om",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "7d73a93f-02ca-49f8-a68b-47d31b642bb4"
      },
      "source": [
        "# PR-AUC\n",
        "avg_pr_elbo_class_results = pd.DataFrame((avg_class_results[0,2], std_class_results[0,2], \n",
        "                                  avg_class_results[1,2], std_class_results[1,2],\n",
        "                                  ), \n",
        "                                  index = pr_header).T\n",
        "avg_pr_elbo_class_results = avg_pr_elbo_class_results.rename(index={0: \"mean\"})\n",
        "avg_pr_elbo_final_results = pd.DataFrame((avg_results[:,0,2], std_results[:,0,2],\n",
        "                                  avg_results[:,1,2], std_results[:,1,2],\n",
        "                                  ), \n",
        "                                  index = pr_header, columns = index_labels).T\n",
        "avg_pr_elbo_final_results.append(avg_pr_elbo_class_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">vae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ed-vae</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.988285</td>\n",
              "      <td>0.003438</td>\n",
              "      <td>0.990907</td>\n",
              "      <td>0.001923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.996292</td>\n",
              "      <td>0.000464</td>\n",
              "      <td>0.995649</td>\n",
              "      <td>0.000759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.846786</td>\n",
              "      <td>0.021684</td>\n",
              "      <td>0.882667</td>\n",
              "      <td>0.021451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.860224</td>\n",
              "      <td>0.023341</td>\n",
              "      <td>0.883761</td>\n",
              "      <td>0.020190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.894577</td>\n",
              "      <td>0.013628</td>\n",
              "      <td>0.912480</td>\n",
              "      <td>0.015687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.884872</td>\n",
              "      <td>0.011750</td>\n",
              "      <td>0.900353</td>\n",
              "      <td>0.011562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.962311</td>\n",
              "      <td>0.008520</td>\n",
              "      <td>0.973199</td>\n",
              "      <td>0.005970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.913266</td>\n",
              "      <td>0.011386</td>\n",
              "      <td>0.924547</td>\n",
              "      <td>0.009787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.809002</td>\n",
              "      <td>0.019917</td>\n",
              "      <td>0.845131</td>\n",
              "      <td>0.016582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.920291</td>\n",
              "      <td>0.008016</td>\n",
              "      <td>0.936706</td>\n",
              "      <td>0.005146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.907590</td>\n",
              "      <td>0.059939</td>\n",
              "      <td>0.924540</td>\n",
              "      <td>0.049106</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             vae                 ed-vae           \n",
              "     pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std\n",
              "0       0.988285   0.003438    0.990907   0.001923\n",
              "1       0.996292   0.000464    0.995649   0.000759\n",
              "2       0.846786   0.021684    0.882667   0.021451\n",
              "3       0.860224   0.023341    0.883761   0.020190\n",
              "4       0.894577   0.013628    0.912480   0.015687\n",
              "5       0.884872   0.011750    0.900353   0.011562\n",
              "6       0.962311   0.008520    0.973199   0.005970\n",
              "7       0.913266   0.011386    0.924547   0.009787\n",
              "8       0.809002   0.019917    0.845131   0.016582\n",
              "9       0.920291   0.008016    0.936706   0.005146\n",
              "mean    0.907590   0.059939    0.924540   0.049106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToWIOp_gn6Ol"
      },
      "source": [
        "### $R_{error}$\n",
        "Compare Reconstruction Error of VAE and ED-VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk77PCc8n6Ol",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "8546979d-f6dc-4434-c55d-e7bc97a532b1"
      },
      "source": [
        "# AUC\n",
        "avg_auc_rec_class_results = pd.DataFrame((avg_class_results[0,1], std_class_results[0,1], \n",
        "                                  avg_class_results[1,1], std_class_results[1,1],\n",
        "                                  ), \n",
        "                                  index = auc_header).T\n",
        "avg_auc_rec_class_results = avg_auc_rec_class_results.rename(index={0: \"mean\"})\n",
        "avg_auc_rec_final_results = pd.DataFrame((avg_results[:,0,1], std_results[:,0,1], \n",
        "                                  avg_results[:,1,1], std_results[:,1,1],\n",
        "                                  ), \n",
        "                                  index = auc_header, columns = index_labels).T\n",
        "avg_auc_rec_final_results.append(avg_auc_rec_class_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">vae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ed-vae</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "      <th>auc_mean</th>\n",
              "      <th>auc_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.997371</td>\n",
              "      <td>0.000639</td>\n",
              "      <td>0.997917</td>\n",
              "      <td>0.000565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.999397</td>\n",
              "      <td>0.000117</td>\n",
              "      <td>0.999129</td>\n",
              "      <td>0.000161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.927271</td>\n",
              "      <td>0.013782</td>\n",
              "      <td>0.956265</td>\n",
              "      <td>0.009806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.941618</td>\n",
              "      <td>0.010844</td>\n",
              "      <td>0.956757</td>\n",
              "      <td>0.008551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.946698</td>\n",
              "      <td>0.010322</td>\n",
              "      <td>0.963841</td>\n",
              "      <td>0.011562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.958839</td>\n",
              "      <td>0.004844</td>\n",
              "      <td>0.968716</td>\n",
              "      <td>0.005531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.990615</td>\n",
              "      <td>0.002973</td>\n",
              "      <td>0.994452</td>\n",
              "      <td>0.001617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.960097</td>\n",
              "      <td>0.007662</td>\n",
              "      <td>0.969931</td>\n",
              "      <td>0.005128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.895123</td>\n",
              "      <td>0.013470</td>\n",
              "      <td>0.910591</td>\n",
              "      <td>0.017666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.978472</td>\n",
              "      <td>0.003114</td>\n",
              "      <td>0.985888</td>\n",
              "      <td>0.001568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.959550</td>\n",
              "      <td>0.032739</td>\n",
              "      <td>0.970349</td>\n",
              "      <td>0.026622</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           vae              ed-vae          \n",
              "      auc_mean   auc_std  auc_mean   auc_std\n",
              "0     0.997371  0.000639  0.997917  0.000565\n",
              "1     0.999397  0.000117  0.999129  0.000161\n",
              "2     0.927271  0.013782  0.956265  0.009806\n",
              "3     0.941618  0.010844  0.956757  0.008551\n",
              "4     0.946698  0.010322  0.963841  0.011562\n",
              "5     0.958839  0.004844  0.968716  0.005531\n",
              "6     0.990615  0.002973  0.994452  0.001617\n",
              "7     0.960097  0.007662  0.969931  0.005128\n",
              "8     0.895123  0.013470  0.910591  0.017666\n",
              "9     0.978472  0.003114  0.985888  0.001568\n",
              "mean  0.959550  0.032739  0.970349  0.026622"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXvMmzqAn6Ol",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "eba17b0d-3cd4-432e-d894-b99db8bfd43e"
      },
      "source": [
        "# PR-AUC\n",
        "avg_pr_rec_class_results = pd.DataFrame((avg_class_results[0,0], std_class_results[0,0], \n",
        "                                  avg_class_results[1,0], std_class_results[1,0],\n",
        "                                  ), \n",
        "                                  index = pr_header).T\n",
        "avg_pr_rec_class_results = avg_pr_rec_class_results.rename(index={0: \"mean\"})\n",
        "avg_pr_rec_final_results = pd.DataFrame((avg_results[:,0,0], std_results[:,0,0], \n",
        "                                  avg_results[:,1,0], std_results[:,1,0],\n",
        "                                  ), \n",
        "                                  index = pr_header, columns = index_labels).T\n",
        "avg_pr_rec_final_results.append(avg_pr_rec_class_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">vae</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ed-vae</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "      <th>pr_auc_mean</th>\n",
              "      <th>pr_auc_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.988409</td>\n",
              "      <td>0.003320</td>\n",
              "      <td>0.990896</td>\n",
              "      <td>0.002023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.997493</td>\n",
              "      <td>0.000477</td>\n",
              "      <td>0.996406</td>\n",
              "      <td>0.000687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.842210</td>\n",
              "      <td>0.022451</td>\n",
              "      <td>0.886398</td>\n",
              "      <td>0.020869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.857914</td>\n",
              "      <td>0.020537</td>\n",
              "      <td>0.884915</td>\n",
              "      <td>0.016641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.897972</td>\n",
              "      <td>0.015864</td>\n",
              "      <td>0.917361</td>\n",
              "      <td>0.018964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.894223</td>\n",
              "      <td>0.010736</td>\n",
              "      <td>0.910305</td>\n",
              "      <td>0.011131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.967355</td>\n",
              "      <td>0.007963</td>\n",
              "      <td>0.977310</td>\n",
              "      <td>0.005809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.909373</td>\n",
              "      <td>0.011026</td>\n",
              "      <td>0.921433</td>\n",
              "      <td>0.009237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.818364</td>\n",
              "      <td>0.018461</td>\n",
              "      <td>0.855947</td>\n",
              "      <td>0.016364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.928812</td>\n",
              "      <td>0.007496</td>\n",
              "      <td>0.945767</td>\n",
              "      <td>0.004407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.910212</td>\n",
              "      <td>0.059524</td>\n",
              "      <td>0.928674</td>\n",
              "      <td>0.047152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             vae                 ed-vae           \n",
              "     pr_auc_mean pr_auc_std pr_auc_mean pr_auc_std\n",
              "0       0.988409   0.003320    0.990896   0.002023\n",
              "1       0.997493   0.000477    0.996406   0.000687\n",
              "2       0.842210   0.022451    0.886398   0.020869\n",
              "3       0.857914   0.020537    0.884915   0.016641\n",
              "4       0.897972   0.015864    0.917361   0.018964\n",
              "5       0.894223   0.010736    0.910305   0.011131\n",
              "6       0.967355   0.007963    0.977310   0.005809\n",
              "7       0.909373   0.011026    0.921433   0.009237\n",
              "8       0.818364   0.018461    0.855947   0.016364\n",
              "9       0.928812   0.007496    0.945767   0.004407\n",
              "mean    0.910212   0.059524    0.928674   0.047152"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7OjI1hRnpgq"
      },
      "source": [
        "## Formated for Publication\n",
        "Mean and SEM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwvN9KbJnpgs"
      },
      "source": [
        "###ELBO\n",
        "Compare ELBO of VAE and ED-VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT6XAfk0npgw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "f02d0e28-a480-4fcd-9343-cec102969346"
      },
      "source": [
        "# AUC\n",
        "df = pd.DataFrame((\n",
        "    round(avg_auc_elbo_final_results[column,'auc_mean']*100,1).astype(str) + '±' + round(avg_auc_elbo_final_results[column,'auc_std']*100/np.sqrt(reps),1).astype(str) for column in avg_auc_elbo_final_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_auc_elbo_final_results.keys().get_level_values(0)[::2]).T\n",
        "df = df.append(pd.DataFrame((\n",
        "    #round(avg_auc_elbo_class_results[column,'auc_mean']*100,1).astype(str) + '±' + round(avg_auc_elbo_class_results[column,'pr_auc_std']*100/np.sqrt(reps * len(df.index)),1).astype(str) for column in avg_auc_elbo_class_results.keys().get_level_values(0)[::2]\n",
        "    round(avg_auc_elbo_class_results[column,'auc_mean']*100,1).astype(str) for column in avg_auc_elbo_class_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_auc_elbo_class_results.keys().get_level_values(0)[::2]).T)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vae</th>\n",
              "      <th>ed-vae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>99.7±0.0</td>\n",
              "      <td>99.8±0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>99.9±0.0</td>\n",
              "      <td>99.9±0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>93.0±0.4</td>\n",
              "      <td>95.3±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>94.6±0.4</td>\n",
              "      <td>95.8±0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>95.0±0.2</td>\n",
              "      <td>96.3±0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>95.8±0.2</td>\n",
              "      <td>96.7±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>98.9±0.1</td>\n",
              "      <td>99.3±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>96.5±0.2</td>\n",
              "      <td>97.3±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>89.5±0.4</td>\n",
              "      <td>91.1±0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>97.6±0.1</td>\n",
              "      <td>98.3±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>96.0</td>\n",
              "      <td>97.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           vae    ed-vae\n",
              "0     99.7±0.0  99.8±0.0\n",
              "1     99.9±0.0  99.9±0.0\n",
              "2     93.0±0.4  95.3±0.4\n",
              "3     94.6±0.4  95.8±0.3\n",
              "4     95.0±0.2  96.3±0.3\n",
              "5     95.8±0.2  96.7±0.2\n",
              "6     98.9±0.1  99.3±0.1\n",
              "7     96.5±0.2  97.3±0.2\n",
              "8     89.5±0.4  91.1±0.5\n",
              "9     97.6±0.1  98.3±0.1\n",
              "mean      96.0      97.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs-rtL8Pnpgx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "27df9b04-6168-4e89-9e9f-fca8e6aff381"
      },
      "source": [
        "df.style.apply(highlight_max, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_c71222c2_bf26_11eb_abda_0242ac1c0002row0_col1,#T_c71222c2_bf26_11eb_abda_0242ac1c0002row1_col0,#T_c71222c2_bf26_11eb_abda_0242ac1c0002row1_col1,#T_c71222c2_bf26_11eb_abda_0242ac1c0002row2_col1,#T_c71222c2_bf26_11eb_abda_0242ac1c0002row3_col1,#T_c71222c2_bf26_11eb_abda_0242ac1c0002row4_col1,#T_c71222c2_bf26_11eb_abda_0242ac1c0002row5_col1,#T_c71222c2_bf26_11eb_abda_0242ac1c0002row6_col1,#T_c71222c2_bf26_11eb_abda_0242ac1c0002row7_col1,#T_c71222c2_bf26_11eb_abda_0242ac1c0002row8_col1,#T_c71222c2_bf26_11eb_abda_0242ac1c0002row9_col1,#T_c71222c2_bf26_11eb_abda_0242ac1c0002row10_col1{\n",
              "            font-weight:  bold;\n",
              "        }</style><table id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >vae</th>        <th class=\"col_heading level0 col1\" >ed-vae</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row0_col0\" class=\"data row0 col0\" >99.7±0.0</td>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row0_col1\" class=\"data row0 col1\" >99.8±0.0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row1_col0\" class=\"data row1 col0\" >99.9±0.0</td>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row1_col1\" class=\"data row1 col1\" >99.9±0.0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row2_col0\" class=\"data row2 col0\" >93.0±0.4</td>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row2_col1\" class=\"data row2 col1\" >95.3±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row3_col0\" class=\"data row3 col0\" >94.6±0.4</td>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row3_col1\" class=\"data row3 col1\" >95.8±0.3</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row4_col0\" class=\"data row4 col0\" >95.0±0.2</td>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row4_col1\" class=\"data row4 col1\" >96.3±0.3</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row5_col0\" class=\"data row5 col0\" >95.8±0.2</td>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row5_col1\" class=\"data row5 col1\" >96.7±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row6_col0\" class=\"data row6 col0\" >98.9±0.1</td>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row6_col1\" class=\"data row6 col1\" >99.3±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row7_col0\" class=\"data row7 col0\" >96.5±0.2</td>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row7_col1\" class=\"data row7 col1\" >97.3±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row8_col0\" class=\"data row8 col0\" >89.5±0.4</td>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row8_col1\" class=\"data row8 col1\" >91.1±0.5</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row9_col0\" class=\"data row9 col0\" >97.6±0.1</td>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row9_col1\" class=\"data row9 col1\" >98.3±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >mean</th>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row10_col0\" class=\"data row10 col0\" >96.0</td>\n",
              "                        <td id=\"T_c71222c2_bf26_11eb_abda_0242ac1c0002row10_col1\" class=\"data row10 col1\" >97.0</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f1b82388dd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs_ceZCCnpgw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "d01a5fb3-b2c4-412b-8504-acf76efe9a85"
      },
      "source": [
        "# PR-AUC\n",
        "df = pd.DataFrame((\n",
        "    round(avg_pr_elbo_final_results[column,'pr_auc_mean']*100,1).astype(str) + '±' + round(avg_pr_elbo_final_results[column,'pr_auc_std']*100/np.sqrt(reps),1).astype(str) for column in avg_pr_elbo_final_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_pr_elbo_final_results.keys().get_level_values(0)[::2]).T  \n",
        "df = df.append(pd.DataFrame((\n",
        "    #round(avg_pr_elbo_class_results[column,'pr_auc_mean']*100,1).astype(str) + '±' + round(avg_pr_elbo_class_results[column,'pr_auc_std']*100/np.sqrt(reps * len(df.index)),1).astype(str) for column in avg_pr_elbo_class_results.keys().get_level_values(0)[::2]\n",
        "    round(avg_pr_elbo_class_results[column,'pr_auc_mean']*100,1).astype(str) for column in avg_pr_elbo_class_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_pr_elbo_class_results.keys().get_level_values(0)[::2]).T)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vae</th>\n",
              "      <th>ed-vae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>98.8±0.1</td>\n",
              "      <td>99.1±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>99.6±0.0</td>\n",
              "      <td>99.6±0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84.7±0.7</td>\n",
              "      <td>88.3±0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>86.0±0.7</td>\n",
              "      <td>88.4±0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>89.5±0.4</td>\n",
              "      <td>91.2±0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>88.5±0.4</td>\n",
              "      <td>90.0±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>96.2±0.3</td>\n",
              "      <td>97.3±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>91.3±0.4</td>\n",
              "      <td>92.5±0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>80.9±0.6</td>\n",
              "      <td>84.5±0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>92.0±0.3</td>\n",
              "      <td>93.7±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>90.8</td>\n",
              "      <td>92.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           vae    ed-vae\n",
              "0     98.8±0.1  99.1±0.1\n",
              "1     99.6±0.0  99.6±0.0\n",
              "2     84.7±0.7  88.3±0.7\n",
              "3     86.0±0.7  88.4±0.6\n",
              "4     89.5±0.4  91.2±0.5\n",
              "5     88.5±0.4  90.0±0.4\n",
              "6     96.2±0.3  97.3±0.2\n",
              "7     91.3±0.4  92.5±0.3\n",
              "8     80.9±0.6  84.5±0.5\n",
              "9     92.0±0.3  93.7±0.2\n",
              "mean      90.8      92.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rJfWOCqnpgw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "6d590b77-d550-4003-a4f5-53bc09d19e6c"
      },
      "source": [
        "df.style.apply(highlight_max, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_c7094ee0_bf26_11eb_abda_0242ac1c0002row0_col1,#T_c7094ee0_bf26_11eb_abda_0242ac1c0002row1_col0,#T_c7094ee0_bf26_11eb_abda_0242ac1c0002row1_col1,#T_c7094ee0_bf26_11eb_abda_0242ac1c0002row2_col1,#T_c7094ee0_bf26_11eb_abda_0242ac1c0002row3_col1,#T_c7094ee0_bf26_11eb_abda_0242ac1c0002row4_col1,#T_c7094ee0_bf26_11eb_abda_0242ac1c0002row5_col1,#T_c7094ee0_bf26_11eb_abda_0242ac1c0002row6_col1,#T_c7094ee0_bf26_11eb_abda_0242ac1c0002row7_col1,#T_c7094ee0_bf26_11eb_abda_0242ac1c0002row8_col1,#T_c7094ee0_bf26_11eb_abda_0242ac1c0002row9_col1,#T_c7094ee0_bf26_11eb_abda_0242ac1c0002row10_col1{\n",
              "            font-weight:  bold;\n",
              "        }</style><table id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >vae</th>        <th class=\"col_heading level0 col1\" >ed-vae</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row0_col0\" class=\"data row0 col0\" >98.8±0.1</td>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row0_col1\" class=\"data row0 col1\" >99.1±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row1_col0\" class=\"data row1 col0\" >99.6±0.0</td>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row1_col1\" class=\"data row1 col1\" >99.6±0.0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row2_col0\" class=\"data row2 col0\" >84.7±0.7</td>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row2_col1\" class=\"data row2 col1\" >88.3±0.7</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row3_col0\" class=\"data row3 col0\" >86.0±0.7</td>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row3_col1\" class=\"data row3 col1\" >88.4±0.6</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row4_col0\" class=\"data row4 col0\" >89.5±0.4</td>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row4_col1\" class=\"data row4 col1\" >91.2±0.5</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row5_col0\" class=\"data row5 col0\" >88.5±0.4</td>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row5_col1\" class=\"data row5 col1\" >90.0±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row6_col0\" class=\"data row6 col0\" >96.2±0.3</td>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row6_col1\" class=\"data row6 col1\" >97.3±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row7_col0\" class=\"data row7 col0\" >91.3±0.4</td>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row7_col1\" class=\"data row7 col1\" >92.5±0.3</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row8_col0\" class=\"data row8 col0\" >80.9±0.6</td>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row8_col1\" class=\"data row8 col1\" >84.5±0.5</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row9_col0\" class=\"data row9 col0\" >92.0±0.3</td>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row9_col1\" class=\"data row9 col1\" >93.7±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >mean</th>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row10_col0\" class=\"data row10 col0\" >90.8</td>\n",
              "                        <td id=\"T_c7094ee0_bf26_11eb_abda_0242ac1c0002row10_col1\" class=\"data row10 col1\" >92.5</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f1b82396210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW6jgjyvnpgx"
      },
      "source": [
        "### $R_{error}$\n",
        "Compare Reconstruction Error of VAE and ED-VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyX16C3ynpgz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "b2d6d02e-ce08-460d-f260-f71f5b008969"
      },
      "source": [
        "# AUC\n",
        "df = pd.DataFrame((\n",
        "    round(avg_auc_rec_final_results[column,'auc_mean']*100,1).astype(str) + '±' + round(avg_auc_rec_final_results[column,'auc_std']*100/np.sqrt(reps),1).astype(str) for column in avg_auc_rec_final_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_auc_rec_final_results.keys().get_level_values(0)[::2]).T\n",
        "df = df.append(pd.DataFrame((\n",
        "    #round(avg_auc_rec_class_results[column,'auc_mean']*100,1).astype(str) + '±' + round(avg_auc_rec_class_results[column,'pr_auc_std']*100/np.sqrt(reps * len(df.index)),1).astype(str) for column in avg_auc_rec_class_results.keys().get_level_values(0)[::2]\n",
        "    round(avg_auc_rec_class_results[column,'auc_mean']*100,1).astype(str) for column in avg_auc_rec_class_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_auc_rec_class_results.keys().get_level_values(0)[::2]).T)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vae</th>\n",
              "      <th>ed-vae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>99.7±0.0</td>\n",
              "      <td>99.8±0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>99.9±0.0</td>\n",
              "      <td>99.9±0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>92.7±0.4</td>\n",
              "      <td>95.6±0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>94.2±0.3</td>\n",
              "      <td>95.7±0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>94.7±0.3</td>\n",
              "      <td>96.4±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>95.9±0.2</td>\n",
              "      <td>96.9±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>99.1±0.1</td>\n",
              "      <td>99.4±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>96.0±0.2</td>\n",
              "      <td>97.0±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>89.5±0.4</td>\n",
              "      <td>91.1±0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>97.8±0.1</td>\n",
              "      <td>98.6±0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>96.0</td>\n",
              "      <td>97.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           vae    ed-vae\n",
              "0     99.7±0.0  99.8±0.0\n",
              "1     99.9±0.0  99.9±0.0\n",
              "2     92.7±0.4  95.6±0.3\n",
              "3     94.2±0.3  95.7±0.3\n",
              "4     94.7±0.3  96.4±0.4\n",
              "5     95.9±0.2  96.9±0.2\n",
              "6     99.1±0.1  99.4±0.1\n",
              "7     96.0±0.2  97.0±0.2\n",
              "8     89.5±0.4  91.1±0.6\n",
              "9     97.8±0.1  98.6±0.0\n",
              "mean      96.0      97.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zZv0rPOnpg0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "fdb76735-a72d-432b-b157-cbf4b3481f6c"
      },
      "source": [
        "df.style.apply(highlight_max, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row0_col1,#T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row1_col0,#T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row1_col1,#T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row2_col1,#T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row3_col1,#T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row4_col1,#T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row5_col1,#T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row6_col1,#T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row7_col1,#T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row8_col1,#T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row9_col1,#T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row10_col1{\n",
              "            font-weight:  bold;\n",
              "        }</style><table id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >vae</th>        <th class=\"col_heading level0 col1\" >ed-vae</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row0_col0\" class=\"data row0 col0\" >99.7±0.0</td>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row0_col1\" class=\"data row0 col1\" >99.8±0.0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row1_col0\" class=\"data row1 col0\" >99.9±0.0</td>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row1_col1\" class=\"data row1 col1\" >99.9±0.0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row2_col0\" class=\"data row2 col0\" >92.7±0.4</td>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row2_col1\" class=\"data row2 col1\" >95.6±0.3</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row3_col0\" class=\"data row3 col0\" >94.2±0.3</td>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row3_col1\" class=\"data row3 col1\" >95.7±0.3</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row4_col0\" class=\"data row4 col0\" >94.7±0.3</td>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row4_col1\" class=\"data row4 col1\" >96.4±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row5_col0\" class=\"data row5 col0\" >95.9±0.2</td>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row5_col1\" class=\"data row5 col1\" >96.9±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row6_col0\" class=\"data row6 col0\" >99.1±0.1</td>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row6_col1\" class=\"data row6 col1\" >99.4±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row7_col0\" class=\"data row7 col0\" >96.0±0.2</td>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row7_col1\" class=\"data row7 col1\" >97.0±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row8_col0\" class=\"data row8 col0\" >89.5±0.4</td>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row8_col1\" class=\"data row8 col1\" >91.1±0.6</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row9_col0\" class=\"data row9 col0\" >97.8±0.1</td>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row9_col1\" class=\"data row9 col1\" >98.6±0.0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >mean</th>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row10_col0\" class=\"data row10 col0\" >96.0</td>\n",
              "                        <td id=\"T_c75f3d5a_bf26_11eb_abda_0242ac1c0002row10_col1\" class=\"data row10 col1\" >97.0</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f1b82386050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgo09D1Wnpgz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "62e1832f-baf8-48f7-ebc0-6e24d7d9b388"
      },
      "source": [
        "# PR-AUC\n",
        "df = pd.DataFrame((\n",
        "    round(avg_pr_rec_final_results[column,'pr_auc_mean']*100,1).astype(str) + '±' + round(avg_pr_rec_final_results[column,'pr_auc_std']*100/np.sqrt(reps),1).astype(str) for column in avg_pr_rec_final_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_pr_rec_final_results.keys().get_level_values(0)[::2]).T\n",
        "df = df.append(pd.DataFrame((\n",
        "    #round(avg_pr_rec_class_results[column,'pr_auc_mean']*100,1).astype(str) + '±' + round(avg_pr_rec_class_results[column,'pr_auc_std']*100/np.sqrt(reps * len(df.index)),1).astype(str) for column in avg_pr_rec_class_results.keys().get_level_values(0)[::2]\n",
        "    round(avg_pr_rec_class_results[column,'pr_auc_mean']*100,1).astype(str) for column in avg_pr_rec_class_results.keys().get_level_values(0)[::2]\n",
        "    ),index = avg_pr_rec_class_results.keys().get_level_values(0)[::2]).T)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vae</th>\n",
              "      <th>ed-vae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>98.8±0.1</td>\n",
              "      <td>99.1±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>99.7±0.0</td>\n",
              "      <td>99.6±0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84.2±0.7</td>\n",
              "      <td>88.6±0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>85.8±0.6</td>\n",
              "      <td>88.5±0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>89.8±0.5</td>\n",
              "      <td>91.7±0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>89.4±0.3</td>\n",
              "      <td>91.0±0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>96.7±0.3</td>\n",
              "      <td>97.7±0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>90.9±0.3</td>\n",
              "      <td>92.1±0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>81.8±0.6</td>\n",
              "      <td>85.6±0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>92.9±0.2</td>\n",
              "      <td>94.6±0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>91.0</td>\n",
              "      <td>92.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           vae    ed-vae\n",
              "0     98.8±0.1  99.1±0.1\n",
              "1     99.7±0.0  99.6±0.0\n",
              "2     84.2±0.7  88.6±0.7\n",
              "3     85.8±0.6  88.5±0.5\n",
              "4     89.8±0.5  91.7±0.6\n",
              "5     89.4±0.3  91.0±0.4\n",
              "6     96.7±0.3  97.7±0.2\n",
              "7     90.9±0.3  92.1±0.3\n",
              "8     81.8±0.6  85.6±0.5\n",
              "9     92.9±0.2  94.6±0.1\n",
              "mean      91.0      92.9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBA2dwdEnpgz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "0abf3eae-02da-4df7-86bb-33dfbebbcdc5"
      },
      "source": [
        "df.style.apply(highlight_max, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_c754d0d6_bf26_11eb_abda_0242ac1c0002row0_col1,#T_c754d0d6_bf26_11eb_abda_0242ac1c0002row1_col0,#T_c754d0d6_bf26_11eb_abda_0242ac1c0002row2_col1,#T_c754d0d6_bf26_11eb_abda_0242ac1c0002row3_col1,#T_c754d0d6_bf26_11eb_abda_0242ac1c0002row4_col1,#T_c754d0d6_bf26_11eb_abda_0242ac1c0002row5_col1,#T_c754d0d6_bf26_11eb_abda_0242ac1c0002row6_col1,#T_c754d0d6_bf26_11eb_abda_0242ac1c0002row7_col1,#T_c754d0d6_bf26_11eb_abda_0242ac1c0002row8_col1,#T_c754d0d6_bf26_11eb_abda_0242ac1c0002row9_col1,#T_c754d0d6_bf26_11eb_abda_0242ac1c0002row10_col1{\n",
              "            font-weight:  bold;\n",
              "        }</style><table id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >vae</th>        <th class=\"col_heading level0 col1\" >ed-vae</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row0_col0\" class=\"data row0 col0\" >98.8±0.1</td>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row0_col1\" class=\"data row0 col1\" >99.1±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row1_col0\" class=\"data row1 col0\" >99.7±0.0</td>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row1_col1\" class=\"data row1 col1\" >99.6±0.0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row2_col0\" class=\"data row2 col0\" >84.2±0.7</td>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row2_col1\" class=\"data row2 col1\" >88.6±0.7</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row3_col0\" class=\"data row3 col0\" >85.8±0.6</td>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row3_col1\" class=\"data row3 col1\" >88.5±0.5</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row4_col0\" class=\"data row4 col0\" >89.8±0.5</td>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row4_col1\" class=\"data row4 col1\" >91.7±0.6</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row5_col0\" class=\"data row5 col0\" >89.4±0.3</td>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row5_col1\" class=\"data row5 col1\" >91.0±0.4</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row6_col0\" class=\"data row6 col0\" >96.7±0.3</td>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row6_col1\" class=\"data row6 col1\" >97.7±0.2</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row7_col0\" class=\"data row7 col0\" >90.9±0.3</td>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row7_col1\" class=\"data row7 col1\" >92.1±0.3</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row8_col0\" class=\"data row8 col0\" >81.8±0.6</td>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row8_col1\" class=\"data row8 col1\" >85.6±0.5</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row9_col0\" class=\"data row9 col0\" >92.9±0.2</td>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row9_col1\" class=\"data row9 col1\" >94.6±0.1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >mean</th>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row10_col0\" class=\"data row10 col0\" >91.0</td>\n",
              "                        <td id=\"T_c754d0d6_bf26_11eb_abda_0242ac1c0002row10_col1\" class=\"data row10 col1\" >92.9</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f1baa076750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    }
  ]
}